<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://ibug.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ibug.io/" rel="alternate" type="text/html" /><updated>2024-02-28T10:34:20+00:00</updated><id>https://ibug.io/feed.xml</id><title type="html">iBug</title><subtitle>The little personal site for iBug</subtitle><author><name>iBug</name></author><entry><title type="html">My firewall solution for RDP</title><link href="https://ibug.io/blog/2024/02/linux-firewall-for-rdp/" rel="alternate" type="text/html" title="My firewall solution for RDP" /><published>2024-02-28T00:00:00+00:00</published><updated>2024-02-28T18:33:21+00:00</updated><id>https://ibug.io/blog/2024/02/linux-firewall-for-rdp</id><content type="html" xml:base="https://ibug.io/blog/2024/02/linux-firewall-for-rdp/"><![CDATA[<p>Today I stumbled upon <a href="https://www.v2ex.com/t/1019147">this V2EX post</a> (Simplified Chinese) where the OP shared their PowerShell implementation of a “makeshift fail2ban” for RDP (<a href="https://github.com/Qetesh/rdpFail2Ban">their GitHub repository</a>). Their script looked very clean and robust, but needless to say, it is unnecessarily difficult on Windows. So on this rare (maybe?) occasion I decide to share my firewall for securing RDP access to my Windows hosts.</p>
			<p><strong>None</strong> of my Windows hosts (PCs and VMs) has their RDP port exposed to the public internet directly, and they’re all connected to my mesh VPN (which is out of scope for this blog article). My primary public internet entry gateway for the intranet runs Debian with fully manually configured iptables-based firewall, and I frequently work on it through SSH.</p>
			<p>My goal is to expose the RDP port only to myself. There are a few obvious solutions eliminated for different reasons:</p>
			<ul>
				<li><strong>VPN</strong> is inconvenient as I don’t want to connect to VPN just for RDP when I don’t need it otherwise.</li>
				<li><strong>SSH port forwarding</strong> is not performant for two things: Double-encryption and lack of UDP support.</li>
			</ul>
			<p>The question arises that if SSH access is sufficiently convenient, why not use it as an authentication and authorization mechanism? So I came up with this:</p>
			<ul>
				<li>
					<p>A pre-configured iptables rule set to allow RDP access from a specific IP set. For example:</p>
					<div class="language-shell highlighter-rouge">
						<div class="highlight">
							<pre class="highlight"><code>  <span class="k">*</span>filter
  :FORWARD DROP
  <span class="nt">-A</span> FORWARD <span class="nt">-d</span> 192.0.2.1 <span class="nt">-p</span> tcp <span class="nt">--dport</span> 3389 <span class="nt">-m</span> <span class="nb">set</span> <span class="nt">--set</span> ibug <span class="nt">-j</span> ACCEPT

  <span class="k">*</span>nat
  <span class="nt">-A</span> RDPForward <span class="nt">-p</span> tcp <span class="nt">--dport</span> 3389 <span class="nt">-j</span> DNAT <span class="nt">--to-destination</span> 192.0.2.1:3389
  <span class="nt">-A</span> RDPForward <span class="nt">-p</span> udp <span class="nt">--dport</span> 3389 <span class="nt">-j</span> DNAT <span class="nt">--to-destination</span> 192.0.2.1:3389
</code></pre>
						</div>
    </div>
				</li>
				<li>
					<p>A way to keep the client address in the set for the duration of the SSH session. I use SSH user rc file to proactively refresh it:</p>
					<div class="language-shell highlighter-rouge">
						<div class="highlight">
							<pre class="highlight"><code>  <span class="c">#!/bin/bash</span>
  <span class="c"># rwxr-xr-x ~/.ssh/rc</span>

  <span class="k">if</span> <span class="o">[</span> <span class="nt">-z</span> <span class="s2">"</span><span class="nv">$BASH</span><span class="s2">"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then
    </span><span class="nb">exec</span> /bin/bash <span class="nt">--</span> <span class="s2">"</span><span class="nv">$0</span><span class="s2">"</span> <span class="s2">"</span><span class="nv">$@</span><span class="s2">"</span>
    <span class="nb">exit </span>1
  <span class="k">fi

  </span><span class="nv">_ssh_client</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">SSH_CONNECTION</span><span class="p">%% *</span><span class="k">}</span><span class="s2">"</span>
  <span class="nv">_ppid</span><span class="o">=</span><span class="s2">"</span><span class="si">$(</span>ps <span class="nt">-o</span> <span class="nv">ppid</span><span class="o">=</span> <span class="si">$(</span>ps <span class="nt">-o</span> <span class="nv">ppid</span><span class="o">=</span> <span class="nv">$PPID</span><span class="si">))</span><span class="s2">"</span>

  <span class="nb">nohup</span> ~/.local/bin/_ssh_refresh_client <span class="s2">"</span><span class="nv">$_ssh_client</span><span class="s2">"</span> <span class="s2">"</span><span class="nv">$_ppid</span><span class="s2">"</span> &amp;&gt;/dev/null &amp; <span class="nb">exit </span>0
</code></pre>
						</div>
    </div>
					<div class="language-shell highlighter-rouge">
						<div class="highlight">
							<pre class="highlight"><code>  <span class="c">#!/bin/sh</span>
  <span class="c"># rwxr-xr-x ~/.local/bin/_ssh_refresh_client</span>
  <span class="nv">_ssh_client</span><span class="o">=</span><span class="s2">"</span><span class="nv">$1</span><span class="s2">"</span>
  <span class="nv">_ppid</span><span class="o">=</span><span class="s2">"</span><span class="nv">$2</span><span class="s2">"</span>
  <span class="k">while </span><span class="nb">kill</span> <span class="nt">-0</span> <span class="s2">"</span><span class="nv">$_ppid</span><span class="s2">"</span> 2&gt;/dev/null<span class="p">;</span> <span class="k">do
    </span><span class="nb">sudo </span>ipset <span class="nt">-exist</span> add ibug <span class="s2">"</span><span class="nv">$_ssh_client</span><span class="s2">"</span> <span class="nb">timeout </span>300
    <span class="nb">sleep </span>60
  <span class="k">done
  </span><span class="nb">exit </span>0
</code></pre>
						</div>
    </div>
				</li>
			</ul>
			<p>The idea is to refresh (<code class="language-plaintext highlighter-rouge">ipset add</code> with timeout) the IPset entry as long as the SSH session remains. When SSH disconnects, the script stops refreshing and IPset will clean it up after the specified time.</p>
			<p>To determine the presence of the associated SSH session, the scripts finds the PID of the “session manager process”. The “parent PID” is read twice because <code class="language-plaintext highlighter-rouge">sshd</code> double-forks. The client address is conveniently provided in the environment variable, so putting all these together yields precisely what I need.</p>
			<p>The only caveat is the use of <code class="language-plaintext highlighter-rouge">sudo</code>, as <code class="language-plaintext highlighter-rouge">ipset</code> requires <code class="language-plaintext highlighter-rouge">CAP_NET_ADMIN</code> for interacting with the kernel network stack. It’s certainly possible to write an SUID binary as a wrapper, but for me configuring passwordless sudo for the <code class="language-plaintext highlighter-rouge">ipset</code> command satisfies my demands.</p>
			<p>So now whenever I need to RDP to my computer through this forwarded port on the public internet, I can just SSH into the gateway and it’ll automatically grant me 5 minutes of RDP access from this specific network. All traffic forwarding is done in the kernel with no extra encapsulation or encryption, ensuring the best possible performance for both the endpoints and the gateway router itself.</p>
			]]></content><author><name>iBug</name></author><category term="linux" /><category term="windows" /><category term="networking" /><summary type="html"><![CDATA[Today I stumbled upon this V2EX post (Simplified Chinese) where the OP shared their PowerShell implementation of a “makeshift fail2ban” for RDP (their GitHub repository). Their script looked very clean and robust, but needless to say, it is unnecessarily difficult on Windows. So on this rare (maybe?) occasion I decide to share my firewall for securing RDP access to my Windows hosts.]]></summary></entry><entry><title type="html">Request limiting in Nginx</title><link href="https://ibug.io/blog/2024/01/nginx-limit-req/" rel="alternate" type="text/html" title="Request limiting in Nginx" /><published>2024-01-23T00:00:00+00:00</published><updated>2024-01-23T06:15:20+00:00</updated><id>https://ibug.io/blog/2024/01/nginx-limit-req</id><content type="html" xml:base="https://ibug.io/blog/2024/01/nginx-limit-req/"><![CDATA[<p>Nginx has a built-in module <code class="language-plaintext highlighter-rouge">limit_req</code> for rate-limiting requests, which does a decent job, except its documentation is not known for its conciseness, plus a few questionable design choices. I happen to have a specific need for this feature so I examined it a bit.</p>
		<p>As always, everything begins with <a href="https://nginx.org/en/docs/http/ngx_http_limit_req_module.html">the documentation</a>. A quick-start example is given:</p>
		<div class="language-nginx highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code><span class="k">http</span> <span class="p">{</span>
    <span class="kn">limit_req_zone</span> <span class="nv">$binary_remote_addr</span> <span class="s">zone=one:10m</span> <span class="s">rate=1r/s</span><span class="p">;</span>
    <span class="kn">...</span>
    <span class="s">server</span> <span class="p">{</span>
        <span class="kn">...</span>
        <span class="s">location</span> <span class="n">/search/</span> <span class="p">{</span>
            <span class="kn">limit_req</span> <span class="s">zone=one</span> <span class="s">burst=5</span><span class="p">;</span>
        <span class="p">}</span>
</code></pre>
			</div>
		</div>
		<p>The basis is the <code class="language-plaintext highlighter-rouge">limit_req_zone</code> directive, which defines a shared memory zone for storing the states of the rate-limiting. Its arguments include the key, the size and the name of the zone, followed by the average or sustained rate limit. The rate limit has two possible units: <code class="language-plaintext highlighter-rouge">r/s</code> or <code class="language-plaintext highlighter-rouge">r/m</code>. It also says</p>
		<blockquote>
			<p>The limitation is done using the “<a href="https://en.wikipedia.org/wiki/Leaky_bucket">leaky bucket</a>” method.</p>
		</blockquote>
		<p>So far so good, except the burst limit is … specified on where it’s used? Moving on for now.</p>
		<p>The <code class="language-plaintext highlighter-rouge">limit_req</code> directive specifies when the requests should be limited.</p>
		<blockquote>
			<p>If the requests rate exceeds the rate configured for a zone, their processing is delayed such that requests are processed at a defined rate.</p>
		</blockquote>
		<p>Seems pretty clear but slightly counter-intuitive. By default, burst requests are queued up and delayed until the rate is below the limit, whereas most common rate-limiting implementations would simply serve them.</p>
		<p>I find it easier to understand this model with a queue. Each key defines a queue where items are popped at the specified rate (e.g. <code class="language-plaintext highlighter-rouge">1r/s</code>). Incoming requests are added to the queue, and are only served <em>upon exiting</em> the queue. The queue size is defined by the burst limit, and excess requests are dropped when the queue is full.</p>
		<p><img src="/image/server/nginx-limit-req.png" alt="Default queue behavior" /></p>
		<p>The more common behavior, however, requires an extra option:</p>
		<blockquote>
			<p>If delaying of excessive requests while requests are being limited is not desired, the parameter <code class="language-plaintext highlighter-rouge">nodelay</code> should be used:</p>
			<div class="language-nginx highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="k">limit_req</span> <span class="s">zone=one</span> <span class="s">burst=5</span> <span class="s">nodelay</span><span class="p">;</span>
</code></pre>
				</div>
  </div>
		</blockquote>
		<p>With <code class="language-plaintext highlighter-rouge">nodelay</code>, requests are served as soon as they <em>enter the queue</em>:</p>
		<p><img src="/image/server/nginx-limit-req-nodelay.png" alt="nodelay queue behavior" /></p>
		<p>The next confusing option, conflicting with <code class="language-plaintext highlighter-rouge">nodelay</code>, is <code class="language-plaintext highlighter-rouge">delay</code>:</p>
		<blockquote>
			<p>The <code class="language-plaintext highlighter-rouge">delay</code> parameter specifies a limit at which excessive requests become delayed. Default value is zero, i.e. all excessive requests are delayed.</p>
		</blockquote>
		<p>After a bit of fiddling, I realized the model is now like this:</p>
		<p><img src="/image/server/nginx-limit-req-delay.png" alt="delay queue behavior" /></p>
		<p>So what <code class="language-plaintext highlighter-rouge">delay</code> actually means is to delay requests after this “delay limit” is reached. In other words, requests are served as soon as they arrive at the n-th position in the front of the queue.</p>
		<p>During all these testing, I wasn’t happy with existing tools for testing, so I wrote my own one, despite its simplicity: <a href="https://gist.github.com/iBug/351b458633ff89fea0fc9f0edd07fc28">GitHub Gist</a>.</p>
		<p>With this new tool, I can now (textually) visualize the behavior of different options. Under the <code class="language-plaintext highlighter-rouge">burst=5</code> and <code class="language-plaintext highlighter-rouge">delay=1</code> setup, the output is like this:</p>
		<div class="language-console highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>go run main.go <span class="nt">-i</span> 10ms <span class="nt">-c</span> 10 http://localhost/test
<span class="go">[1] Done [0s] [200 in 2ms]
[2] Done [10ms] [200 in 1ms]
[3] Done [21ms] [200 in 981ms]
[4] Done [31ms] [200 in 1.972s]
[5] Done [42ms] [200 in 2.962s]
[6] Done [53ms] [200 in 3.948s]
[7] Done [64ms] [503 in 0s]
[8] Done [75ms] [503 in 1ms]
[9] Done [85ms] [503 in 0s]
[10] Done [95ms] [503 in 0s]
</span></code></pre>
			</div>
		</div>
		<p>If you try the tool yourself, the HTTP status codes are colored for even better prominence.</p>
		<p>In the above example, the first request is served immediately as it also exits the queue immediately. The second request is queued at the front, and because <code class="language-plaintext highlighter-rouge">delay=1</code>, it’s also served immediately. Subsequent requests are queued up until the sixth when the queue becomes full. The seventh and thereafter are dropped.</p>
		<p>If we change <code class="language-plaintext highlighter-rouge">delay=0</code>, the output becomes:</p>
		<div class="language-console highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>go run main.go <span class="nt">-i</span> 10ms <span class="nt">-c</span> 10 http://localhost/test
<span class="go">[1] Done [0s] [200 in 2ms]
[2] Done [10ms] [200 in 993ms]
[3] Done [21ms] [200 in 1.982s]
[4] Done [32ms] [200 in 2.973s]
[5] Done [43ms] [200 in 3.959s]
[6] Done [54ms] [200 in 4.949s]
[7] Done [65ms] [503 in 1ms]
[8] Done [75ms] [503 in 1ms]
[9] Done [85ms] [503 in 2ms]
[10] Done [96ms] [503 in 1ms]
</span></code></pre>
			</div>
		</div>
		<p>Still only the first 6 requests are served, but the 2nd to the 6th are delayed by an additional second due to the removal of <code class="language-plaintext highlighter-rouge">delay=1</code>.</p>
		<p>Under this model, the <code class="language-plaintext highlighter-rouge">nodelay</code> option can be understood as <code class="language-plaintext highlighter-rouge">delay=infinity</code>, while still respecting the <code class="language-plaintext highlighter-rouge">burst</code> limit.</p>
		<h2 id="one-more-question">One more question</h2>
		<p>Why is the burst limit specified at use time, instead of at zone definition? Only experiments can find out:</p>
		<div class="language-nginx highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code><span class="k">location</span> <span class="n">/a</span> <span class="p">{</span>
    <span class="kn">limit_req</span> <span class="s">zone=test</span> <span class="s">burst=1</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">location</span> <span class="n">/b</span> <span class="p">{</span>
    <span class="kn">limit_req</span> <span class="s">zone=test</span> <span class="s">burst=5</span><span class="p">;</span>
<span class="p">}</span>
</code></pre>
			</div>
		</div>
		<p>Then I fire up two simultaneous batches of 10 requests each to <code class="language-plaintext highlighter-rouge">/a</code> and <code class="language-plaintext highlighter-rouge">/b</code> respectively:</p>
		<div class="language-console highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>go run main.go <span class="nt">-i</span> 10ms <span class="nt">-c</span> 10 http://localhost/a
<span class="go">[1] Done [0s] [200 in 2ms]
[2] Done [10ms] [200 in 992ms]
[3] Done [21ms] [503 in 0s]
[4] Done [32ms] [503 in 0s]
[5] Done [42ms] [503 in 0s]
[6] Done [53ms] [503 in 0s]
[7] Done [63ms] [503 in 0s]
[8] Done [73ms] [503 in 0s]
[9] Done [83ms] [503 in 0s]
[10] Done [94ms] [503 in 0s]
</span></code></pre>
			</div>
		</div>
		<div class="language-console highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>go run main.go <span class="nt">-i</span> 10ms <span class="nt">-c</span> 10 http://localhost/b
<span class="go">[1] Done [0s] [200 in 1.862s]
[2] Done [11ms] [200 in 2.852s]
[3] Done [21ms] [200 in 3.842s]
[4] Done [32ms] [200 in 4.832s]
[5] Done [43ms] [503 in 1ms]
[6] Done [54ms] [503 in 0s]
[7] Done [64ms] [503 in 0s]
[8] Done [75ms] [503 in 1ms]
[9] Done [85ms] [503 in 0s]
[10] Done [95ms] [503 in 1ms]
</span></code></pre>
			</div>
		</div>
		<p>As can be seen from the output, the batch to <code class="language-plaintext highlighter-rouge">/a</code> is served as usual, but the batch to <code class="language-plaintext highlighter-rouge">/b</code> is significantly delayed, and two fewer requests are served.</p>
		<p>If I reverse the order of sending the batches, the result is different again:</p>
		<div class="language-console highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>go run main.go <span class="nt">-i</span> 10ms <span class="nt">-c</span> 10 http://localhost/b
<span class="go">[1] Done [0s] [200 in 2ms]
[2] Done [10ms] [200 in 993ms]
[3] Done [20ms] [200 in 1.982s]
[4] Done [31ms] [200 in 2.974s]
[5] Done [42ms] [200 in 3.963s]
[6] Done [52ms] [200 in 4.955s]
[7] Done [63ms] [503 in 0s]
[8] Done [74ms] [503 in 0s]
[9] Done [84ms] [503 in 0s]
[10] Done [95ms] [503 in 0s]
</span></code></pre>
			</div>
		</div>
		<div class="language-console highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>go run main.go <span class="nt">-i</span> 10ms <span class="nt">-c</span> 10 http://localhost/a
<span class="go">[1] Done [0s] [503 in 1ms]
[2] Done [10ms] [503 in 1ms]
[3] Done [20ms] [503 in 0s]
[4] Done [31ms] [503 in 0s]
[5] Done [42ms] [503 in 0s]
[6] Done [52ms] [503 in 0s]
[7] Done [63ms] [503 in 1ms]
[8] Done [73ms] [503 in 0s]
[9] Done [83ms] [503 in 0s]
[10] Done [93ms] [503 in 0s]
</span></code></pre>
			</div>
		</div>
		<p>This time the batch to <code class="language-plaintext highlighter-rouge">/b</code> is served as usual, but the entire batch to <code class="language-plaintext highlighter-rouge">/a</code> is rejected.</p>
		<p>I am now convinced that the queue itself is shared between <code class="language-plaintext highlighter-rouge">/a</code> and <code class="language-plaintext highlighter-rouge">/b</code>, and each <code class="language-plaintext highlighter-rouge">limit_req</code> directive decides for itself whether and when to serve the requests. So when <code class="language-plaintext highlighter-rouge">/a</code> is served first, the queue holds one burst request, and <code class="language-plaintext highlighter-rouge">/b</code> fills the queue up to 5 requests. When <code class="language-plaintext highlighter-rouge">/b</code> is served first, the queue is already holding 5 requests and leaves no room for <code class="language-plaintext highlighter-rouge">/a</code>. Similarly, with the <code class="language-plaintext highlighter-rouge">delay</code> option, each <code class="language-plaintext highlighter-rouge">limit_req</code> directive can still decide when the request is ready to serve.</p>
		<p>This is probably not the most straightforward design, and I can’t come up with a use case for this behavior. But at least now I understand how it works.</p>
		<h2 id="one-last-thing">One last thing</h2>
		<p>I originally wanted to set up a 403 page for banned clients, and wanted to limit the rate of log writing in case of an influx of requests. The limit_req module does provide a <code class="language-plaintext highlighter-rouge">$limit_req_status</code> variable which appears to be useful. This is what I ended up with:</p>
		<div class="language-nginx highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code><span class="k">limit_req_zone</span> <span class="nv">$binary_remote_addr</span> <span class="s">zone=403:64k</span> <span class="s">rate=1r/s</span><span class="p">;</span>

<span class="k">map</span> <span class="nv">$limit_req_status</span> <span class="nv">$loggable_403</span> <span class="p">{</span>
    <span class="kn">default</span> <span class="mi">0</span><span class="p">;</span>
    <span class="kn">PASSED</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kn">DELAYED</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kn">DELAYED_DRY_RUN</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">server</span> <span class="p">{</span>
    <span class="kn">access_log</span> <span class="n">/var/log/nginx/403/access.log</span> <span class="s">main</span> <span class="s">if=</span><span class="nv">$loggable_403</span><span class="p">;</span>
    <span class="kn">error_log</span> <span class="n">/var/log/nginx/403/error.log</span> <span class="s">warn</span><span class="p">;</span>
    <span class="kn">error_page</span> <span class="mi">403</span> <span class="n">/403.html</span><span class="p">;</span>
    <span class="kn">error_page</span> <span class="mi">404</span> <span class="p">=</span><span class="mi">403</span> <span class="n">/403.html</span><span class="p">;</span>
    <span class="kn">limit_req</span> <span class="s">zone=403</span><span class="p">;</span>
    <span class="kn">limit_req_status</span> <span class="mi">403</span><span class="p">;</span>
    <span class="kn">limit_req_log_level</span> <span class="s">info</span><span class="p">;</span>

    <span class="kn">location</span> <span class="n">/</span> <span class="p">{</span>
        <span class="kn">return</span> <span class="mi">403</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="kn">location</span> <span class="p">=</span> <span class="n">/403.html</span> <span class="p">{</span>
        <span class="kn">internal</span><span class="p">;</span>
        <span class="kn">root</span> <span class="n">/srv/nginx</span><span class="p">;</span>
        <span class="kn">sub_filter</span> <span class="s">"%remote_addr%"</span> <span class="s">"</span><span class="nv">$remote_addr</span><span class="s">"</span><span class="p">;</span>
        <span class="kn">sub_filter_once</span> <span class="no">off</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre>
			</div>
		</div>
		<p>With this setup, excessive requests are rejected by <code class="language-plaintext highlighter-rouge">limit_req</code> with a 403 status. Only <code class="language-plaintext highlighter-rouge">1r/s</code> passes through the rate limiting, which will carry the <code class="language-plaintext highlighter-rouge">PASSED</code> status and be logged, albeit still seeing the 403 page from the <code class="language-plaintext highlighter-rouge">return 403</code> rule. This does exactly what I want, so time to call it a day.</p>
		]]></content><author><name>iBug</name></author><category term="server" /><category term="nginx" /><summary type="html"><![CDATA[Nginx has a built-in module limit_req for rate-limiting requests, which does a decent job, except its documentation is not known for its conciseness, plus a few questionable design choices. I happen to have a specific need for this feature so I examined it a bit.]]></summary></entry><entry><title type="html">Visualizing Weather Forecast with Grafana</title><link href="https://ibug.io/blog/2024/01/weather-forecast-with-grafana/" rel="alternate" type="text/html" title="Visualizing Weather Forecast with Grafana" /><published>2024-01-08T00:00:00+00:00</published><updated>2024-01-08T04:40:54+00:00</updated><id>https://ibug.io/blog/2024/01/weather-forecast-with-grafana</id><content type="html" xml:base="https://ibug.io/blog/2024/01/weather-forecast-with-grafana/"><![CDATA[<p>Grafana is a great piece of software for visualizing data and monitoring. It’s outstanding at what it does when paired with a time-series database like InfluxDB, except this time I’m trying to get it to work as a weather forecast dashboard, instead of any historical time-series data.</p>
	<p>I choose <a href="https://open.caiyunapp.com/%E5%BD%A9%E4%BA%91%E5%A4%A9%E6%B0%94_API_%E4%B8%80%E8%A7%88%E8%A1%A8">CaiYun Weather (彩云天气) API</a> for having previous experience with it, as well as its unlimited free tier. I must admit that I initially came up with this idea for having seen the presence of <a href="https://grafana.com/grafana/plugins/marcusolsson-json-datasource/">JSON API datasource plugin</a> for Grafana, which reminds me of CaiYun’s JSON API being a perfect fit.</p>
	<h2 id="json-api-datasource">JSON API Datasource</h2>
	<p>Configuring the datasource seems easy at first, like just inserting the URL and configure HTTP headers as needed. Since CY’s API puts the API key in the URL path, there’s no headers to configure. So I can just put a single URL and save it.</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>https://api.caiyunapp.com/v2.5/TAkhjf8d1nlSlspN/121.6544,25.1552/hourly.json
</code></pre>
		</div>
	</div>
	<p>I choose the hourly API so I can have forecast for the upcoming 48 hours.</p>
	<p>So far this is a readily available datasource that I can query. But after reviewing the <a href="https://grafana.github.io/grafana-json-datasource/query-editor">JSON query editor</a>, I decided to chop off the last segments of the URL and leave just the part up to the API key:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>https://api.caiyunapp.com/v2.5/TAkhjf8d1nlSlspN/
</code></pre>
		</div>
	</div>
	<p>The point here is, the query editor allows specifying an extra Path, which appears to be concatenated with this URL in the datasource configuration. Notably, I can then put the coordinates in a variable, use it in the query, and build a single dashboard for many cities.</p>
	<h2 id="dashboard-variables">Dashboard variables</h2>
	<p>Now that I have the query format planned, I can add a dashboard variable for selecting cities.</p>
	<p>First things first, since I’m going to use the same datasource for all panels, I first add a variable for the datasource and restrict it to “CaiYun Weather”:</p>
	<p><img src="/image/grafana/dashboard-variable-datasource.png" alt="Datasource variable" /></p>
	<p>Then I add a variable <code class="language-plaintext highlighter-rouge">$location</code> for the city name, and provide it with a list of cities I want to show. The variable type would be “Custom” since this is just a human-maintained list. There certainly are better ways like using a relational database or an external API, making it easier to update, but for now I’d like to keep it simple.</p>
	<div class="language-text highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>Beijing : 116.4074\,39.9042,Shanghai : 121.4691\,31.2243,Guangzhou : 113.2644\,23.1291,Shenzhen : 114.0596\,22.5429
</code></pre>
		</div>
	</div>
	<h2 id="panels">Panels</h2>
	<p>First and foremost, the most intuitive metric to show is temperature. I add a time series panel and configure it to graph the temperature. Start by building the query:</p>
	<ul>
		<li>Datasource: Select <code class="language-plaintext highlighter-rouge">${datasource}</code></li>
		<li>Query A:
			<ul>
				<li>Path: <code class="language-plaintext highlighter-rouge">/${location}/hourly.json</code></li>
				<li>Fields:
					<ul>
						<li>JSONPath: <code class="language-plaintext highlighter-rouge">$.result.hourly.temperature[*].value</code>, Type: <code class="language-plaintext highlighter-rouge">Number</code>, Alias: <code class="language-plaintext highlighter-rouge">${location:text}</code></li>
						<li>JSONPath: <code class="language-plaintext highlighter-rouge">$.result.hourly.temperature[*].datetime</code>, Type: <code class="language-plaintext highlighter-rouge">Time</code></li>
					</ul>
				</li>
			</ul>
		</li>
	</ul>
	<p>I stumbled on getting the <em>time</em> series to display correctly. It wasn’t anywhere obvious in the documentation for the JSON API plugin, but a series with Type = Time is required. Fortunately, CY’s API returns the time in ISO 8601 format in the <code class="language-plaintext highlighter-rouge">datetime</code> field, so I can feed it directly to Grafana.</p>
	<p>So far so good, except Grafana shows “No data”. I realized Grafana is trying to show past data, but apparently a weather forecast provides <em>future</em> data. I need to change the time range to “now” and “now + 48h”. Ideally, this time range is fixed and not affected by the time range selector, since after all it’s limited by the API.</p>
	<p>This is another place where I spent half an hour on Google. The answer is “Relative time” in “Query options”. Its format, however, is again unintuitive. While <a href="https://community.grafana.com/t/how-to-give-different-time-ranges-for-grafana-panels-i-am-using-azure-monitor-as-data-source/80300">community posts</a> shows <code class="language-plaintext highlighter-rouge">1d</code> for “last 1 day” and the <a href="https://grafana.com/docs/grafana/latest/panels-visualizations/query-transform-data/">official docs</a> gives several examples on using <code class="language-plaintext highlighter-rouge">now</code>, none of them told me how to indicate “next 48 hours”. The answer is just <code class="language-plaintext highlighter-rouge">+48h</code> or <code class="language-plaintext highlighter-rouge">+2d</code>. Notably, entering <code class="language-plaintext highlighter-rouge">now+48h</code> would result in an error.</p>
	<p>To make the graph look nicer, I set the unit to “°C”, limit decimals to 1, and set the Y-axis range to 0-40, and add a series of thresholds with colors to indicate the temperature range. Also worth mentioning is to make the graph change its color according to the temperature, so I set “Graph style → Gradient mode” to “Scheme” and “Standard options → Color scheme” to “From thresholds (by value)”.</p>
	<p>Now this panel looks stunning.</p>
	<p><img src="/image/grafana/caiyun-temperature-panel.png" alt="Temperature panel" /></p>
	<h3 id="more-panels">More panels</h3>
	<p>CY’s API offers a variety of weather data, so with little effort I can add more panels for humidity, precipitation and more, by duplicating the temperature panel and changing the query. I also need to change the unit and thresholds accordingly but that goes without saying.</p>
	<p>There’s also a small piece worth displaying: A <code class="language-plaintext highlighter-rouge">description</code> text. It’s easy to put it in a “Stat” panel and display as “String” (instead of “Number”). And better yet, CY provides two descriptions: One for the next two hours, and one for the next two days. Two panels for two pieces of text, yeah.</p>
	<p>One last thing I decided to leave out for now: The <code class="language-plaintext highlighter-rouge">skycon</code> field that describes the weather condition, like “CLEAR_DAY” or “RAIN”. It’d be comparably easy to add a panel for it, using “Value mapping” to change the text to something more human-readable, but I’m not at the high mood for it right now, so maybe I’ll pick it up later.</p>
	<h2 id="results">Results</h2>
	<p>Now I have a nice dashboard for viewing weather forecast for multiple cities:</p>
	<p><img src="/image/grafana/caiyun-forecast-example.png" alt="Dashboard" /></p>
	<p>If you’d like to try it yourself, I’ve published the dashboard on Grafana.com: <a href="https://grafana.com/grafana/dashboards/20259-weather-forecast/">Weather Forecast</a>. Just add the same datasource with your API key, and you can import my dashboard and start getting weather forecast for yourself.</p>
	]]></content><author><name>iBug</name></author><category term="software" /><summary type="html"><![CDATA[Grafana is a great piece of software for visualizing data and monitoring. It’s outstanding at what it does when paired with a time-series database like InfluxDB, except this time I’m trying to get it to work as a weather forecast dashboard, instead of any historical time-series data.]]></summary></entry><entry><title type="html">Understanding ZFS block sizes</title><link href="https://ibug.io/blog/2023/10/zfs-block-size/" rel="alternate" type="text/html" title="Understanding ZFS block sizes" /><published>2023-10-30T00:00:00+00:00</published><updated>2023-10-30T02:58:51+00:00</updated><id>https://ibug.io/blog/2023/10/zfs-block-size</id><content type="html" xml:base="https://ibug.io/blog/2023/10/zfs-block-size/"><![CDATA[<p>ZFS is about the most complex filesystem for single-node storage servers. Coming with its sophistication is its equally confusing “block size”, which is normally self-evident on common filesystems like ext4 (or more primitively, FAT). The enigma continues as ZFS bundles more optimizations, either for performance or in the name of “intuition” (which I would hardly agree). So recently I read a lot of materials on this and try to make sense of it.</p>
	<p>We’ll begin with a slide from a ZFS talk from Lustre<sup id="fnref:dilger" role="doc-noteref"><a href="#fn:dilger" class="footnote" rel="footnote">1</a></sup> (page 5):</p>
	<figure class="">
		<img src="/image/zfs/zfs-io-stack.png" alt="ZFS I/O Stack" />
		<figcaption>
			Figure 1. ZFS I/O Stack
		</figcaption>
	</figure>
	<!-- This article will focus on the topmost layer (ZPL and DMU) and the lowermost layer (vdev and disk sectors). -->
	<h2 id="logical-blocks">Logical blocks</h2>
	<p>The first thing to understand is that there are at least two levels of “block” concepts in ZFS. There’s “logical blocks” on an upper layer (DMU), and “physical blocks” on a lower layer (vdev). The latter is easier to understand and it’s almost synonymous to “disk sectors”. It’s precisely the <code class="language-plaintext highlighter-rouge">ashift</code> parameter in <code class="language-plaintext highlighter-rouge">zpool create</code> command and usually matches the physical sector size of your disks (4 KiB for modern disks). Once set, <code class="language-plaintext highlighter-rouge">ashift</code> is immutable and can only be changed when recreating the entire vdev array (fortunately not the entire pool<sup id="fnref:zfs101" role="doc-noteref"><a href="#fn:zfs101" class="footnote" rel="footnote">2</a></sup>). The “logical block”, however, is slightly more complicated, and beyond the expressibility of a few words. In short, it’s the smallest <em>meaningful</em> unit of data that ZFS can operate on, including reading, writing, checksumming, compression and deduplication.</p>
	<h3 id="recordsize-and-volblocksize">“recordsize” and “volblocksize”</h3>
	<p>You’ve probably seen <code class="language-plaintext highlighter-rouge">recordsize</code> being talked about extensively in ZFS tuning guides<sup id="fnref:tuning" role="doc-noteref"><a href="#fn:tuning" class="footnote" rel="footnote">3</a></sup>, which is already a great source of confusion. The default <code class="language-plaintext highlighter-rouge">recordsize</code> is 128 KiB, which controls the <em>maximum</em> size of a logical block. The <em>actual</em> block size depends on the file you’re writing:</p>
	<ul>
		<li>If the file is smaller than or equal to <code class="language-plaintext highlighter-rouge">recordsize</code>, it’s stored as a single logical block of its size, rounded up to the nearest multiple of 512 bytes.</li>
		<li>If the file is larger than <code class="language-plaintext highlighter-rouge">recordsize</code>, it’s split into multiple logical blocks of <code class="language-plaintext highlighter-rouge">recordsize</code> each, with the last block being zero-padded to <code class="language-plaintext highlighter-rouge">recordsize</code>.</li>
	</ul>
	<p>As with other filesystems, if you change a small portion of a large file, only 128 KiB (or whatever your <code class="language-plaintext highlighter-rouge">recordsize</code> is) is rewritten, along with new metadata and checksums. Large <code class="language-plaintext highlighter-rouge">recordsize</code> bloats the read/write amplification for random I/O workloads, while small <code class="language-plaintext highlighter-rouge">recordsize</code> increases the fragmentation and metadata overhead for large files. Note that ZFS always validates checksums, so every read operation is done on an entire block, even if only a few bytes are requested. So it is important to align your <code class="language-plaintext highlighter-rouge">recordsize</code> with your workload, like using 16 KiB for (most) databases and 1 MiB for media files. The default 128 KiB is a good compromise for general-purpose workloads, and there certainly isn’t a one-size-fits-all solution. Also note that while <code class="language-plaintext highlighter-rouge">recordsize</code> can be changed on the fly, it only affects newly written data, and existing ones stay intact.</p>
	<p>For ZVOLs, as you’d imagine, the rule is much simpler: Every block of <code class="language-plaintext highlighter-rouge">volblocksize</code> is a logical block, and it’s aligned to its own size. Since ZFS 2.2, the default <code class="language-plaintext highlighter-rouge">volblocksize</code> is 16 KiB, providing a good balance between performance and compatibility.</p>
	<h3 id="compression">Compression</h3>
	<p>Compression is applied on a per-block basis, and compressed data is not shared between blocks. This is best shown with an example:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>zfs get compression tank/test
<span class="go">NAME       PROPERTY     VALUE  SOURCE
tank/test  compression  zstd   inherited from tank
</span><span class="gp">$</span><span class="w"> </span><span class="nb">head</span> <span class="nt">-c</span> 131072 /dev/urandom <span class="o">&gt;</span> 128k
<span class="gp">$</span><span class="w"> </span><span class="nb">cat </span>128k 128k 128k 128k 128k 128k 128k 128k <span class="o">&gt;</span> 1m
<span class="gp">$</span><span class="w"> </span><span class="nb">du</span> <span class="nt">-sh</span> 128k 1m
<span class="go">129K    128k
1.1M    1m
</span></code></pre>
		</div>
	</div>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">$</span><span class="w"> </span><span class="nb">head</span> <span class="nt">-c</span> 16384 /dev/urandom <span class="o">&gt;</span> 16k
<span class="gp">$</span><span class="w"> </span><span class="nb">cat </span>16k 16k 16k 16k 16k 16k 16k 16k <span class="o">&gt;</span> 128k1
<span class="gp">$</span><span class="w"> </span><span class="nb">cat </span>128k1 128k1 128k1 128k1 128k1 128k1 128k1 128k1 <span class="o">&gt;</span> 1m1
<span class="gp">$</span><span class="w"> </span><span class="nb">du</span> <span class="nt">-sh</span> 16k 128k1 1m1
<span class="go">17K     16k
21K     128k1
169K    1m1
</span></code></pre>
		</div>
	</div>
	<p>As you can see from <code class="language-plaintext highlighter-rouge">du</code>’s output above, despite containing 8 identical copies of the same 128 KiB random data, the 1 MiB file gains precisely nothing from compression, as each 128 KiB block is compressed individually. The other test of combining 8 copies of 16 KiB random data into one 128 KiB file shows positive results, as the 128 KiB file is only 21 KiB in size. Similarly, the 1 MiB file that contains 64 exact copies of the same 16 KiB chunk is exactly 8 times the size of that 128 KiB file, because the chunk data is not shared across 128 KiB boundaries.</p>
	<p>This brings up an interesting point: <strong>It’s beneficial to turn on compression even for filesystems with uncompressible data</strong><sup id="fnref:cks-1" role="doc-noteref"><a href="#fn:cks-1" class="footnote" rel="footnote">4</a></sup>. One direct impact is on the last block of a large file, where its zero-filled bytes up to <code class="language-plaintext highlighter-rouge">recordsize</code> compress very well. Using LZ4 or ZSTD, compression should have negligible impact on any reasonably modern CPU and reasonably sized disks.</p>
	<p>There are two more noteworthy points about compression, both from <a href="https://openzfs.github.io/openzfs-docs/man/master/7/zfsprops.7.html"><code class="language-plaintext highlighter-rouge">man zfsprops.7</code></a>:</p>
	<ol>
		<li>
			<blockquote>
				<p>When any setting except <strong>off</strong> is selected, compression will explicitly check for blocks consisting of only zeroes (the NUL byte). When a zero-filled block is detected, it is stored as a hole and not compressed using the indicated compression algorithm.</p>
			</blockquote>
			<p>Instead of compressing entire blocks of zeroes like the last block of a large file, ZFS will not store anything about these zero blocks. Technically, this is done by omitting the corresponding ranges from the file’s indirect blocks<sup id="fnref:cks-1:1" role="doc-noteref"><a href="#fn:cks-1" class="footnote" rel="footnote">4</a></sup>.</p>
			<p>Take this test for example: I created a file with 64 KiB of urandom, then 256 KiB of zeroes, then another 64 KiB of urandom. The file is 384 KiB in size, but only 128 KiB is actually stored on disk:</p>
			<div class="language-console highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="gp">#</span><span class="w"> </span>zfs create pool0/srv/test
<span class="gp">#</span><span class="w"> </span><span class="nb">cat</span> &lt;<span class="o">(</span><span class="nb">head</span> <span class="nt">-c</span> 64K /dev/urandom<span class="o">)</span> &lt;<span class="o">(</span><span class="nb">head</span> <span class="nt">-c</span> 256K /dev/zero<span class="o">)</span> &lt;<span class="o">(</span><span class="nb">head</span> <span class="nt">-c</span> 64K /dev/urandom<span class="o">)</span> <span class="o">&gt;</span> /srv/test/test
<span class="gp">#</span><span class="w"> </span><span class="nb">du</span> <span class="nt">-sh</span> /srv/test/test
<span class="go">145K    /srv/test/test
</span></code></pre>
				</div>
    </div>
			<p>We can also examine the file’s indirect blocks with <code class="language-plaintext highlighter-rouge">zdb</code>:</p>
			<div class="language-console highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="gp">#</span><span class="w"> </span><span class="nb">ls</span> <span class="nt">-li</span> /srv/test/test
<span class="go">2 -rw-r--r-- 1 root root 393216 Oct 30 02:05 /srv/test/test
</span><span class="gp">#</span><span class="w"> </span>zdb <span class="nt">-ddddd</span> pool0/srv/test 2
<span class="go">[...]
Indirect blocks:
               0 L1  0:1791b7d3000:1000 20000L/1000P F=2 B=9769680/9769680 cksum=[...]
               0  L0 0:1791b7b1000:11000 20000L/11000P F=1 B=9769680/9769680 cksum=[...]
           40000  L0 0:1791b7c2000:11000 20000L/11000P F=1 B=9769680/9769680 cksum=[...]

                segment [0000000000000000, 0000000000020000) size  128K
                segment [0000000000040000, 0000000000060000) size  128K
</span></code></pre>
				</div>
    </div>
			<p>Here we can see only two L0 blocks allocated, each being 20000 (hex, dec = 131072) bytes logical and 11000 (hex, dec = 69632) bytes physical in size. The two L0 blocks match the two segments shown at the bottom, with the middle segment nowhere to be found.</p>
		</li>
		<li>
			<blockquote>
				<p>Any block being compressed must be no larger than 7/8 of its original size after compression, otherwise the compression will not be considered worthwhile and the block saved uncompressed. […] for example, 8 KiB blocks on disks with 4 KiB disk sectors must compress to 1/2 or less of their original size.</p>
			</blockquote>
			<p>This one should be self-explanatory.</p>
		</li>
	</ol>
	<h2 id="raidz">RAIDZ</h2>
	<p>Up until now we’ve only talked about logical blocks, which are all on the higher layers of the ZFS hierarchy. RAIDZ is where physical blocks (disk sectors) really come into play and adds another field of confusion.</p>
	<p>Unlike traditional RAID 5/6/7<sup class="no-select">(?)</sup> that combine disks into an array and presents a single volume for the filesystem, RAIDZ handles each <em>logical block</em> separately. I’ll cite this illustration from Delphix<sup id="fnref:delphix" role="doc-noteref"><a href="#fn:delphix" class="footnote" rel="footnote">5</a></sup> to explain:</p>
	<figure class="">
		<img src="/image/zfs/raidz-block-layout.png" alt="RAID-Z block layout" />
		<figcaption>
			Figure 2. RAID-Z block layout
		</figcaption>
	</figure>
	<p>This example shows a 5-wide RAID-Z1 setup.</p>
	<ul>
		<li>A single-sector block takes another sector for parity, like the dark red block on row 3.</li>
		<li>
			<p>Multi-sector blocks are striped across disks, with parity sectors inserted every 4 sectors, matching the data-to-parity ratio of the vdev array.</p>
			<ul>
				<li>You may have noticed that parity sectors for the same block are always stored on the same disk that resembles RAID-4 instead of RAID-5. Keep in mind that ZFS reads, writes and verifies entire blocks, so interleaving parity sectors across disks will not provide any benefit, while keeping “stripes” on the same disk simplifies the logic for validation and reconstruction.</li>
			</ul>
		</li>
		<li>In order to avoid unusable fragments, ZFS requires each allocated block to be padded to a multiple of (<em>p+1</em>) sectors, where <em>p</em> is the number of parity disks. For example, RAID-Z1 requires each block to be padded to a multiple of 2 sectors, and RAID-Z2 requires each block to be padded to a multiple of 3 sectors. This can be seen on rows 7 to 9, where the X sectors are reserved for parity padding.</li>
	</ul>
	<p>This design allows RAID to play well with ZFS’s log-structured design and avoids the need for read-modify-write cycles. Consequently, the RAID overhead is now dependent on your data and is no longer an intrinsic property of the RAID level and array width. The same Delphix article shares a nice spreadsheet<sup id="fnref:delphix-spreadsheet" role="doc-noteref"><a href="#fn:delphix-spreadsheet" class="footnote" rel="footnote">6</a></sup> that calculates RAID overhead for you:</p>
	<p><a href="https://docs.google.com/a/delphix.com/spreadsheets/d/1tf4qx1aMJp8Lo_R6gpT689wTjHv6CGVElrPqTA0w_ZY/"><img src="/image/zfs/raidz1-parity-overhead.png" alt="Size of parity overhead for RAID-Z1" /></a></p>
	<h3 id="raidz-accounting">Accounting</h3>
	<p>Accounting the storage space for a RAIDZ array is as problematic as it seems: There’s no way to calculate the available space in advance without knowledge on the block size pattern.</p>
	<p>ZFS works around this by showing an estimate, assuming all data were stored as 128 KiB blocks<sup id="fnref:zfs-4599" role="doc-noteref"><a href="#fn:zfs-4599" class="footnote" rel="footnote">7</a></sup>. On my test setup with five 16 GiB disks in RAID-Z1 and <code class="language-plaintext highlighter-rouge">ashift=12</code>, the available space shows as 61.5G, while <code class="language-plaintext highlighter-rouge">zpool</code> shows the raw size as 79.5G:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">#</span><span class="w"> </span>zpool create <span class="nt">-o</span> <span class="nv">ashift</span><span class="o">=</span>12 <span class="nb">test </span>raidz1 nvme3n1p<span class="o">{</span>1,2,3,4,5<span class="o">}</span>
<span class="gp">#</span><span class="w"> </span>zfs list <span class="nb">test</span>
<span class="go">NAME   USED  AVAIL     REFER  MOUNTPOINT
test   614K  61.5G      153K  /test
</span><span class="gp">#</span><span class="w"> </span>zpool list <span class="nb">test</span>
<span class="go">NAME   SIZE  ALLOC   FREE  CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP    HEALTH  ALTROOT
test  79.5G   768K  79.5G        -         -     0%     0%  1.00x    ONLINE  -
</span></code></pre>
		</div>
	</div>
	<p>When I increase <code class="language-plaintext highlighter-rouge">ashift</code> to 15 (32 KiB sectors), the available space drops quite a bit, even if <code class="language-plaintext highlighter-rouge">zpool</code> shows the same raw size:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">#</span><span class="w"> </span>zpool create <span class="nt">-o</span> <span class="nv">ashift</span><span class="o">=</span>15 <span class="nb">test </span>raidz1 nvme3n1p<span class="o">{</span>1,2,3,4,5<span class="o">}</span>
<span class="gp">#</span><span class="w"> </span>zfs list <span class="nb">test</span>
<span class="go">NAME   USED  AVAIL     REFER  MOUNTPOINT
test  4.00M  51.3G     1023K  /test
</span><span class="gp">#</span><span class="w"> </span>zpool list <span class="nb">test</span>
<span class="go">NAME   SIZE  ALLOC   FREE  CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP    HEALTH  ALTROOT
test  79.5G  7.31M  79.5G        -         -     0%     0%  1.00x    ONLINE  -
</span></code></pre>
		</div>
	</div>
	<p>In both cases, calculating the “raw” disk space from the available space gives roughly congruent results:</p>
	<ul>
		<li>61.5 GiB × (1 + 25%) = 76.9 GiB</li>
		<li>51.3 GiB × (1 + 50%) = 76.9 GiB</li>
	</ul>
	<p>The default <code class="language-plaintext highlighter-rouge">refreservation</code> for non-sparse ZVOLs exhibits a similar behavior:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">#</span><span class="w"> </span>zfs create <span class="nt">-V</span> 4G <span class="nt">-o</span> <span class="nv">volblocksize</span><span class="o">=</span>8K <span class="nb">test</span>/v8k
<span class="gp">#</span><span class="w"> </span>zfs create <span class="nt">-V</span> 4G <span class="nt">-o</span> <span class="nv">volblocksize</span><span class="o">=</span>16K <span class="nb">test</span>/v16k
<span class="gp">#</span><span class="w"> </span>zfs get refreservation <span class="nb">test</span>/v8k <span class="nb">test</span>/v16k
<span class="go">NAME       PROPERTY        VALUE      SOURCE
test/v16k  refreservation  4.86G      local
test/v8k   refreservation  6.53G      local
</span></code></pre>
		</div>
	</div>
	<p>Interestingly, neither of the <code class="language-plaintext highlighter-rouge">refreservation</code> sizes matches the RAID overhead as calculated in the Delphix spreadsheet<sup id="fnref:delphix-spreadsheet:1" role="doc-noteref"><a href="#fn:delphix-spreadsheet" class="footnote" rel="footnote">6</a></sup>, as you would expect some 6.0 GiB for the 16k-volblocksized ZVOL and some 8.0 GiB for the 8k-volblocksized one. <strong>Let’s just don’t forget that the whole accounting system assumed 128 KiB blocks and scaled by that<sup id="fnref:acct-128k" role="doc-noteref"><a href="#fn:acct-128k" class="footnote" rel="footnote">8</a></sup>.</strong> So the actual meaning of 4.86G and 6.53G would be “the <em>equivalent</em> space if volblocksize had been 128 KiB”. If we multiply both values by 1.25 (overhead for 128 KiB blocks and 5-wide RAIDZ), we get 6.08 GiB and 8.16 GiB of raw disk spaces respectively, both of which match more closely the expected values. The final minor difference is due to the different amount of metadata required for different number of blocks.</p>
	<h2 id="thoughts">Thoughts</h2>
	<p>I never imagined I would delve this deep into ZFS when I first stumbled upon the question. There are lots of good write-ups on individual components of ZFS all around the web, and <a href="https://utcc.utoronto.ca/~cks/space/blog/">Chris Siebenmann’s blog</a> in particular. But few combine all the pieces together and paint the whole picture, so I had to spend some time synthesizing them by myself. As you’ve seen in the Luster slide, ZFS is so complex a beast that it’s hard to digest in its entirety. So for now I have no idea how much effort I would put into learning it, nor any future blogs I would write. But anyways, that’s one large mystery solved, for myself and my readers (you), and time to call it a day.</p>
	<h2 id="references">References</h2>
	<div class="footnotes" role="doc-endnotes">
		<ol>
			<li id="fn:dilger" role="doc-endnote">
				<p>Andreas Dilger (2010) <a href="https://wiki.lustre.org/images/4/49/Beijing-2010.2-ZFS_overview_3.1_Dilger.pdf">ZFS Features &amp; Concepts TOI</a> <a href="#fnref:dilger" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
			</li>
			<li id="fn:zfs101" role="doc-endnote">
				<p>Jim Salter (2020) <a href="https://arstechnica.com/information-technology/2020/05/zfs-101-understanding-zfs-storage-and-performance/">ZFS 101 – Understanding ZFS storage and performance</a> <a href="#fnref:zfs101" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
			</li>
			<li id="fn:tuning" role="doc-endnote">
				<p>OpenZFS <a href="https://openzfs.github.io/openzfs-docs/Performance%20and%20Tuning/Workload%20Tuning.html">Workload Tuning</a> <a href="#fnref:tuning" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
			</li>
			<li id="fn:cks-1" role="doc-endnote">
				<p>Chris Siebenmann (2017) <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFilePartialAndHoleStorage">ZFS’s recordsize, holes in files, and partial blocks</a> <a href="#fnref:cks-1" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:cks-1:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
			</li>
			<li id="fn:delphix" role="doc-endnote">
				<p>Matthew Ahrens (2014) <a href="https://www.delphix.com/blog/zfs-raidz-stripe-width-or-how-i-learned-stop-worrying-and-love-raidz">How I Learned to Stop Worrying and Love RAIDZ</a> <a href="#fnref:delphix" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
			</li>
			<li id="fn:delphix-spreadsheet" role="doc-endnote">
				<p><a href="https://docs.google.com/a/delphix.com/spreadsheets/d/1tf4qx1aMJp8Lo_R6gpT689wTjHv6CGVElrPqTA0w_ZY/">RAID-Z parity cost</a> (Google Sheets) <a href="#fnref:delphix-spreadsheet" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:delphix-spreadsheet:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
			</li>
			<li id="fn:zfs-4599" role="doc-endnote">
				<p>openzfs/zfs#4599 (2016) <a href="https://github.com/openzfs/zfs/issues/4599">disk usage wrong when using larger recordsize, raidz and ashift=12</a> <a href="#fnref:zfs-4599" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
			</li>
			<li id="fn:acct-128k" role="doc-endnote">
				<p>Mike Gerdts (2019) <a href="https://github.com/illumos/illumos-gate/blob/b73ccab03ec36581b1ae5945ef1fee1d06c79ccf/usr/src/lib/libzfs/common/libzfs_dataset.c#L5118">(Code comment in <code class="language-plaintext highlighter-rouge">libzfs_dataset.c</code>)</a> <a href="#fnref:acct-128k" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
			</li>
		</ol>
	</div>
	]]></content><author><name>iBug</name></author><category term="linux" /><category term="zfs" /><summary type="html"><![CDATA[ZFS is about the most complex filesystem for single-node storage servers. Coming with its sophistication is its equally confusing “block size”, which is normally self-evident on common filesystems like ext4 (or more primitively, FAT). The enigma continues as ZFS bundles more optimizations, either for performance or in the name of “intuition” (which I would hardly agree). So recently I read a lot of materials on this and try to make sense of it.]]></summary></entry><entry><title type="html">Debugging Proxmox VE Firewall Dropping TCP Reset Packets</title><link href="https://ibug.io/blog/2023/10/pve-firewall-drops-tcp-reset/" rel="alternate" type="text/html" title="Debugging Proxmox VE Firewall Dropping TCP Reset Packets" /><published>2023-10-06T00:00:00+00:00</published><updated>2023-10-06T13:37:51+00:00</updated><id>https://ibug.io/blog/2023/10/pve-firewall-drops-tcp-reset</id><content type="html" xml:base="https://ibug.io/blog/2023/10/pve-firewall-drops-tcp-reset/"><![CDATA[<p>A few days back when I was setting up a new VM to host some extra websites, I noticed an unexpected Nginx error page. As I don’t administer the new websites, I just added reverse proxy rules on the gateway Nginx server, and deferred the actual configuration to whoever is in charge of them.</p>
	<p>When I reviewed my edited Nginx configuration and tried visiting the new website, I received a 504 Gateway Timeout error after <code class="language-plaintext highlighter-rouge">curl</code> hung for a minute. Knowing that the web server had yet to be set up, I was expecting a 502 Bad Gateway error. I quickly recalled the conditions for Nginx to return these specific errors: 502 if the upstream server is immediately known down, and 504 if the upstream server is up but not responding.</p>
	<p>Since the actual web application hadn’t been set up yet, the new VM should have nothing listening on the configured ports. Consequently, the kernel should immediately respond with a TCP Reset for any incoming connections. To verify this, I ran <code class="language-plaintext highlighter-rouge">tcpdump</code> on both sides to check if the TCP reset packets actually came out. To my surprise, the packets were indeed sent out from the new VM, but the gateway server received nothing. So there was certainly something wrong with the firewall. I took a glance at the output of <code class="language-plaintext highlighter-rouge">pve-firewall compile</code>. They were very structured and adequately easy to understand, but I couldn’t immediately identify anything wrong. Things were apparently more complicated than I had previously anticipated.</p>
	<h2 id="searching">Searching for information</h2>
	<p>As usual, the first thing to try is Googling. Searching for <code class="language-plaintext highlighter-rouge">pve firewall tcp reset</code> brought <a href="https://forum.proxmox.com/threads/tcp-rst-packets-dropped-by-pve-firewall.56300/">this post on Proxmox Forum</a> as the first result. Their symptoms were precisely the same as mine:</p>
	<blockquote>
		<ul>
			<li>Assume we have a service running on TCP port 12354</li>
			<li>Clients can communicate with it while running</li>
			<li>While service is down, clients recieved “Connection timed out” (no answer) even if OS send TCP RST packets:</li>
		</ul>
		<p>[…]</p>
		<p>However, these RST packets are dropped somewhere in PVE firewall.<br />
			On the VM options :</p>
		<ul>
			<li>Firewall &gt; Options &gt; Firewall = No, Has no effect</li>
			<li>Firewall &gt; Options &gt; * Policy = ACCEPT, Has no effect (even with NO rule in active for this VM)</li>
			<li>Hardware &gt; Network Device &gt; <code class="language-plaintext highlighter-rouge">firewall=0</code>, allows packets RST to pass!</li>
		</ul>
	</blockquote>
	<p>I gave the last suggestion a try, and it worked! I could now see connections immediately reset on the gateway server, and Nginx started producing 502 errors. But I was still confused why this happened in the first place. The first thread contained nothing else useful, so I continued scanning through other search results and noticed <a href="https://forum.proxmox.com/threads/turning-on-the-pve-firewall-stops-vm-lxc-connectivity.55634/#post-261316">another post</a> about another seemingly unrelated problem, with a plausible solution:</p>
	<blockquote>
		<p>[…], and the fix was just to add the <code class="language-plaintext highlighter-rouge">nf_conntrack_allow_invalid: 1</code> in the <code class="language-plaintext highlighter-rouge">host.fw</code> for each node - I didn’t have to do anything other than that.</p>
	</blockquote>
	<p>That seemed understandable to me, so I gave it a try as well, and to my pleasure, it also worked.</p>
	<p>Regrettably, useful information ceased to exist online beyond this, and it was far from painting the whole picture. So anything further would have to be uncovered on my own.</p>
	<h2 id="reviewing">Reviewing information</h2>
	<p>I reviewed the two helpful workarounds and made myself abundantly clear about their effects:</p>
	<ul>
		<li>
			<p>Disabling the firewall on the virtual network device stops PVE from bridging the interface an extra time, as shown in the following diagram:</p>
			<p><img src="/image/pve-firewall/pve-fwbr.png" alt="PVE Firewall Diagram" /></p>
		</li>
		<li>
			<p>Adding <code class="language-plaintext highlighter-rouge">nf_conntrack_allow_invalid: 1</code> removes one single iptables rule:</p>
			<div class="language-shell highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="nt">-A</span> PVEFW-FORWARD <span class="nt">-m</span> conntrack <span class="nt">--ctstate</span> INVALID <span class="nt">-j</span> DROP
</code></pre>
				</div>
    </div>
		</li>
	</ul>
	<p>I couldn’t figure out how the first difference was relevant, but the second one provided an important clue: The firewall was dropping TCP Reset packets because conntrack considered them invalid.</p>
	<p>Conntrack (<strong>conn</strong>ection <strong>track</strong>ing) is a Linux kernel subsystem that tracks network connections and aids in stateful packet inspection and network address translation. The first packet of a connection is considered “NEW”, and subsequent packets from the same connection are considered “ESTABLISHED”, including the TCP Reset packet when it’s first seen, which causes conntrack to delete the connection entry.</p>
	<p>There was still yet anything obvious, so time to start debugging.</p>
	<h2 id="tcpdump">Inspecting packet captures</h2>
	<p>I ran <code class="language-plaintext highlighter-rouge">tcpdump -ni any host 172.31.0.2 and host 172.31.1.11 and tcp</code> on the PVE host to capture packets between the two VMs. This is what I got (output trimmed):</p>
	<div class="language-text highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>tcpdump: data link type LINUX_SLL2
tcpdump: verbose output suppressed, use -v[v]... for full protocol decode
listening on any, link-type LINUX_SLL2 (Linux cooked v2), snapshot length 262144 bytes
16:33:11.911184 veth101i1 P   IP 172.31.0.2.50198 &gt; 172.31.1.11.80: Flags [S], seq 3404503761, win 64240
16:33:11.911202 fwln101i1 Out IP 172.31.0.2.50198 &gt; 172.31.1.11.80: Flags [S], seq 3404503761, win 64240
16:33:11.911203 fwpr101p1 P   IP 172.31.0.2.50198 &gt; 172.31.1.11.80: Flags [S], seq 3404503761, win 64240
16:33:11.911206 fwpr811p0 Out IP 172.31.0.2.50198 &gt; 172.31.1.11.80: Flags [S], seq 3404503761, win 64240
16:33:11.911207 fwln811i0 P   IP 172.31.0.2.50198 &gt; 172.31.1.11.80: Flags [S], seq 3404503761, win 64240
16:33:11.911213 tap811i0  Out IP 172.31.0.2.50198 &gt; 172.31.1.11.80: Flags [S], seq 3404503761, win 64240
16:33:11.911262 tap811i0  P   IP 172.31.1.11.80 &gt; 172.31.0.2.50198: Flags [R.], seq 0, ack 3404503762, win 0, length 0
16:33:11.911267 fwln811i0 Out IP 172.31.1.11.80 &gt; 172.31.0.2.50198: Flags [R.], seq 0, ack 1, win 0, length 0
16:33:11.911269 fwpr811p0 P   IP 172.31.1.11.80 &gt; 172.31.0.2.50198: Flags [R.], seq 0, ack 1, win 0, length 0
^C
9 packets captured
178 packets received by filter
0 packets dropped by kernel
</code></pre>
		</div>
	</div>
	<p><img src="/image/pve-firewall/fw-diagram-1.png" alt="Diagram" /></p>
	<p>The first thing to notice is the ACK number. After coming from <code class="language-plaintext highlighter-rouge">tap811i0</code>, it suddenly became 1 with no apparent reason. I struggled on this for a good while and temporarily put it aside.</p>
	<p>Adding <code class="language-plaintext highlighter-rouge">nf_conntrack_allow_invalid: 1</code> to the firewall options and capturing packets again, I got the following:</p>
	<div class="language-text highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>listening on any, link-type LINUX_SLL2 (Linux cooked v2), snapshot length 262144 bytes
16:46:15.243002 veth101i1 P   IP 172.31.0.2.58784 &gt; 172.31.1.11.80: Flags [S], seq 301948896, win 64240
16:46:15.243015 fwln101i1 Out IP 172.31.0.2.58784 &gt; 172.31.1.11.80: Flags [S], seq 301948896, win 64240
16:46:15.243016 fwpr101p1 P   IP 172.31.0.2.58784 &gt; 172.31.1.11.80: Flags [S], seq 301948896, win 64240
16:46:15.243020 fwpr811p0 Out IP 172.31.0.2.58784 &gt; 172.31.1.11.80: Flags [S], seq 301948896, win 64240
16:46:15.243021 fwln811i0 P   IP 172.31.0.2.58784 &gt; 172.31.1.11.80: Flags [S], seq 301948896, win 64240
16:46:15.243027 tap811i0  Out IP 172.31.0.2.58784 &gt; 172.31.1.11.80: Flags [S], seq 301948896, win 64240
16:46:15.243076 tap811i0  P   IP 172.31.1.11.80 &gt; 172.31.0.2.58784: Flags [R.], seq 0, ack 301948897, win 0, length 0
16:46:15.243081 fwln811i0 Out IP 172.31.1.11.80 &gt; 172.31.0.2.58784: Flags [R.], seq 0, ack 1, win 0, length 0
16:46:15.243083 fwpr811p0 P   IP 172.31.1.11.80 &gt; 172.31.0.2.58784: Flags [R.], seq 0, ack 1, win 0, length 0
16:46:15.243086 fwpr101p1 Out IP 172.31.1.11.80 &gt; 172.31.0.2.58784: Flags [R.], seq 0, ack 1, win 0, length 0
16:46:15.243087 fwln101i1 P   IP 172.31.1.11.80 &gt; 172.31.0.2.58784: Flags [R.], seq 0, ack 1, win 0, length 0
16:46:15.243090 veth101i1 Out IP 172.31.1.11.80 &gt; 172.31.0.2.58784: Flags [R.], seq 0, ack 1, win 0, length 0
^C
</code></pre>
		</div>
	</div>
	<p><img src="/image/pve-firewall/fw-diagram-2.png" alt="Diagram" /></p>
	<p>This time while the ACK number was still wrong, the RST packet somehow got through. Ignoring the ACK numbers for now, the output suggested that the RST packet was dropped between <code class="language-plaintext highlighter-rouge">fwpr811p0 P</code> and <code class="language-plaintext highlighter-rouge">fwln811i0 Out</code>. That was the main bridge <code class="language-plaintext highlighter-rouge">vmbr0</code>. All right then, that was where the <code class="language-plaintext highlighter-rouge">PVEFW-FORWARD</code> chain kicked in, so at this point the RST packet was <code class="language-plaintext highlighter-rouge">--ctstate INVALID</code>. Everything was logical so far.</p>
	<p>So how about disabling firewall for the interface on VM 811?</p>
	<div class="language-text highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>listening on any, link-type LINUX_SLL2 (Linux cooked v2), snapshot length 262144 bytes
17:19:01.812030 veth101i1 P   IP 172.31.0.2.39734 &gt; 172.31.1.11.80: Flags [S], seq 1128018611, win 64240
17:19:01.812045 fwln101i1 Out IP 172.31.0.2.39734 &gt; 172.31.1.11.80: Flags [S], seq 1128018611, win 64240
17:19:01.812046 fwpr101p1 P   IP 172.31.0.2.39734 &gt; 172.31.1.11.80: Flags [S], seq 1128018611, win 64240
17:19:01.812051 tap811i0  Out IP 172.31.0.2.39734 &gt; 172.31.1.11.80: Flags [S], seq 1128018611, win 64240
17:19:01.812178 tap811i0  P   IP 172.31.1.11.80 &gt; 172.31.0.2.39734: Flags [R.], seq 0, ack 1128018612, win 0, length 0
17:19:01.812183 fwpr101p1 Out IP 172.31.1.11.80 &gt; 172.31.0.2.39734: Flags [R.], seq 0, ack 1, win 0, length 0
17:19:01.812185 fwln101i1 P   IP 172.31.1.11.80 &gt; 172.31.0.2.39734: Flags [R.], seq 0, ack 1, win 0, length 0
17:19:01.812190 veth101i1 Out IP 172.31.1.11.80 &gt; 172.31.0.2.39734: Flags [R.], seq 0, ack 1, win 0, length 0
^C
</code></pre>
		</div>
	</div>
	<p><img src="/image/pve-firewall/fw-diagram-3.png" alt="Diagram" /></p>
	<p>This time <code class="language-plaintext highlighter-rouge">fwbr811i0</code> was missing, and the RST packet didn’t get dropped at <code class="language-plaintext highlighter-rouge">vmbr0</code>. I was left totally confused.</p>
	<p>I decided to sort out the ACK number issue, but ended up asking my friends for help. It turned out this was well documented in <code class="language-plaintext highlighter-rouge">tcpdump(8)</code>:</p>
	<blockquote>
		<p><code class="language-plaintext highlighter-rouge">-S</code><br />
			<code class="language-plaintext highlighter-rouge">--absolute-tcp-sequence-numbers</code><br />
			Print absolute, rather than relative, TCP sequence numbers.</p>
	</blockquote>
	<p>This certainly came out unexpected, but at least I was assured there was nothing wrong with the ACK numbers.</p>
	<p>Up to now, that’s one more step forward, and a small conclusion:</p>
	<ul>
		<li>At the point the RST packet reached <code class="language-plaintext highlighter-rouge">vmbr0</code>, it was already <code class="language-plaintext highlighter-rouge">--ctstate INVALID</code>.</li>
	</ul>
	<p>But how? As far as I knew, when the RST packet came out, it should still be considered part of the connection, and thus should be <code class="language-plaintext highlighter-rouge">--ctstate ESTABLISHED</code>. I was still missing something.</p>
	<p>Time to investigate conntrack.</p>
	<h2 id="conntrack">Inspecting conntrack</h2>
	<p><code class="language-plaintext highlighter-rouge">conntrack</code> is the tool to inspect and modify conntrack entries. I ran <code class="language-plaintext highlighter-rouge">conntrack -L</code> to list all entries, only to realize it’s inefficient. So instead, I ran <code class="language-plaintext highlighter-rouge">conntrack -E</code> to watch for “events” in real time, so that I could compare the output with <code class="language-plaintext highlighter-rouge">tcpdump</code>. Except that the entire connection concluded so quickly that I couldn’t identify anything.</p>
	<p>I had to add artificial delays to the packets to clearly separate each hop that the RST packet goes through:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>tc qdisc add dev tap811i0 root netem delay 200ms
tc qdisc add dev fwln811i0 root netem delay 200ms
</code></pre>
		</div>
	</div>
	<p>I also tuned the output on both sides to show the timestamp in a consistent format. For conntrack, <code class="language-plaintext highlighter-rouge">-o timestamp</code> produced Unix timestamps (which is the only supported format), so for <code class="language-plaintext highlighter-rouge">tcpdump</code> I also resorted to <code class="language-plaintext highlighter-rouge">-tt</code> to show Unix timestamps as well.</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>conntrack <span class="nt">-E</span> <span class="nt">-o</span> timestamp <span class="nt">-s</span> 172.31.0.2 <span class="nt">-d</span> 172.31.1.11
tcpdump <span class="nt">-ttSni</span> any host 172.31.0.2 and host 172.31.1.11 and tcp
</code></pre>
		</div>
	</div>
	<p>Now I could watch the outputs on two separate tmux panes. The problem immediately emerged (blank lines added for readability):</p>
	<div class="language-text highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>listening on any, link-type LINUX_SLL2 (Linux cooked v2), snapshot length 262144 bytes
1696412047.886575 veth101i1 P   IP 172.31.0.2.47066 &gt; 172.31.1.11.80: Flags [S]
1696412047.886592 fwln101i1 Out IP 172.31.0.2.47066 &gt; 172.31.1.11.80: Flags [S]
1696412047.886594 fwpr101p1 P   IP 172.31.0.2.47066 &gt; 172.31.1.11.80: Flags [S]
1696412047.886599 fwpr811p0 Out IP 172.31.0.2.47066 &gt; 172.31.1.11.80: Flags [S]
1696412047.886600 fwln811i0 P   IP 172.31.0.2.47066 &gt; 172.31.1.11.80: Flags [S]

1696412048.086620 tap811i0  Out IP 172.31.0.2.47066 &gt; 172.31.1.11.80: Flags [S]
1696412048.086841 tap811i0  P   IP 172.31.1.11.80 &gt; 172.31.0.2.47066: Flags [R.]

1696412048.286919 fwln811i0 Out IP 172.31.1.11.80 &gt; 172.31.0.2.47066: Flags [R.]
1696412048.286930 fwpr811p0 P   IP 172.31.1.11.80 &gt; 172.31.0.2.47066: Flags [R.]
^C
</code></pre>
		</div>
	</div>
	<div class="language-text highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>[1696412047.886657]         [NEW] tcp      6 120 SYN_SENT src=172.31.0.2 dst=172.31.1.11 sport=47066 dport=80 [UNREPLIED] src=172.31.1.11 dst=172.31.0.2 sport=80 dport=47066
[1696412048.086899]     [DESTROY] tcp      6 119 CLOSE src=172.31.0.2 dst=172.31.1.11 sport=47066 dport=80 [UNREPLIED] src=172.31.1.11 dst=172.31.0.2 sport=80 dport=47066
</code></pre>
		</div>
	</div>
	<p>The artificial delays and the timestamps were absolutely useful: It was clear that the corresponding conntrack connection was destroyed as soon as the RST packet passed through <code class="language-plaintext highlighter-rouge">fwbr811i0</code>, before it came out via <code class="language-plaintext highlighter-rouge">fwln811i0</code>. When it reached <code class="language-plaintext highlighter-rouge">vmbr0</code>, the connection was already gone, and the RST packet was considered invalid.</p>
	<p><img src="/image/pve-firewall/fw-diagram-4.png" alt="Diagram" /></p>
	<p>It also became explainable how <code class="language-plaintext highlighter-rouge">firewall=0</code> on the virtual network device remedied the issue: It removed an extra bridge <code class="language-plaintext highlighter-rouge">fwbr811i0</code>, so the connection stayed alive when the RST packet reached <code class="language-plaintext highlighter-rouge">vmbr0</code>, at which point a previous rule for <code class="language-plaintext highlighter-rouge">--ctstate ESTABLISHED</code> gave an <code class="language-plaintext highlighter-rouge">ACCEPT</code> verdict. While it was still <code class="language-plaintext highlighter-rouge">INVALID</code> when passing through <code class="language-plaintext highlighter-rouge">fwbr101i1</code>, there was no rule concerning <code class="language-plaintext highlighter-rouge">--ctstate</code> at play, so it slipped through this stage with no problem.</p>
	<p>After double-checking the intention of the extra <code class="language-plaintext highlighter-rouge">fwbr*</code> bridge, I drew the conclusion that <strong>this must be a bug with PVE Firewall</strong>. I reported it on the Proxmox VE bug tracker as <a href="https://bugzilla.proxmox.com/show_bug.cgi?id=4983">#4983</a>, and soon received a reply:</p>
	<blockquote>
		<p>Thank you for the detailed write-up!</p>
		<p>This is a known limitation for our kind of firewall setup, since the conntrack is shared between all interfaces on the host.</p>
		<p>[…]</p>
		<p>If you know of any other way to avoid this happening, other than using conntrack zones, I’d be happy to take a look.</p>
	</blockquote>
	<p>So they admitted that this was a limitation but without a satisfactory solution. Guess I’m still on my own, though.</p>
	<h2 id="solution">Finding the solution</h2>
	<p>The actual problem is, when passing through <code class="language-plaintext highlighter-rouge">fwbr811i0</code>, the RST packet isn’t supposed to be processed by conntrack by then. There is no <code class="language-plaintext highlighter-rouge">sysctl</code> option to disable conntrack on a specific interface (or even just all bridges altogether), but at the right time the rarely-used <code class="language-plaintext highlighter-rouge">raw</code> table came to my mind. It didn’t take long to work this out:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>iptables <span class="nt">-t</span> raw <span class="nt">-A</span> PREROUTING <span class="nt">-i</span> fwbr+ <span class="nt">-j</span> CT <span class="nt">--notrack</span>
</code></pre>
		</div>
	</div>
	<p>After verifying this is the intended solution, I added it as a reply to the bug report. At the time of writing this blog post, the bug report is still open, but I’m sure it’s to be resolved soon.</p>
	<h2 id="conclusion">Conclusion</h2>
	<p>Debugging Linux networking has always been a pain for its lack of proper tools and its complexity. Most of the times even reading and understanding packet captures requires immense knowledge of the protocols and all the involved components, as well as scrutinizing every single detail available. Sometimes it’s even necessary to think outside the box but fortunately not today.</p>
	<p>Also worth mentioning is that it’s easy to suspect the fault of another piece of software, but detailed investigation is always necessary to actually lay the blame.</p>
	<p>Just as a late reminder, useful bug reports always require detailed information and solid evidence. Glad I was able to have them at hand this time.</p>
	]]></content><author><name>iBug</name></author><category term="linux" /><category term="networking" /><category term="proxmox-ve" /><summary type="html"><![CDATA[A few days back when I was setting up a new VM to host some extra websites, I noticed an unexpected Nginx error page. As I don’t administer the new websites, I just added reverse proxy rules on the gateway Nginx server, and deferred the actual configuration to whoever is in charge of them.]]></summary></entry><entry><title type="html">Running a dual-protocol OpenVPN/WireGuard VPN server on one port</title><link href="https://ibug.io/blog/2023/09/dual-protocol-vpn-port/" rel="alternate" type="text/html" title="Running a dual-protocol OpenVPN/WireGuard VPN server on one port" /><published>2023-09-26T00:00:00+00:00</published><updated>2023-09-26T14:26:49+00:00</updated><id>https://ibug.io/blog/2023/09/dual-protocol-vpn-port</id><content type="html" xml:base="https://ibug.io/blog/2023/09/dual-protocol-vpn-port/"><![CDATA[<p>Public Wi-Fi and some campus network typically block traffic from unauthenticated clients, but more often allow traffic targeting UDP port 53 to pass through, which is normally used for DNS queries. This feature can be exploited to bypass authentication by connecting to a VPN server that’s also running on UDP 53.</p>
	<p>In previous times, OpenVPN was the general preference for personal VPN services. Since the emergence of WireGuard, however, popularity has shifted significantly for its simplicity and performance. A challenge presents itself as there’s only one UDP port numbered 53, making it seemingly impossible to run both OpenVPN and WireGuard on the same port.</p>
	<p>There solution hinges itself on a little bit of insights.</p>
	<h2 id="inspiration">Inspiration</h2>
	<p>In a similar situation, many local proxy software like Shadowsocks and V2ray support a feature called “mixed mode”, which accepts both HTTP and SOCKS5 connections on the same TCP port. This also seems impossible at first glance, but with a bit of knowledge in both protocols, it’s actually easy to pull it off.</p>
	<ul>
		<li>An HTTP proxy request, just like other HTTP requests, begins with an HTTP verb. In proxy requests, it’s either <code class="language-plaintext highlighter-rouge">GET</code> or <code class="language-plaintext highlighter-rouge">CONNECT</code>,</li>
		<li>A SOCKS proxy request begins with a 1-byte header containing its version, which is <code class="language-plaintext highlighter-rouge">0x04</code> for SOCKS4 or <code class="language-plaintext highlighter-rouge">0x05</code> for SOCKS5.</li>
	</ul>
	<p>Now there’s a clear line between the two protocols, and we can identify them by looking at the first byte of the request. This is how most proxy implementations work, like <a href="https://github.com/3proxy/3proxy/commit/fb56b7d307a7bce1f2109c73864bad7c71716f3b#diff-e268b23274bc9df1b2c0957dfa85d684519282ed611f6135e795205e53fb6e3b">3proxy</a> and <a href="https://github.com/nadoo/glider/blob/4f12a4f3082940d8a4c56ba4f06f02a72d90d5d6/proxy/mixed/mixed.go#L84">glider</a>.</p>
	<p>So the question is, is there a similar trait between OpenVPN and WireGuard? The answer is, as you would expect, yes.</p>
	<h2 id="protocols">Protocols</h2>
	<p>WireGuard runs over UDP and defines 4 packet types: 3 for handshake and 1 for data. All 4 packet types share the same 4-byte <a href="https://github.com/WireGuard/wireguard-linux/blob/fa41884c1c6deb6774135390e5813a97184903e0/drivers/net/wireguard/messages.h#L65">header</a>:</p>
	<div class="language-rust highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">struct</span> <span class="n">message_header</span> <span class="p">{</span>
    <span class="nb">u8</span> <span class="k">type</span><span class="p">;</span>
    <span class="nb">u8</span> <span class="n">reserved_zero</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>
<span class="p">}</span>
</code></pre>
		</div>
	</div>
	<p>Similarly, all OpenVPN packet types share the same 1-byte <a href="https://build.openvpn.net/doxygen/network_protocol.html#network_protocol_external_types">header</a>:</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">struct</span> <span class="n">header_byte</span> <span class="p">{</span>
    <span class="kt">uint8_t</span> <span class="n">opcpde</span> <span class="o">:</span> <span class="mi">5</span><span class="p">;</span>
    <span class="kt">uint8_t</span> <span class="n">key_id</span> <span class="o">:</span> <span class="mi">3</span><span class="p">;</span>
<span class="p">}</span>
</code></pre>
		</div>
	</div>
	<p>It’s worth noting that 0 is not a defined opcode, so the smallest valid value for this byte is 8, as <code class="language-plaintext highlighter-rouge">key_id</code> can be anything from 0 to 7.</p>
	<h2 id="implementation">Implementation</h2>
	<p>Now that we have the packet format for both protocols understood, we can implement a classifier that filters traffic in one protocol from the other.</p>
	<p>Considering that the WireGuard packet format is much simpler than that of OpenVPN, I choose to identify WireGuard. With kernel firewall <code class="language-plaintext highlighter-rouge">iptables</code>, options are abundant, though I find <code class="language-plaintext highlighter-rouge">u32</code> the easiest:</p>
	<div class="language-sh highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">*</span>nat
:iBugVPN - <span class="o">[</span>0:0]
<span class="nt">-A</span> PREROUTING <span class="nt">-m</span> addrtype <span class="nt">--dst-type</span> LOCAL <span class="nt">-p</span> udp <span class="nt">--dport</span> 53 <span class="nt">-j</span> iBugVPN
<span class="nt">-A</span> iBugVPN <span class="nt">-m</span> u32 <span class="nt">--u32</span> <span class="s2">"25 &amp; 0xFF = 1:4 &amp;&amp; 28 &amp; 0xFFFFFF = 0"</span> <span class="nt">-j</span> REDIRECT <span class="nt">--to-port</span> 51820
<span class="nt">-A</span> iBugVPN <span class="nt">-j</span> REDIRECT <span class="nt">--to-port</span> 1194
COMMIT
</code></pre>
		</div>
	</div>
	<p>With both OpenVPN and WireGuard running on their standard ports, this will redirect each protocol to its respective service port. While these rules only operate on the initial packet, Linux conntrack will handle the rest of the connection.</p>
	<p>The <code class="language-plaintext highlighter-rouge">u32</code> match is explained:</p>
	<ul>
		<li>Basic syntax: <code class="language-plaintext highlighter-rouge">&lt;offset&gt; [operators...] = &lt;range&gt;</code>, where <code class="language-plaintext highlighter-rouge">&lt;offset&gt;</code> is relative to the IP header. For UDP over IPv4, the application payload starts from 28 (20 bytes of IPv4 and 8 bytes of UDP)</li>
		<li><code class="language-plaintext highlighter-rouge">25 &amp; 0xFF = 1:4</code>: The 28th byte is in range <code class="language-plaintext highlighter-rouge">1:4</code>.</li>
		<li><code class="language-plaintext highlighter-rouge">28 &amp; 0xFFFFFF = 0</code>: The 29th to 31th bytes are all zero.</li>
	</ul>
	<p>For IPv6, you just need to increase the offset by 20 (IPv6 header is 40 bytes), so the rule becomes <code class="language-plaintext highlighter-rouge">45 &amp; 0xFF = 1:4 &amp;&amp; 48 &amp; 0xFFFFFF = 0</code>.</p>
	<p>This VPN server is running like a hearse so proofs are left out for brevity.</p>
	]]></content><author><name>iBug</name></author><category term="linux" /><category term="networking" /><summary type="html"><![CDATA[Public Wi-Fi and some campus network typically block traffic from unauthenticated clients, but more often allow traffic targeting UDP port 53 to pass through, which is normally used for DNS queries. This feature can be exploited to bypass authentication by connecting to a VPN server that’s also running on UDP 53.]]></summary></entry><entry><title type="html">Vlab 远程教学云桌面</title><link href="https://ibug.io/blog/2023/08/nju-talk/" rel="alternate" type="text/html" title="Vlab 远程教学云桌面" /><published>2023-08-19T00:00:00+00:00</published><updated>2024-01-08T04:40:54+00:00</updated><id>https://ibug.io/blog/2023/08/nju-talk</id><content type="html" xml:base="https://ibug.io/blog/2023/08/nju-talk/"><![CDATA[<section id="title">
		<h1 class="title">Vlab<br>
			远程教学云桌面</h1>
		<p class="date">iBug @ USTC</p>
		<p class="date">2023 年 8 月 19 日<br />
			南京大学</p>
	</section>
	<section id="cover-image">
		<style>
			:root {
			  --r-heading-font-weight: bold;
			}

			.slides section {
			  max-height: 100%;
			}

			li img {
			  vertical-align: middle;
			}

			li+li {
			  margin-top: 0.25em;
			}

			.img-container {
			  width: 100%;
			  height: 100%;

			  display: flex;
			  flex-direction: column;
			  justify-content: center;
			}

			.img-container img {
			  display: block;
			  max-height: 100%;
			  margin: auto !important;
			  object-fit: contain;
			}

			.reveal section>img {
			  display: block;
			  margin: auto !important;
			  max-height: 95vh;
			}

			.border {
			  border: 1px solid black;
			}
		</style>
		<div class="img-container">
			<img src="https://image.ibugone.com/vlab/vlab-in-browser.jpg" />
		</div>
	</section>
	<section id="目录">
		<h2>目录</h2>
		<ol type="1">
			<li>背景</li>
			<li>第一代 Vlab</li>
			<li>第二代 Vlab</li>
			<li>技术分享</li>
			<li>共享灵车</li>
			<li>成果</li>
		</ol>
	</section>
	<section>
		<section id="background">
			<h2>背景</h2>
			<p>计算机实验的环境配置问题：</p>
			<ul>
				<li>学校机房开放时间有限，利用率低</li>
				<li>部分实验软件体积大、对配置要求高（如 Vivado）</li>
				<li>学生使用的系统环境不同，导致安装与使用时出现奇怪的问题</li>
				<li>部分实验环境安装时容易损坏（如双系统安装）</li>
			</ul>
		</section>
		<section id="background-idea">
			<h2>思考</h2>
			<p>能不能通过提供预先配置好实验环境的虚拟机来解决这个问题呢？</p>
			<ul>
				<li>Linux 虚拟机还是 Windows 虚拟机？</li>
				<li>实验软件怎么配？</li>
				<li>给学生分配多少系统资源？主机需要多少硬件配置？</li>
				<li>单位支持：计算机实验教学中心</li>
			</ul>
		</section>
	</section>
	<section>
		<section id="1st-gen">
			<h2>第一代 Vlab</h2>
			<ul>
				<li>2019 年暑假搭建完成<br />
					秋季学期小范围运营</li>
				<li>接入校园网，提供 VNC 连接</li>
				<li>打包虚拟机镜像预装 Vivado 方便实验</li>
			</ul>
		</section>
		<section id="1st-gen-features">
			<h3>平台特点</h3>
			<ul>
				<li>单台 E5 2630 v4 (2S)，<s>64</s> 128 GB 内存，一些固态和机械</li>
				<li>Ubuntu 18.04 + 3.10.0-957.el7🤔 + LXD snap</li>
				<li>lxdbr0 ↔ USTCnet</li>
			</ul>
			<hr />
			<ul>
				<li>校园网接入：可以使用网络通选择出口或从校外连接
					<ul>
						<li><s>也可以挂 Minecraft 服务器、Terraria 服务器、……</s></li>
					</ul>
				</li>
				<li>虚拟机镜像：(Ubuntu 1 GB) + Xfce4 (2 GB) + Vivado (<b>18 GB</b>)
					<ul>
						<li>好在单机有 ZFS 可以用</li>
					</ul>
				</li>
				<li>用 Django 糊了个面板（@taoky），使用统一身份认证登录</li>
			</ul>
		</section>
		<section id="1st-gen-sumup">
			<h3>总结经验</h3>
			<ul>
				<li><s>一台母鸡超卖也卖不动多少啊</s></li>
				<li>避免将用户虚拟机直接连接在校园网上
					<ul>
						<li>这样既不方便使用，也不安全</li>
						<li>机房 IP 早晚会不够用的（3× /24）</li>
						<li>开个 NAT</li>
					</ul>
				</li>
				<li>提供桌面和命令行的统一登录接口，方便用户连接使用</li>
				<li>配备更多实验软件</li>
				<li>完善用户文档</li>
			</ul>
		</section>
	</section>
	<section>
		<section id="2nd-gen">
			<h2>第二代 Vlab</h2>
			<ul>
				<li>2020 年寒假基本配置完成<br />
					春季学期投入使用</li>
				<li>改进了第一代 Vlab 的许多不足点</li>
			</ul>
		</section>
		<section id="2nd-gen-infrastructure">
			<h3>基础设施</h3>
			<ul>
				<li>采购：HPE MSA 1050，Gen10 节点 ×8, 251 交换机</li>
				<li>Ubuntu ❌ Proxmox VE ✔</li>
				<li>iSCSI 存储共享：LVM（no thin provisioning）</li>
				<li>网络：VXLAN、NAT 网关</li>
				<li><s>小修小补的</s> Django 面板</li>
				<li>超卖能力++++</li>
			</ul>
		</section>
		<section id="2nd-gen-network">
			<div class="img-container">
				<img src="https://image.ibugone.com/vlab/network-external-1.png" />
			</div>
		</section>
		<section id="2nd-gen-network-internal">
			<div class="img-container">
				<img src="https://image.ibugone.com/vlab/network-internal.png" />
			</div>
		</section>
		<section id="gateway">
			<h3>年轻人的第一次卵路由实践</h3>
			<ul>
				<li>基础功能：为虚拟机提供 NAT 上网</li>
				<li>基本操作：Debian LXC + 手搓 iproute2 + iptables（其实也没那么复杂）</li>
				<li>DNS + 监控：AdGuard Home</li>
				<li>流量记录：<code>-m conntrack --ctstate NEW -j NFLOG</code>
					<ul>
						<li>没有磁带，不宜全量镜像</li>
					</ul>
				</li>
			</ul>
		</section>
		<section id="lxc-build">
			<h3>稳定可靠的 LXC 镜像构建技术</h3>
			<ul>
				<li>Docker 提供 build environment，PVE 提供 base image</li>
				<li>基于 shell 脚本和 GitHub Actions 的自动化流程
					<ul>
						<li><code>add_file</code>, <code>add_package</code>, <code>run</code> 等“指令”</li>
						<li><s>就差发明一个 <code>Lxcfile</code> DSL 了</s></li>
					</ul>
				</li>
				<li>Repository：<a href="https://github.com/USTC-vlab/labstrap"><i class="fab fa-github"></i>
						USTC-vlab/labstrap</a>
					<ul>
						<li>精神前辈：图书馆查询🐔的 PXE 镜像构建：<a href="https://github.com/ustclug/liimstrap"><i class="fab fa-github"></i>
								ustclug/liimstrap</a></li>
					</ul>
				</li>
			</ul>
		</section>
	</section>
	<section>
		<section id="login">
			<h2>登录方式</h2>
			<p>不开放端口，各种协议都需要转发</p>
			<p>VNC, SSH, and what?</p>
		</section>
		<section id="login-ssh-1">
			<h3>SSH 统一登录</h3>
			<ul>
				<li>SSH 没有 Host header 怎么办：来点 PubkeyAuthentication</li>
				<li><code>ssh <b>-i vm-114514.pem</b> ubuntu@vlab.ustc.edu.cn</code></li>
				<li>鉴权：就像 GitHub / GitLab 一样直接按公钥区分用户（VM）
					<ul>
						<li>Django 提供一个 pubkey → VM IP address 的接口</li>
					</ul>
				</li>
				<li>后端：<code>golang.org/x/crypto/ssh</code>
					<ul>
						<li>初版：Forked from <a href="https://github.com/tg123/sshpiper"><i class="fab fa-github"></i>
								tg123/sshpiper</a></li>
						<li>现在：<a href="https://github.com/USTC-vlab/sshmux"><i class="fab fa-github"></i> USTC-vlab/sshmux</a>
						</li>
						<li>sshpiper 重构了，不好用了 QwQ</li>
					</ul>
				</li>
			</ul>
		</section>
		<section id="login-ssh-2">
			<h3>SSH 统一登录</h3>
			<ul>
				<li>恢复模式（LXC）：<code>ssh <b>recovery</b>@vlab.ustc.edu.cn</code>
					<ul>
						<li>后台转接到 <code>pct enter &lt;vmid&gt;</code></li>
					</ul>
				</li>
				<li>控制台模式（LXC）：<code>ssh <b>console</b>@vlab.ustc.edu.cn</code>
					<ul>
						<li>后台转接到 <code>pct console &lt;vmid&gt;</code></li>
					</ul>
				</li>
				<li>控制台模式（KVM）：<code>ssh <b>serial</b>@vlab.ustc.edu.cn</code>
					<ul>
						<li>后台转接到 <code>qm serial &lt;vmid&gt;</code></li>
					</ul>
				</li>
			</ul>
		</section>
		<section id="login-vnc-1">
			<h3>VNC 统一登录</h3>
			<ul>
				<li>请出神仙：<a href="https://github.com/pdlan"><i class="fab fa-github"></i> pdlan</a>
					<ul>
						<li>逆向了 RealVNC，写了 10,000 行 C艹，到处 <code>co_await</code>，……</li>
						<li>顺带还实现了 TLS 加密</li>
						<li>顺带还实现了……</li>
						<li>外加一个 unix-domain socket 发送管理指令</li>
					</ul>
				</li>
				<li><s>一起来大受震撼吧</s></li>
				<li>使用 VNC 软件连接：
					<ul>
						<li>服务器：<code>vlab.ustc.edu.cn</code>（标准端口 5900/tcp）</li>
						<li>用户名：<code>PB17000001:114514</code>（用户名 + VM ID，如果用户有多个 VM 的话）</li>
					</ul>
				</li>
			</ul>
		</section>
		<section id="login-vnc-2">
			<h3>VNC 统一登录</h3>
			<ul>
				<li>开源贡献：</li>
				<li>
					<img src="https://image.ibugone.com/vlab/tigervnc-pr-pdlan.png" />
					<img src="https://image.ibugone.com/vlab/novnc-pr-pdlan.png" />
				</li>
			</ul>
		</section>
		<section id="login-rdp">
			<h3>RDP 统一登录</h3>
			<ul>
				<li><s>咕咕咕了，Windows VM 支持还没搞定</s></li>
				<li>RDP 一大坨非常起夜级的协议，<s>不是很想逆向</s></li>
				<li><i class="fas fa-fw fa-lightbulb-on"></i> 计划规格：<code>loadbalanceinfo</code></li>
			</ul>
		</section>
		<section id="login-browser">
			<h3>浏览器登录</h3>
			<ul>
				<li>VNC：魔改版 noVNC
					<ul>
						<li>没错，vncmux 顺带还实现了 WebSocket</li>
					</ul>
				</li>
				<li>SSH：Go → WASM</li>
				<li>RDP：从入门到放弃</li>
			</ul>
		</section>
	</section>
	<section>
		<section id="hearses">
			<h2>灵车时间</h2>
		</section>
		<section id="vlab-software-1">
			<h3>磁盘容量</h3>
			<ul>
				<li>一个虚拟机镜像就已经 21 GB 了</li>
				<li>+MATLAB, +Mathematica, +<a href="https://image.ibugone.com/vlab/node_modules-meme.png">node_modules</a></li>
				<li>我们的存储阵列里就有 114514 份 Vivado</li>
			</ul>
		</section>
		<section id="vlab-software-2">
			<h3>Bind mount!</h3>
			<ul>
				<li>local-lvm 开个新卷给 <code>/opt/vlab</code></li>
				<li>mp0: /opt/vlab,mp=/opt/vlab,ro=1</li>
				<li>易于维护：Rsync cron job</li>
			</ul>
		</section>
		<section id="novnc-fun">
			<h3>No... VNC?</h3>
			<p><img src="https://image.ibugone.com/vlab/no-vnc.png" /></p>
		</section>
		<section>
			<img src="https://image.ibugone.com/vlab/502.png" />
		</section>
		<section id="lvm-metadata-full">
			<h3>Everything breaks if pushed too hard...</h3>
			<pre style="font-size: 1em;"><code>VG test 1723 metadata on /dev/sdc1 (521759 bytes) exceeds maximum metadata size (521472 bytes)
Failed to write VG test.</code></pre>
			<p><a href="https://ibug.io/p/52"><i class="fas fa-fw fa-arrow-alt-circle-right"></i> ibug.io/p/52</a></p>
		</section>
		<section id="iowait-spike">
			<h3>IOWait（<code>%wa</code>）午夜准时爆炸</h3>
			<p style="width: 100%; height: 8em; display: flex; justify-content: space-evenly;">
				<img src="https://image.ibugone.com/vlab/iowait-load-average.png" />
				<img src="https://image.ibugone.com/vlab/iowait-iowait.png" />
			</p>
			<p>
				替用户停掉了 <code>man-db.timer</code> 和 <code>apt-daily-upgrade.timer</code>，
				<br />
				给 <code>logrotate.timer</code> 补上了 <code>RandomizedDelaySec=3h</code>。
			</p>
		</section>
		<section id="other-software-gore">
			<h3>其他灵异事件</h3>
			<ul>
				<li>
					一运行备份，网卡就掉了 😦<br />
					解决方法：两边开启 jumbo frame，MTU 拉到 9000 字节
				</li>
				<li>存储服务器的密码掉了</li>
				<li>PVE HA 过于热情（+<code>nofailback</code>）</li>
				<li>Vivado 又双叒叕炸了
					<ol type="1">
						<li><code>LD_PRELOAD</code> += <code>libudev.so.1</code></li>
						<li><code>LD_PRELOAD</code> += <code>libdbus-glib-1.so.2</code></li>
					</ol>
				</li>
			</ul>
		</section>
	</section>
	<section>
		<section id="results">
			<h2>成果</h2>
			<ul>
				<li>自 2020 年春季学期运行至今</li>
				<li>与 <a href="https://fpgaol.ustc.edu.cn/">FPGA Online</a> 和 <a href="https://verilogoj.ustc.edu.cn/">Verilog
						OJ</a> 等项目结合，实现纯在线 FPGA 编程教学</li>
				<li>Grafana：<a href="https://monitor.ibugone.com/grafana/d/2">monitor.ibugone.com/grafana/d/2</a></li>
			</ul>
		</section>
		<section>
			<div class="img-container">
				<img src="https://image.ibugone.com/vlab/containers-2023-08.png" />
			</div>
		</section>
		<section>
			<h3>学习资料</h3>
			<ul>
				<li>用户文档：<a href="https://vlab.ustc.edu.cn/docs/">vlab.ustc.edu.cn/docs</a></li>
				<li>维护文档：<a href="https://vlab.ibugone.com/">vlab.ibugone.com</a></li>
				<li>GitHub Org：<a href="https://github.com/USTC-vlab"><i class="fab fa-github"></i> USTC-vlab</a></li>
			</ul>
		</section>
	</section>
	<section id="outro">
		<h1>谢谢！</h1>
		<p><small>本页面的链接：<a href="https://ibug.io/p/59"><i class="fas fa-fw fa-link"></i> ibug.io/p/59</a></small></p>
	</section>
	]]></content><author><name>iBug</name></author></entry><entry><title type="html">Prolonging eMMC Life Span with Proxmox VE</title><link href="https://ibug.io/blog/2023/07/prolonging-emmc-life-span-with-proxmox-ve/" rel="alternate" type="text/html" title="Prolonging eMMC Life Span with Proxmox VE" /><published>2023-07-15T00:00:00+00:00</published><updated>2023-07-15T20:32:06+00:00</updated><id>https://ibug.io/blog/2023/07/prolonging-emmc-life-span-with-proxmox-ve</id><content type="html" xml:base="https://ibug.io/blog/2023/07/prolonging-emmc-life-span-with-proxmox-ve/"><![CDATA[<p>Since my blog on <a href="/p/49">installing Proxmox VE on eMMC</a>, there’s been a lot of discussion over the Internet on this. I suspect that Proxmox decided not to include eMMCs in their hardware options by design, as eMMCs typically do not offer the level of endurance as anything better than USB flash drives. Among many concerns, the most important one is the limited number of write cycles that an eMMC can sustain, while Proxmox VE, being an enterprise-grade product, has to constantly write stuff like logs to the storage. I came across <a href="https://fat-nerds.com/dot-nerd/cut-down-proxmox-ve-emmc-sd-read-write/">this blog (fat-nerds.com)</a> on reducing eMMC writes on a Proxmox VE installation on a single-board computer from a Hong Kong guy, so I figure I’d share my ideas here.</p>
	<p>This article will be a remix of the original blog, with some of my own experiences blended in.</p>
	<p>As a courtesy, here’s the disclaimer from the original blog:</p>
	<blockquote>
		<p>警告：下面的設定不應該被應用於有重大價值的伺服器上面！這只是筆者強行在便宜硬件上塞進PVE並以更暴力的方式去為其續命的手段。</p>
	</blockquote>
	<blockquote>
		<p>WARNING: The following settings should not be applied to valuable production servers! This is just a method for the author to force Proxmox VE onto cheap hardware and to prolong its life span.</p>
	</blockquote>
	<h2 id="swap">Disable swap</h2>
	<p>Swap is the mechanism of offloading some memory from physical RAM to disk in order to improve RAM management efficiency. If you have a lot of physical RAM, chances are swap isn’t going to be much helpful while producing a lot of writes to the disk. On a default Proxmox VE installation, the swap size is set from 4 GB to 8 GB, depending on your RAM capacity and disk size.</p>
	<p>You can temporarily disable swap by setting sysctl <code class="language-plaintext highlighter-rouge">vm.swappiness</code> to 0:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>sysctl vm.swappiness<span class="o">=</span>0
</code></pre>
		</div>
	</div>
	<p>Or why not just remove the swap space altogether?</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>swapoff <span class="nt">-a</span>  <span class="c"># disables swap</span>
vim /etc/fstab  <span class="c"># remove the swap entry</span>
lvremove /dev/pve/swap  <span class="c"># remove the swap logical volume</span>
</code></pre>
		</div>
	</div>
	<p>In most cases, you won’t need swap on a Proxmox VE host. If you find yourself needing swap, you should probably consider upgrading your RAM instead.</p>
	<h2 id="logs">System logs</h2>
	<h3 id="move-logs">Move logs to another disk</h3>
	<p>Every system produces logs, but Proxmox VE is particularly prolific on this. In a production environment, you’ll want to keep the logs by storing them on a separate disk (but why is it running on an eMMC in the first place?). So get another reliable disk and migrate the logs:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="c"># assuming the new disk is /dev/sdX</span>
systemctl stop rsyslog

mount /dev/sdX1 /var/log1
rsync <span class="nt">-avAXx</span> /var/log/ /var/log1/
<span class="nb">rm</span> <span class="nt">-rf</span> /var/log
<span class="nb">mkdir</span> /var/log
umount /var/log1
vim /etc/fstab  <span class="c"># add an entry for /dev/sdX1</span>
systemctl daemon-reload  <span class="c"># see notes</span>
mount /var/log

systemctl start rsyslog
</code></pre>
		</div>
	</div>
	<p>Notes on the above commands:</p>
	<ul>
		<li>Rsync is better than <code class="language-plaintext highlighter-rouge">cp</code> if you need to perform a non-trivial copy operation. (The original blog uses <code class="language-plaintext highlighter-rouge">cp</code>.)</li>
		<li>Using <code class="language-plaintext highlighter-rouge">fstab</code> guarantees any mounts are consistent and persistent across reboots.</li>
		<li>
			<p>Why <code class="language-plaintext highlighter-rouge">systemctl daemon-reload</code> after edting <code class="language-plaintext highlighter-rouge">fstab</code>? Because <a href="https://unix.stackexchange.com/q/474743/211239">systemd is sometimes too smart</a> (I got bitten by this once).</p>
		</li>
	</ul>
	<h3 id="disable-logs">Or disable logs altogether</h3>
	<p>On a hobbyist setup, you may be fine with disabling logs altogether.</p>
	<p>The original blog suggests replacing a few file with symlinks to <code class="language-plaintext highlighter-rouge">/dev/null</code>, which I find rather incomplete and ineffective. On my 5-GB-used rootfs, <code class="language-plaintext highlighter-rouge">/var/log</code> takes 1.8 GB, of which <code class="language-plaintext highlighter-rouge">/var/log/journal</code> eats 1.6 GB alone, so systemd journal is the first thing to go. Editing <code class="language-plaintext highlighter-rouge">/etc/systemd/journald.conf</code> and setting <code class="language-plaintext highlighter-rouge">Storage=none</code> will stop its disk hogging, but better yet, you can keep a minimal amount of logs by combining <code class="language-plaintext highlighter-rouge">Storage=volatile</code> and <code class="language-plaintext highlighter-rouge">RuntimeMaxUse=16M</code> (<a href="https://unix.stackexchange.com/a/705057/211239">ref</a>).</p>
	<p>If you’re on Proxmox VE 8+, you can create an “override” file for systemd-journald by adding your customizations to <code class="language-plaintext highlighter-rouge">/etc/systemd/journald.conf.d/override.conf</code>. This will save some trouble when the stock configuration file gets updated and you’re asked to merge the changes.</p>
	<p>For other logs, you can simply replace them with symlinks to <code class="language-plaintext highlighter-rouge">/dev/null</code>. For example:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="nb">ln</span> <span class="nt">-sfn</span> /dev/null /var/log/lastlog
</code></pre>
		</div>
	</div>
	<p>I’m not keen on this method as other logs only comes at a rate of a few hundred MBs per week, so I’d rather keep them around.</p>
	<h2 id="pve-services">Stop certain PVE services</h2>
	<p>The original blog suggests stopping a few non-essential services as they (which I couldn’t verify, nor do I believe so):</p>
	<ul>
		<li>High-Availability-related services (you don’t need HA on a single-node setup):
			<ul>
				<li><code class="language-plaintext highlighter-rouge">pve-ha-lrm</code></li>
				<li><code class="language-plaintext highlighter-rouge">pve-ha-crm</code></li>
			</ul>
		</li>
		<li>Firewall logger: <code class="language-plaintext highlighter-rouge">pvefw-logger</code></li>
		<li>Non-essential and non-PVE services:
			<ul>
				<li>spiceproxy (required for SPICE console, but noVNC is better)</li>
				<li>corosync (required for multi-node setup)</li>
			</ul>
		</li>
	</ul>
	<p>Except for <code class="language-plaintext highlighter-rouge">pvefw-logger</code>, stopping these services will not save you much disk writes as per my experiences.</p>
	<h2 id="rrdcached">Reduce <code class="language-plaintext highlighter-rouge">rrdcached</code> writes</h2>
	<p><code class="language-plaintext highlighter-rouge">rrdcached</code> is the service that stores and provides data for the PVE web interface to display graphs on system resource usage. I have no idea how much writes it produces, so I just relay the optimization given in the original blog.</p>
	<ul>
		<li>Edit <code class="language-plaintext highlighter-rouge">/etc/default/rrdcached</code>:
			<ul>
				<li>Set <code class="language-plaintext highlighter-rouge">WRITE_TIMEOUT=3600</code> so it only writes to disk once per hour.</li>
				<li>Comment out <code class="language-plaintext highlighter-rouge">JOURNAL_PATH</code> so it stops writing journals (not the data itself).</li>
				<li>Add <code class="language-plaintext highlighter-rouge">FLUSH_TIMEOUT=7200</code> (timeout for <code class="language-plaintext highlighter-rouge">flush</code> command, not sure how useful it is).</li>
			</ul>
		</li>
		<li>
			<p>Edit <code class="language-plaintext highlighter-rouge">/etc/init.d/rrdcached</code> for it to pick up the new <code class="language-plaintext highlighter-rouge">FLUSH_TIMEOUT</code> value:</p>
			<p>Find these lines:</p>
			<div class="language-shell highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="k">${</span><span class="nv">WRITE_TIMEOUT</span>:+-w<span class="p"> </span><span class="k">${</span><span class="nv">WRITE_TIMEOUT</span><span class="k">}}</span> <span class="se">\</span>
<span class="k">${</span><span class="nv">WRITE_JITTER</span>:+-z<span class="p"> </span><span class="k">${</span><span class="nv">WRITE_JITTER</span><span class="k">}}</span> <span class="se">\</span>
</code></pre>
				</div>
    </div>
			<p>And insert one line for <code class="language-plaintext highlighter-rouge">FLUSH_TIMEOUT</code>:</p>
			<div class="language-shell highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="k">${</span><span class="nv">WRITE_TIMEOUT</span>:+-w<span class="p"> </span><span class="k">${</span><span class="nv">WRITE_TIMEOUT</span><span class="k">}}</span> <span class="se">\</span>
<span class="k">${</span><span class="nv">FLUSH_TIMEOUT</span>:+-f<span class="p"> </span><span class="k">${</span><span class="nv">FLUSH_TIMEOUT</span><span class="k">}}</span> <span class="se">\</span>
<span class="k">${</span><span class="nv">WRITE_JITTER</span>:+-z<span class="p"> </span><span class="k">${</span><span class="nv">WRITE_JITTER</span><span class="k">}}</span> <span class="se">\</span>
</code></pre>
				</div>
    </div>
		</li>
	</ul>
	<p>After editing both files, restart the service: <code class="language-plaintext highlighter-rouge">systemctl restart rrdcached.service</code></p>
	<h2 id="pvestatd">Stop <code class="language-plaintext highlighter-rouge">pvestatd</code></h2>
	<p><code class="language-plaintext highlighter-rouge">pvestatd</code> provides an interface for hardware information for the PVE system. It shouldn’t produce much writes and stopping it will prevent creation of new VMs and containers, so I don’t recommend stopping it. The original blog probably included this option as a result of a mistake or ignorance.</p>
	<h2 id="conclusion">Conclusion</h2>
	<p>We can see how Proxmox VE is designed to provide enterprise-grade reliability and durability, at the expense of producing lots of disk writes for its various components like system logging and statistics. Based on the above analysis, it seems perfectly reasonable that Proxmox VE decides not to support eMMC storage.</p>
	<p>This blog combines a few tips from the original blog and my own experiences. I hope it helps you with your Proxmox VE setup on any eMMC-backed devices.</p>
	<div class="notice notice--primary">
		<p class="align-center" style="font-size: 1.6em;">But <em>really</em>?</p>
	</div>
	<h2 class="no_toc" id="results">Results</h2>
	<p>There’s one key question left unanswered by everything above: How much writes does Proxmox VE really produce?</p>
	<p>To answer this question, let’s see some of my examples:</p>
	<h3 class="no_toc" id="server-1">Server 1</h3>
	<p>Specs:</p>
	<ul>
		<li>Two enterprise-grade SSDs in RAID 1</li>
		<li>Running since October 2019</li>
		<li>“Master” node in a multi-node cluster, with the entire cluster running over 2,000 VMs and containers (~10 on this host)</li>
	</ul>
	<p>Total writes as of July 2023 (rootfs-only, thanks to <a href="https://unix.stackexchange.com/q/121699/211239">this answer</a>):</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="c"># lrwxrwxrwx 1 root root 7 Jul 12 15:48 /dev/pve/root -&gt; ../dm-4</span>
<span class="c"># cat /sys/fs/ext4/dm-4/lifetime_write_kbytes</span>
17017268104
</code></pre>
		</div>
	</div>
	<p>Result: 4.5 TB annually.</p>
	<h3 class="no_toc" id="server-2">Server 2</h3>
	<p>Specs:</p>
	<ul>
		<li>Two ol’ rusty spinning drives in RAID 1</li>
		<li>Running since January 2022</li>
		<li>Belongs to a multi-node cluster, running around 20 VMs (~3 on this host)</li>
	</ul>
	<p>Total writes as of July 2023 (rootfs-only):</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="c"># lrwxrwxrwx 1 root root 7 Jan 21  2022 /dev/pve/root -&gt; ../dm-1</span>
<span class="c"># cat /sys/fs/ext4/dm-1/lifetime_write_kbytes</span>
2336580629
</code></pre>
		</div>
	</div>
	<p>Result: 1.5 TB annually.</p>
	<h3 class="no_toc" id="server-3">Server 3</h3>
	<p>Specs:</p>
	<ul>
		<li>Lab’s storage server, single SSD for rootfs and ZFS SLOG (ZIL)</li>
		<li>Running since October 2022</li>
		<li>Single-node setup, running 2 VMs</li>
		<li>Data is stored separately</li>
	</ul>
	<p>Total writes as of July 2023:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="c"># smartctl -A /dev/sda</span>
241 Total_LBAs_Written 2849895751
</code></pre>
		</div>
	</div>
	<p><code class="language-plaintext highlighter-rouge">humanize.naturalsize(2849895751 * 512, format="%.2f")</code>: 1.46 TB (≈ 2 TB annually)</p>
	<h3 class="no_toc" id="emmc-write-life">eMMC Write Life</h3>
	<p>This one really depends on the hardware you get. In 2023 virtually every reasonable TLC flash chip should withstand at least 1,000 P/E cycles, so even a pathetic 8 GB eMMC should last around 10 TB of writes, <a href="https://forums.raspberrypi.com/viewtopic.php?t=291808">as that on a Raspberry Pi Compute Module 4</a>.</p>
	<p>If you get anything larger than that, you should be fine expecting it to survive at least 20 TB of writes.</p>
	<h2 class="no_toc" id="real-conclusion">REAL Conclusion</h2>
	<p>Congratulations on reading this far.</p>
	<p>If you managed to hold your paranoia and refrain from putting anything into action, you can now sit back and relax. Unless you’re squeezing hundreds of VMs and containers into a single eMMC-driven board (poor board) without separate storage for VMs, your eMMC is not going to die anytime soon.</p>
	<h2 id="references">References</h2>
	<ul>
		<li>Original blog (Traditional Chinese): <a href="https://fat-nerds.com/dot-nerd/cut-down-proxmox-ve-emmc-sd-read-write/">單板小主機上的Proxmox VE實務：暴力減少eMMC或SD卡的讀寫耗損</a></li>
		<li><a href="https://forums.raspberrypi.com/viewtopic.php?t=291808">CM4 eMMC durability - Terabytes written value (TBW)?</a></li>
	</ul>
	]]></content><author><name>iBug</name></author><category term="linux" /><category term="server" /><category term="proxmox-ve" /><summary type="html"><![CDATA[Since my blog on installing Proxmox VE on eMMC, there’s been a lot of discussion over the Internet on this. I suspect that Proxmox decided not to include eMMCs in their hardware options by design, as eMMCs typically do not offer the level of endurance as anything better than USB flash drives. Among many concerns, the most important one is the limited number of write cycles that an eMMC can sustain, while Proxmox VE, being an enterprise-grade product, has to constantly write stuff like logs to the storage. I came across this blog (fat-nerds.com) on reducing eMMC writes on a Proxmox VE installation on a single-board computer from a Hong Kong guy, so I figure I’d share my ideas here.]]></summary></entry><entry><title type="html">My automated Daily Health Report infrastructure</title><link href="https://ibug.io/blog/2023/04/checkin-infrastructure/" rel="alternate" type="text/html" title="My automated Daily Health Report infrastructure" /><published>2023-04-23T00:00:00+00:00</published><updated>2023-04-24T00:48:56+00:00</updated><id>https://ibug.io/blog/2023/04/checkin-infrastructure</id><content type="html" xml:base="https://ibug.io/blog/2023/04/checkin-infrastructure/"><![CDATA[<p>Back in the days when the <a href="https://en.wikipedia.org/wiki/Chinese_government_response_to_COVID-19">Zero COVID policy</a> was prevailing, our university introduced a <em>Daily Health Report</em> system. Students and faculty were mandated to submit a daily online form detailing their health status. Noncompliance resulted in denied campus access, and in more stringent times, forced quarantine. Thanks to the comprehensive lockdown of campuses, our activity were strictly confined. Consequently, our daily data submission were pratically invariant. It’s a colossal waste of effort to do it manually (with some anecdotes later on), so I opted to automate the process.</p>
	<p>As the policies evolved, our school’s reporting platform also underwent changes. I had to update the reporting script multiple times with new features to align those of the reporting platform.</p>
	<p>Much like my <a href="/blog/2023/01/overengineering-adventofcode/">previous article</a>, there’s a significant distinction between making something work and making it work with elegance. So in this article, I’ll share my infrastructure for the automated daily report system, and delve into some design options and decisions I made in the way.</p>
	<h2 id="script">The reporting script</h2>
	<p>Writing a script is about the easiest thing in the whole system with the least technical complexity. Anyone with basic scripting abilities can do it well, so I <a href="https://github.com/iBug/thu-checkin">open-sourced mine</a>. It only takes a few minutes to open the Developer Tools on your browser, identify the request originating from the [Submit] button, copy its payload out and put that into a script, and it’s ready to service. If anything marginally fancy were to be added, it’d be saving certain data to a separate file so that others can adopt the script more easily.</p>
	<p>The next thing is to run the script every day at a desired time. A common solution is to use Cron that is simple and easy. <a href="https://wiki.archlinux.org/title/systemd/Timers">Systemd timers</a> is a modern alternative offering more features at the expense of a more complex configuration. I chose the latter for its <code class="language-plaintext highlighter-rouge">RandomizedDelaySec</code> option, so that the script won’t be run at the exact same time every day.</p>
	<p>At the beginning I also had a sample GitHub Actions workflow file so that others can fork my repository and start automating their reports with minimal effort. However, I scrapped it later on realizing it’s against GitHub’s ToS.</p>
	<p><img src="/image/server/checkin-1.png" alt="First step" /></p>
	<h2 id="status">Status report</h2>
	<p>The next thing is to stay informed of whether the script is working properly. Logging in to the server and reading logs every day is not fun. Assuming that it worked and ending up being denied entry to the school is even worse. So it’d be nice to be notified of everything it does.</p>
	<p>A common choice is via email, but it’s lacking a bit of timeliness. I chose Telegram because I’m actively using it and it provides a bot API. Adding <code class="language-plaintext highlighter-rouge">python-telegram-bot</code> to the script and a few lines of code, I can get a notification on my Telegram every time the script runs.</p>
	<p>My actual setup differs slightly, with an extra component between the script and the bot: an AWS Lambda serverless function. I did this for two reasons:</p>
	<ul>
		<li>Minor reason: Telegram servers (<code class="language-plaintext highlighter-rouge">api.telegram.org</code>) is not directly accessible from mainland China for well-known reasons.</li>
		<li><strong>Major reason</strong>: I already have a <a href="/blog/2021/02/github-webhook-on-aws-lambda/">GitHub webhook</a> running on AWS Lambda. It is much less involved to add another URL handler to that function and reuse the existing codebase, like credentials and message formatting. This allows me to simplify the notification to a single <code class="language-plaintext highlighter-rouge">requests.post</code>.</li>
	</ul>
	<p><img src="/image/server/checkin-2.png" alt="Second step" /></p>
	<p>As a bonus feature, I also send the error message and the line number in case of an exception, so that I can quickly identify the problem before investigating the logs.</p>
	<blockquote>
		<p><strong>[THU Checkin]</strong> Success: 2023-02-24 20:42:23<br />
			Checkin: Success<br />
			Apply: Success</p>
	</blockquote>
	<blockquote>
		<p><strong>[THU Checkin]</strong> ❌ <strong>Error</strong>: 2023-02-25 20:05:46<br />
			AttributeError: ‘NoneType’ object has no attribute ‘group’<br />
			On <code class="language-plaintext highlighter-rouge">checkin.py</code> line 67</p>
	</blockquote>
	<h2 id="image">Uploading images</h2>
	<p>Sometime later, our school began to demand regular uploads of our <a href="https://en.wikipedia.org/wiki/Health_Code">health QR code</a>. The QR code is generated by a govermental mobile app whose retrieval is, unfortunately, difficult to automate. Before stepping over the line of producing fake QR codes, I decided to take the screenshots manually and have my script upload them to the reporting platform. The good news is, there’s no measures on the platform to validate the uploaded images, so uploading an outdated screenshot yields no consequences most of the time, and I don’t have to constantly update the screenshots for the script.</p>
	<p>Image uploading is nothing new to the <code class="language-plaintext highlighter-rouge">requests</code> Python library, but I have to deliver the files from my phone somehow. Options to transfer files from an Android phone to a Linux server are abundant, and for me I found SMB the most convenient. <a href="https://play.google.com/store/apps/details?id=com.speedsoftware.rootexplorer">Root Explorer</a> is the file manager that I’ve been using for a decade, so I could just set up Samba on my server to receive the files from it.</p>
	<blockquote>
		<p><strong>[THU Checkin]</strong> Success: 2023-02-25 08:33:36<br />
			Checkin: Success<br />
			Apply: Success<br />
			Image 1: Skipped<br />
			Image 2: Success<br />
			Image 3: Success</p>
	</blockquote>
	<p><img src="/image/server/checkin-3.png" alt="Third step" /></p>
	<p>Alternatively, I could have my Telegram bot accept the images and forward them to the server. This would be more convenient in terms of using, but much less in coding as I didn’t have any existing code in my Telegram bot that handles images. Meanwhile, I already had Samba running on my server so I in fact did not set it up anew.</p>
	<h2 id="security">Securing the server</h2>
	<p>At this point everything is operational, with one detail missing: The SMB protocol is not known for being secure. Exposing the SMB port to the Internet is prone to troubles and connecting to a VPN every time is not convenient. Luckily I have Clash for Android running on my phone 24/7 that I can use to proxy Root Explorer. I set up a shadowsocks-libev server and configured Clash to route traffic targeting my server through it, and then closed the SMB port in my server firewall.</p>
	<p>There’s a noteworthy thing about Clash: It’s a rule-based proxy software that reads configurations. My airport<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> service provides their configuration through a subscription URL, but Clash for Android doesn’t support editing subscribed config. Another background story comes up here: I have another Lambda function serving as my own Clash config subscription. It fetches the airport config and modifies it to my preferences, and then serves it to Clash. It also makes updating the config easier, as I can just update the Lambda function code and the changes will be reflected in Clash.</p>
	<p>Fun fact: My custom subscription is also used with Clash for Windows on my computer, which helped me completely bypass two RCE vulnerabilities (<a href="https://github.com/Fndroid/clash_for_windows_pkg/issues/2710">1</a>, <a href="https://github.com/advisories/GHSA-rq24-vhfq-6v9x">2</a>).</p>
	<h2 id="conclusion">Conclusion</h2>
	<p>After all this complexity, here’s what I’ve got:</p>
	<p><img src="/image/server/checkin-infra.png" alt="Final state" /></p>
	<p>The script runs every day at a random time in a configured time span, and I get a notification on Telegram regardless of whether it succeeds or fails. If the script fails I also have the required information to look into it. The script also uploads the health QR code screenshots to the reporting platform, and I can update the images from my phone through a secured connection.</p>
	<p>Of all these tasks, only taking the screenshots and uploading them to the server is manual, denoted in the image by blue arrows. All black arrows are automated and require no attention to function.</p>
	<p>As the zero-COVID policy <a href="https://en.wikipedia.org/wiki/Chinese_government_response_to_COVID-19#2022_outbreaks_and_end_of_zero-COVID_policy">came crumbling down</a> in December 2022, our school also put an end to the daily health reporting system. As a result, I can safely share my setup here without fearing repercussions. I hope this article brings you some inspiration for your next automation project.</p>
	<div class="notice--primary">
		<h4 class="no_toc" id="anecdote">Anecdote</h4>
		<p>During the days around the strictest lockdown of campuses, all students’ requests for outgoing were manually reviewed by two levels of authority, with the second level being the dean. Our department consists of over 2,000 students that kept submitting requests every day. Needless to say, many staff weren’t happy about this, and the dean in particular. We were once asked to stop phoning her as she was already processing the requests from 7 AM to 11 PM every day. To everyone’s relief, the reviewing process was cancelled in a few days and requests were automatically approved thereafter.</p>
	</div>
	<div class="footnotes" role="doc-endnotes">
		<ol>
			<li id="fn:1" role="doc-endnote">
				<p>Shadowsocks service providers are commonly called “airports” because the icon of Shadowsocks is a paper plane, and every provider has multiple “plane servers” that you can use. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
			</li>
		</ol>
	</div>
	]]></content><author><name>iBug</name></author><category term="tech" /><category term="server" /><category term="networking" /><category term="development" /><summary type="html"><![CDATA[Back in the days when the Zero COVID policy was prevailing, our university introduced a Daily Health Report system. Students and faculty were mandated to submit a daily online form detailing their health status. Noncompliance resulted in denied campus access, and in more stringent times, forced quarantine. Thanks to the comprehensive lockdown of campuses, our activity were strictly confined. Consequently, our daily data submission were pratically invariant. It’s a colossal waste of effort to do it manually (with some anecdotes later on), so I opted to automate the process.]]></summary></entry><entry><title type="html">Overengineering Advent of Code 2022</title><link href="https://ibug.io/blog/2023/01/overengineering-adventofcode/" rel="alternate" type="text/html" title="Overengineering Advent of Code 2022" /><published>2023-01-08T00:00:00+00:00</published><updated>2023-01-09T02:17:24+00:00</updated><id>https://ibug.io/blog/2023/01/overengineering-adventofcode</id><content type="html" xml:base="https://ibug.io/blog/2023/01/overengineering-adventofcode/"><![CDATA[<p><em>Advent of Code</em> (<a href="https://en.wikipedia.org/wiki/Advent_of_Code">Wikipedia</a>, <a href="https://adventofcode.com/">link</a>) is an annual event that releases a programming puzzle every day from December 1 to December 25. It’s a great chance to learn a new language or practice your skills.</p>
	<p><img src="/image/adventofcode-2022.png" alt="Image" /></p>
	<p>Considering that all the puzzles are designed to be lightweight, meaning that if implemented correctly, they’re solvable in no more than a few seconds with a reasonably small memory footprint, I picked Go as my language of choice. Go has been my preference over Python for a while, for being compiled into machine code and thus more performant, and a decent set of standard libraries.</p>
	<h2 id="puzzles">Notes on puzzles</h2>
	<p>The first 10 puzzles are very easy and doesn’t even require special knowledge. They’re practically just text processing and simulation, so there aren’t many comments to be made.</p>
	<ul>
		<li>
			<p>Day 2: While it’s straightforward to implement a rock-paper-scissors game using <code class="language-plaintext highlighter-rouge">switch</code>es or lookup tables, noticing that shape <code class="language-plaintext highlighter-rouge">i+1</code> beats shape <code class="language-plaintext highlighter-rouge">i</code> allows us to simplify the code in an obscure way.</p>
			<p>For example, I implemented the “shape score” as <code class="language-plaintext highlighter-rouge">int(s[2] - 'W')</code>, and the “outcome score” as <code class="language-plaintext highlighter-rouge">(4 + int(s[2]-'X') - int(s[0]-'A')) % 3 * 3</code> for the first part. For the second part, the “shape score” is now <code class="language-plaintext highlighter-rouge">1 + (int(s[0]-'A')+int(s[2]-'X')+2)%3</code>, and the “outcome score” is <code class="language-plaintext highlighter-rouge">int(s[2]-'X') * 3</code>.</p>
			<p>This is certainly not the most readable code, but it’s a good example of how to use math to simplify code. Less code = less bugs, and if you’re really crazy about that, you can always add unit tests to ensure that the code doesn’t break unexpectedly. That’s not my style, though.</p>
		</li>
	</ul>
	<p>Starting from Day 11, the puzzles become more interesting. Some math or data structures are required to solve them.</p>
	<ul>
		<li>Day 11: The first part is plain simulation, but the second part can easily run the numbers out of range if you don’t manage them properly. Actually, modulo by the <a href="https://en.wikipedia.org/wiki/Least_common_multiple">least common multiple</a> of the divisors is a good way to keep them down.</li>
		<li>Day 14, 15 and 23: With a large coordinate space but limited elements, it’s a better idea to use a map or set instead of contiguous memory.</li>
		<li>Day 17 part 2: Running a simulation for 1000000000000 rounds is certainly not feasible, but it’s possible to find a pattern from the first 10000 or so rounds, and calculate the result from there.</li>
		<li>Day 18 part 2: Finding internal holes would be difficult, but <a href="https://en.wikipedia.org/wiki/Flood_fill">flood filling</a> from the outside is an alternative approach.</li>
		<li>Day 19 part 2: Even if searching for the “next robot to make” can’t keep the search space small, pruning near the leaves (i.e. stop searching in the last few minutes) can still cut it down by a large factor. This is the only way that I managed to bring the run time below 1 second.</li>
		<li>Day 20 part 2: Again simulating for so many 811589153 steps is not feasible, so like Day 11 part 2, it’s important to find a correct modulo.</li>
		<li>Day 21 part 2: At first this seems like tremendous work, but I made a bold assumption that the equation is linear (degree = 1), which turned out to be true. This enabled me to use very simple math to solve it.</li>
		<li>Day 22 is my favorite puzzle. Finding an algorithm to fold a flat layout into a cube is far from easy, so I hard-coded it for my input. (It seems like everyone is getting the same layout.) Such a two-layer <code class="language-plaintext highlighter-rouge">switch</code> statement is prone to bugs and took me the longest time to debug.</li>
		<li>Day 25: To my surprise, the puzzle is missing a part 2. Maybe the author is getting on a vacation?</li>
	</ul>
	<p>Finally, a magic trick that I discovered from Reddit for Day 15 part 2: Observing that the only uncovered space must be adjacent to multiple covered areas, examining the intersections of the edges of the beacons’ coverage areas produces a tiny search space. While it’s intuitive to build upon part 1’s solution, this discovery leads to a lightspeed solution.</p>
	<h2 id="engineering">Engineering the project</h2>
	<p>In fact, rushing to the puzzles was not even the first thing. I did not come across the event until my friend <a href="https://www.taoky.moe/">taoky</a> recommended it to me. He was already halfway through the puzzles (<a href="https://github.com/taoky/adventofcode">his <i class="fab fa-fw fa-github"></i> repository</a>) and had set himself a set of rules, including one where “<em>all solutions should take reasonable time and memory usage</em>”. We discussed various methods to measure the time and memory usage, when he set it forth that it was not easy to add measurements to every single program.</p>
	<p>Based on our discussion, I decided I would leave room for measurements when designing the project. So the first decision was to reuse code as much as possible within the project. For example, I’d like all solutions to share the same “peripherals” like the <code class="language-plaintext highlighter-rouge">main</code> function. This way if I want to add an extra feasure like performance measurement, I only need to do it once.</p>
	<p>The next decision was to compile solutions for all puzzles into a single binary. Go is not known for producing small binaries due to static linking, so having separate binaries for each solutions implies a non-trivial amount of unnecessary disk space. Another reason is that due to Go’s package design, it’s more complex to selectively compile individual files than to compile all files together (the “package”). With a <code class="language-plaintext highlighter-rouge">go.mod</code> file present, <code class="language-plaintext highlighter-rouge">go build</code> conveniently compiles all files in the same directory.</p>
	<p>With that in mind, <a href="https://github.com/iBug/AdventOfCode/commit/73715a64f7e860dffa63382ed3dff14b8d4ae60d">here</a>’s the first commit of the project. In addition to the code itself, two more design ideas can be seen:</p>
	<ul>
		<li>Individual solutions are in their own files, calling <code class="language-plaintext highlighter-rouge">RegisterSolution</code> in their <code class="language-plaintext highlighter-rouge">init</code> functions to register themselves. Also, the solution function takes a single <code class="language-plaintext highlighter-rouge">io.Reader</code> interface as input, so that providing input can be more flexible if needed.</li>
		<li>If multiple input files are provided, the solution function sees a concatenation of all of them, similar to a number of common Unix tools. However, this little care was later decided to be unnecessary, and only a single input file would be processed.</li>
	</ul>
	<p>Now with the project structure in place, I started working on the solutions. <a href="https://github.com/iBug/AdventOfCode/commit/4b695648807b47818e60ab19d246ff61183c7ce2">The second commit</a> added my solution for Day 1 part 1, and it followed the designed structure like this:</p>
	<div class="language-go highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">package</span> <span class="n">main</span>

<span class="k">import</span> <span class="p">(</span> <span class="o">...</span> <span class="p">)</span>

<span class="k">func</span> <span class="n">Solution1_1</span><span class="p">(</span><span class="n">r</span> <span class="n">io</span><span class="o">.</span><span class="n">reader</span><span class="p">)</span> <span class="p">{</span> <span class="o">...</span> <span class="p">}</span>

<span class="k">func</span> <span class="n">init</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">RegisterSolution</span><span class="p">(</span><span class="s">"1-1"</span><span class="p">,</span> <span class="n">Solution1_1</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>
		</div>
	</div>
	<p>While the first few days’ solutions were pretty ordinary, my design began to prosper when I started working on Day 5 part 2. The only difference between part 1 and part 2 is whether moving a stack of crates maintains or reverses their order. Compared to the common one-source-file-per-solution design, I can now reuse almost the whole function from part 1, and abstract the difference into a function parameter. This is how <code class="language-plaintext highlighter-rouge">day5.go</code> looks like after <a href="https://github.com/iBug/AdventOfCode/commit/fe63dc98e36b70c0f9ffb779eadffc34d2a7b80b">adding part 2</a>:</p>
	<div class="language-go highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">package</span> <span class="n">main</span>

<span class="k">import</span> <span class="p">(</span> <span class="o">...</span> <span class="p">)</span>

<span class="k">func</span> <span class="n">init</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">RegisterSolution</span><span class="p">(</span><span class="s">"5-1"</span><span class="p">,</span> <span class="k">func</span><span class="p">(</span><span class="n">r</span> <span class="n">io</span><span class="o">.</span><span class="n">Reader</span><span class="p">)</span> <span class="p">{</span> <span class="n">Solution5</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">Move5_1</span><span class="p">)</span> <span class="p">})</span>
    <span class="n">RegisterSolution</span><span class="p">(</span><span class="s">"5-2"</span><span class="p">,</span> <span class="k">func</span><span class="p">(</span><span class="n">r</span> <span class="n">io</span><span class="o">.</span><span class="n">Reader</span><span class="p">)</span> <span class="p">{</span> <span class="n">Solution5</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">Move5_2</span><span class="p">)</span> <span class="p">})</span>
<span class="p">}</span>

<span class="k">func</span> <span class="n">Move5_1</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="p">{</span> <span class="o">...</span> <span class="p">}</span>
<span class="k">func</span> <span class="n">Move5_2</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="p">{</span> <span class="o">...</span> <span class="p">}</span>

<span class="k">func</span> <span class="n">Solution5</span><span class="p">(</span><span class="n">r</span> <span class="n">io</span><span class="o">.</span><span class="n">Reader</span><span class="p">,</span> <span class="n">moveFunc</span> <span class="k">func</span><span class="p">(</span><span class="o">...</span><span class="p">))</span> <span class="p">{</span> <span class="o">...</span> <span class="p">}</span>
</code></pre>
		</div>
	</div>
	<p>For Day 6, <a href="https://github.com/iBug/AdventOfCode/commit/cf19fad5b05e992dfdab9f6abcf2a87c4b808d7a">the benefit</a> is even more prominent:</p>
	<div class="language-go highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">func</span> <span class="n">init</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">RegisterSolution</span><span class="p">(</span><span class="s">"6-1"</span><span class="p">,</span> <span class="k">func</span><span class="p">(</span><span class="n">r</span> <span class="n">io</span><span class="o">.</span><span class="n">Reader</span><span class="p">)</span> <span class="p">{</span> <span class="n">Solution6</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="m">4</span><span class="p">)</span> <span class="p">})</span>
    <span class="n">RegisterSolution</span><span class="p">(</span><span class="s">"6-2"</span><span class="p">,</span> <span class="k">func</span><span class="p">(</span><span class="n">r</span> <span class="n">io</span><span class="o">.</span><span class="n">Reader</span><span class="p">)</span> <span class="p">{</span> <span class="n">Solution6</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="m">14</span><span class="p">)</span> <span class="p">})</span>
<span class="p">}</span>
</code></pre>
		</div>
	</div>
	<p>Had I not designed the project this way, I would have to duplicate the whole function for part 2 only to change a single parameter, making things much more error-prone.</p>
	<h3 id="measurements">Adding measurements</h3>
	<p>Given the project design above, adding measurements is much simpler than it would have been if I had adopted the one-source-file-per-solution layout. It boils down to just two things:</p>
	<ul>
		<li>
			<p>A command-line flag to enable measurements:</p>
			<div class="language-go highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="n">flag</span><span class="o">.</span><span class="n">BoolVar</span><span class="p">(</span><span class="o">&amp;</span><span class="n">fShowPerformance</span><span class="p">,</span> <span class="s">"p"</span><span class="p">,</span> <span class="no">false</span><span class="p">,</span> <span class="s">"show performance information"</span><span class="p">)</span>
</code></pre>
				</div>
    </div>
		</li>
		<li>
			<p>Adding <code class="language-plaintext highlighter-rouge">time.Now()</code> and <code class="language-plaintext highlighter-rouge">time.Since()</code> around the call to the solution function:</p>
			<div class="language-go highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="n">start</span> <span class="o">:=</span> <span class="n">time</span><span class="o">.</span><span class="n">Now</span><span class="p">()</span>
<span class="n">fn</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
<span class="n">duration</span> <span class="o">:=</span> <span class="n">time</span><span class="o">.</span><span class="n">Since</span><span class="p">(</span><span class="n">startTime</span><span class="p">)</span>
</code></pre>
				</div>
    </div>
			<p>… as well as displaying the result:</p>
			<div class="language-go highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="k">if</span> <span class="n">fShowPerformance</span> <span class="p">{</span>
    <span class="n">fmt</span><span class="o">.</span><span class="n">Fprintf</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">Stderr</span><span class="p">,</span> <span class="s">"</span><span class="se">\n</span><span class="s">Duration: %s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">duration</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>
				</div>
    </div>
		</li>
	</ul>
	<p>Measuring memory usage is a bit more complicated. Go’s memory profiling doesn’t provide a simple “max usage in this session” metric, so I have to resort to OS-specific methods. On Linux, for the time being, I use <code class="language-plaintext highlighter-rouge">getrusage(2)</code> with <code class="language-plaintext highlighter-rouge">RUSAGE_SELF</code>, as two other known methods (using Cgroup and polling <code class="language-plaintext highlighter-rouge">/proc/self/status</code>) either require forking an extra process or add significant overhead and engineering complexity.</p>
	<p>Now the program can produce a short summary of the performance when running a solution:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>./adventofcode <span class="nt">-p</span> 1-1 2022/inputs/1.txt
<span class="go">71780

Time: 875µs, Memory: 7.8 MiB
</span></code></pre>
		</div>
	</div>
	<p>There’s one caveat here: The “Max RSS” value returned by <code class="language-plaintext highlighter-rouge">getrsage(2)</code> is the peak memory usage during the whole program’s lifetime, starting from when it’s forked from the parent process, when it inherits all mapped pages (resident set). Using an interactive Bash gives a minimum value of around 7.7 MiB, while using <code class="language-plaintext highlighter-rouge">sh -c './adventofcode -p'</code>, adding a level indirection, reduces the starting size to 1.2 MiB.</p>
	<h3 id="multi-year">Adding multi-year support</h3>
	<p>Up until now, the project has a flat layout with no subdirectories, and all Go source files start with <code class="language-plaintext highlighter-rouge">package main</code>. This is because I did not plan to support multiple years at the beginning. However, as I started working on puzzles from 2021, I realized that I need a better structure to support multiple years without worrying about namespace issues, like both years having a <code class="language-plaintext highlighter-rouge">Solution1_1</code> function.</p>
	<p>Moving each year’s solutions into a subdirectory is a natural choice. However, <code class="language-plaintext highlighter-rouge">go build</code> doesn’t pick up subdirectories by default, so I have to find a way to make it work. There are also some minor name searching issues, like <code class="language-plaintext highlighter-rouge">RegisterSolution</code> being defined in <code class="language-plaintext highlighter-rouge">main.go</code> but used in every solution file.</p>
	<p>After a bit of trial-and-error, I <a href="https://github.com/iBug/AdventOfCode/commit/36b256c41897633bae53a1ca4c39476e0af9d858">carried out</a> the following changes:</p>
	<ul>
		<li>Split out the “solution registry” into a <code class="language-plaintext highlighter-rouge">common</code> subdirectory, making it a separate package that can be imported by each year’s package.
			<ul>
				<li>Each year’s package should import just <code class="language-plaintext highlighter-rouge">common.RegisterSolution</code>, possibly wrapping it up to add a custom “year identifier” (this was <a href="https://github.com/iBug/AdventOfCode/commit/7f7080aae1df181ec2b16eafc3bbd214610914c4">implemented</a> right after).</li>
			</ul>
		</li>
		<li>Move all solution files into a <code class="language-plaintext highlighter-rouge">2022</code> subdirectory, and change the package name to just <code class="language-plaintext highlighter-rouge">year</code> (because I don’t expect this directory to be imported and used with the package name).</li>
		<li>Add <code class="language-plaintext highlighter-rouge">import _ "adventofcode/2022"</code> in <code class="language-plaintext highlighter-rouge">main.go</code> for each year’s subdirectory.</li>
	</ul>
	<p>In subsequent commits, I implemented “year selection” (e.g. choosing between the solutions <code class="language-plaintext highlighter-rouge">2021/1-1</code> and <code class="language-plaintext highlighter-rouge">2022/1-1</code>) as well as more listings (e.g. <code class="language-plaintext highlighter-rouge">./adventofcode 2021/</code> to list all solutions for 2021).</p>
	<p>With this in place, I can now add solutions for 2021 without worrying about name conflicts. For convenience, I also added auto-searching for input files in the current directory, so I can just run <code class="language-plaintext highlighter-rouge">./adventofcode 2021/1-1</code> to run the solution for Day 1 part 1 of 2021.</p>
	<h2 id="epilogue">Epilogue</h2>
	<p>At this point, the project has successfully deviated from a collection of solutions to small-but-interesting puzzles, and has become more like a general-purpose tool for this kind of events. Nevertheless, it’s a fun journey as a software engineering practice, in addition to solving the puzzles themselves.</p>
	<p>Looking at these paths I’ve taken, it is manifest that the initial decisions in the right direction are highly contributory in easing the development process, particularly when I’m coming back later to add a new global feature. This experience once again emphasizes the importance and advantages of having a clear idea of the project before starting to write code, as well as keeping the code in an extensible and maintainable fashion.</p>
	]]></content><author><name>iBug</name></author><category term="development" /><summary type="html"><![CDATA[Advent of Code (Wikipedia, link) is an annual event that releases a programming puzzle every day from December 1 to December 25. It’s a great chance to learn a new language or practice your skills.]]></summary></entry></feed>