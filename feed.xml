<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://ibug.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ibug.io/" rel="alternate" type="text/html" /><updated>2022-03-14T13:00:48+00:00</updated><id>https://ibug.io/feed.xml</id><title type="html">iBug</title><subtitle>The little personal site for iBug</subtitle><author><name>iBug</name></author><entry><title type="html">Install Proxmox VE on eMMC</title><link href="https://ibug.io/blog/2022/03/install-proxmox-ve-emmc/" rel="alternate" type="text/html" title="Install Proxmox VE on eMMC" /><published>2022-03-01T00:00:00+00:00</published><updated>2022-03-01T19:03:19+00:00</updated><id>https://ibug.io/blog/2022/03/install-proxmox-ve-emmc</id><content type="html" xml:base="https://ibug.io/blog/2022/03/install-proxmox-ve-emmc/"><![CDATA[<p>Recently I bought a mini PC looking forward to setting up a home router. It started quite well except the specs were higher than I anticipated. 8 GB RAM plus 128 GB eMMC - too much waste for “just a router”, so I figured I’d get some virtual machines to improve its utilization. Choosing the virtualization platform isn’t hard - I’m most familiar with Proxmox VE.</p>
			<p>The offcial ISO installer is pretty straightforward, until the last step:</p>
			<div class="language-text highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code>Unable to get device for partition 1 on device /dev/mmcblk0
</code></pre>
				</div>
			</div>
			<h2 id="solution">Solution</h2>
			<p>The Proxmox VE forum is <em>completely unhelpful</em> this time (<a href="https://forum.proxmox.com/threads/unable-to-get-device-for-partition-1-on-device-dev-mmcblk0.42348/">1</a>, <a href="https://forum.proxmox.com/threads/unable-to-get-device-for-partition-1.43234/">2</a>) with staff keeping on saying “it’s not supported”, so I had to look around for alternatives. Fortunately this article is right there:</p>
			<ul>
				<li><a href="https://lookas2001.com/%E8%A7%A3%E5%86%B3-proxmox-ve-%E6%97%A0%E6%B3%95%E5%AE%89%E8%A3%85%E5%88%B0-emmc-%E4%B8%8A%E7%9A%84%E9%97%AE%E9%A2%98/">解决 Proxmox VE 无法安装到 eMMC 上的问题 - lookas2001</a></li>
			</ul>
			<p>Turns out it’s hard-coded into Proxmox VE’s Perl installer script, so all you have to do is to patch it:</p>
			<ol>
				<li>Boot the installer ISO to the first menu, select the second option <code class="language-plaintext highlighter-rouge">Install Proxmox VE (Debug mode)</code></li>
				<li>The first time you’re present with a command-line prompt, type <code class="language-plaintext highlighter-rouge">exit</code> and Enter to skip it. This is a very early stage and you can’t do much here.</li>
				<li>The second time you have a shell, locate <code class="language-plaintext highlighter-rouge">/usr/bin/proxinstall</code> and open it. Text editors such as <code class="language-plaintext highlighter-rouge">vi</code> and <code class="language-plaintext highlighter-rouge">nano</code> are available.</li>
				<li>
					<p>Search for <code class="language-plaintext highlighter-rouge">unable to get device</code> and you should find some code like this:</p>
					<div class="language-perl highlighter-rouge">
						<div class="highlight">
							<pre class="highlight"><code> <span class="p">}</span> <span class="k">elsif</span> <span class="p">(</span><span class="nv">$dev</span> <span class="o">=~</span> <span class="sr">m|^/dev/[^/]+/hd[a-z]$|</span><span class="p">)</span> <span class="p">{</span>
     <span class="k">return</span> <span class="p">"</span><span class="si">${dev}$partnum</span><span class="p">";</span>
 <span class="p">}</span> <span class="k">elsif</span> <span class="p">(</span><span class="nv">$dev</span> <span class="o">=~</span> <span class="sr">m|^/dev/nvme\d+n\d+$|</span><span class="p">)</span> <span class="p">{</span>
     <span class="k">return</span> <span class="p">"</span><span class="si">${dev}</span><span class="s2">p</span><span class="si">$partnum</span><span class="p">";</span>
 <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
     <span class="nb">die</span> <span class="p">"</span><span class="s2">unable to get device for partition </span><span class="si">$partnum</span><span class="s2"> on device </span><span class="si">$dev</span><span class="se">\n</span><span class="p">";</span>
 <span class="p">}</span>
</code></pre>
						</div>
    </div>
					<p>The full code can be found <a href="https://github.com/proxmox/pve-installer/blob/b04864ece2654c6ecf794f9c3ad1cedede351532/proxinstall#L729">on GitHub</a> if you’d like.</p>
				</li>
				<li>
					<p>See how different kinds of storage devices are enumerated? Now add <code class="language-plaintext highlighter-rouge">/dev/mmcblk</code> to the list like this:</p>
					<div class="language-perl highlighter-rouge">
						<div class="highlight">
							<pre class="highlight"><code> <span class="p">}</span> <span class="k">elsif</span> <span class="p">(</span><span class="nv">$dev</span> <span class="o">=~</span> <span class="sr">m|^/dev/[^/]+/hd[a-z]$|</span><span class="p">)</span> <span class="p">{</span>
     <span class="k">return</span> <span class="p">"</span><span class="si">${dev}$partnum</span><span class="p">";</span>
 <span class="p">}</span> <span class="k">elsif</span> <span class="p">(</span><span class="nv">$dev</span> <span class="o">=~</span> <span class="sr">m|^/dev/nvme\d+n\d+$|</span><span class="p">)</span> <span class="p">{</span>
     <span class="k">return</span> <span class="p">"</span><span class="si">${dev}</span><span class="s2">p</span><span class="si">$partnum</span><span class="p">";</span>
 <span class="p">}</span> <span class="k">elsif</span> <span class="p">(</span><span class="nv">$dev</span> <span class="o">=~</span> <span class="sr">m|^/dev/mmcblk\d+$|</span><span class="p">)</span> <span class="p">{</span>
     <span class="k">return</span> <span class="p">"</span><span class="si">${dev}</span><span class="s2">p</span><span class="si">$partnum</span><span class="p">";</span>
 <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
     <span class="nb">die</span> <span class="p">"</span><span class="s2">unable to get device for partition </span><span class="si">$partnum</span><span class="s2"> on device </span><span class="si">$dev</span><span class="se">\n</span><span class="p">";</span>
 <span class="p">}</span>
</code></pre>
						</div>
    </div>
				</li>
				<li>Save your edits and type <code class="language-plaintext highlighter-rouge">exit</code>. Proceed with the installation as normal. Select <code class="language-plaintext highlighter-rouge">/dev/mmcblk0</code> (without the <code class="language-plaintext highlighter-rouge">bootX</code> suffix) as the install target. You may want to disable swap to avoid rapid wearing of the eMMC.</li>
				<li>The next time you have a shell, use <code class="language-plaintext highlighter-rouge">exit</code> to skip it. Nothing to do here.</li>
			</ol>
			<h2 id="rambling">Rambling</h2>
			<p>While it’s possible to install Proxmox VE on top of a matching version of Debian, it’s tedious to install Debian <em>just for PVE</em>. The last time I had to do it this way was on very old hardware that the PVE installer just crashed (X server died), and that the PVE installer didn’t have a CLI version. Plus a standard Debian installation typically comes with extra stuff that you don’t want on a PVE system (or want to get rid of ASAP).</p>
			<p>It’s also possible to modify the installer script beforehand, but you need to unpack <code class="language-plaintext highlighter-rouge">pve-installer.squashfs</code> and re-pack it into the ISO. You should think more seriously if you want to install PVE on a lot of eMMC devices.</p>
			]]></content><author><name>iBug</name></author><category term="linux" /><summary type="html"><![CDATA[Recently I bought a mini PC looking forward to setting up a home router. It started quite well except the specs were higher than I anticipated. 8 GB RAM plus 128 GB eMMC - too much waste for “just a router”, so I figured I’d get some virtual machines to improve its utilization. Choosing the virtualization platform isn’t hard - I’m most familiar with Proxmox VE.]]></summary></entry><entry><title type="html">New Pandora’s box: Install Linux and Windows onto the same NTFS partition</title><link href="https://ibug.io/blog/2021/11/linux-windows-amalgam-monster-ntfs/" rel="alternate" type="text/html" title="New Pandora’s box: Install Linux and Windows onto the same NTFS partition" /><published>2021-11-28T00:00:00+00:00</published><updated>2021-11-28T04:39:20+00:00</updated><id>https://ibug.io/blog/2021/11/linux-windows-amalgam-monster-ntfs</id><content type="html" xml:base="https://ibug.io/blog/2021/11/linux-windows-amalgam-monster-ntfs/"><![CDATA[<p>Linux 5.15 is shipped with a brand new driver for Microsoft’s classic NTFS filesystem, <a href="https://www.techrepublic.com/article/linux-kernel-5-15-is-now-available-and-it-has-something-special-for-ntfs-users/">NTFS3</a>. Unlike the decades-old open-source NTFS-3G project, which is based on FUSE and have always received criticism for breaking existing filesystems, NTFS3 is a new driver that is designed to be compatible with contemporary NTFS filesystems, while providing safer read/write operations. This makes it possible to install Linux onto NTFS (as is with most other filesystems), and opens up a whole new can of worms: run Linux alongside Windows, TOGETHER.</p>
		<div class="notice--danger">
			<h4 class="no_toc" id="warning"><i class="fas fa-exclamation-triangle"></i> WARNING</h4>
			<p>This is COMPLETELY EXPERIMENTAL. If you are not familiar with either Linux or Windows, <strong>do not try this</strong>.</p>
		</div>
		<p>Sounds WEIRD to me. I’m going to do this experiment on my Proxmox VE cluster.</p>
		<p><img src="/image/linux/monster/vm-create.png" alt="Create virtual machine" class="border" /></p>
		<h2 id="preparation">Preparation</h2>
		<h3 id="archiso">Archiso</h3>
		<p>At the time of writing this article, the latest Arch Linux ISO (2021.11.01) was shipped with Kernel <strong>5.14</strong>.15 - no new NTFS3 driver. I need to create one for myself or this won’t work.</p>
		<p><a href="https://wiki.archlinux.org/title/archiso">Archiso</a> is Arch’s official tool for creating custom ISO images. I’m not normally an Arch user, so I choose to install Arch first from an official ISO (20211101) before wiping it.</p>
		<p><img src="/image/linux/monster/install-arch-partition.png" alt="Partitioning in Arch ISO" /></p>
		<p>After this temporary system is set up, I just follow the Archiso guide and receive my own <code class="language-plaintext highlighter-rouge">archlinux-2021.11.22-x86_64.iso</code> with no trouble. It has Kernel <strong>5.15</strong>.4 packed.</p>
		<p>I copy the ISO onto the Proxmox VE host system, reboot the VM with this new ISO and wipe <code class="language-plaintext highlighter-rouge">/dev/sda2</code> to avoid (possible) further issues with the Windows installer. I also format <code class="language-plaintext highlighter-rouge">/dev/sda1</code> again to ensure I’m really starting over anew.</p>
		<h3 id="install-windows">Install Windows</h3>
		<p>Since NTFS is developed by Microsoft and for Windows, it seems reasonable to assume Windows is best suited for NTFS. So I’ll install Windows first lest it recognizes the filesystem created by <code class="language-plaintext highlighter-rouge">mkfs.ntfs</code> (from the old <code class="language-plaintext highlighter-rouge">ntfs-3g</code> package) as “foreign” and complains anyhow.</p>
		<p>The installation process of Windows 10 has always been as boring and mundane as it is, so I’m not going to be verbose here. Following the usual steps, except that the disk has already been partitioned, it’s easy to get Windows 10 up and ready.</p>
		<p><img src="/image/linux/monster/install-win10-oobe.png" alt="Windows 10 OOBE screen" /></p>
		<p>Proceeding through the out-of-box experience and I get to the desktop. There’s not many things of interest here, so I just shutdown the VM and take a snapshot.</p>
		<p>Now it’s time to get this compound monstrosity set up.</p>
		<h2 id="the-main-show">The Main Show</h2>
		<p>Swap the CD/DVD drive image for the newly created archiso and boot it up:</p>
		<p><img src="/image/linux/monster/install-archiso.png" alt="CD/DVD image selection" /></p>
		<p>With the proper Linux kernel equipped, I can now mount the NTFS partition create by Windows installer. It seems NTFS is sophisticated enough to even allow Unix filesystem attibutes, like file modes (permissions) and ownership, as well as “special file types” like symbolic links and named sockets (Unix domain sockets). This may hint that bootstrapping a Linux system should not be too problematic.</p>
		<div class="language-shell highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code>fdisk <span class="nt">-l</span> /dev/sda  <span class="c"># confirm partition layout</span>
mount <span class="nt">-t</span> ntfs3 /dev/sda2 /mnt
<span class="nb">mkdir</span> <span class="nt">-p</span> /mnt/boot/efi
mount /dev/sda1 /mnt/boot/efi
pacstrap /mnt base linux linux-firmware
</code></pre>
			</div>
		</div>
		<p>Indeed, <code class="language-plaintext highlighter-rouge">pacstrap</code> goes so smoothly that I almost forget it’s on a non-native filesystem. The only thing that makes me concerned is that <strong>there’s no <code class="language-plaintext highlighter-rouge">fsck</code> tool for NTFS</strong> (<em>file not found: <code class="language-plaintext highlighter-rouge">fsck.ntfs3</code></em> in console output).</p>
		<p><img src="/image/linux/monster/install-arch-pacstrap.png" alt="pacstrap output" /></p>
		<p>Now I can chroot into the system and set up the rest of the system.</p>
		<div class="language-shell highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code>genfstab <span class="nt">-U</span> /mnt <span class="o">&gt;&gt;</span> /mnt/etc/fstab
arch-chroot /mnt
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
vim /etc/locale.gen  <span class="c"># add en_US.UTF-8 UTF-8</span>
<span class="nb">echo </span>monster <span class="o">&gt;</span> /etc/hostname
passwd <span class="nt">-d</span> root
<span class="nb">exit</span>  <span class="c"># quit chroot environment, return to archiso</span>
</code></pre>
			</div>
		</div>
		<p>Fixing the bootloader is a bit different than usual, as Linux detects NTFS partitions as <code class="language-plaintext highlighter-rouge">ntfs</code>, not <code class="language-plaintext highlighter-rouge">ntfs3</code>. In case of auto mounting, Linux will try to mount with <code class="language-plaintext highlighter-rouge">-t ntfs</code>, which is not available (it’s provided by ntfs-3g). Fortunately, there’s a <code class="language-plaintext highlighter-rouge">rootfstype=</code> <a href="https://wiki.archlinux.org/title/kernel_parameters">kernel command-line parameter</a> to override the “filesystem type” parameter when mounting.</p>
		<p>Putting this into action:</p>
		<div class="language-shell highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code>arch-chroot /mnt
<span class="c"># configure networking</span>
pacman <span class="nt">-Sy</span> grub efibootmgr
vim /etc/default/grub
<span class="c"># remove "quiet" from GRUB_CMDLINE_LINUX</span>
<span class="c"># set GRUB_CMDLINE_LINUX_DEFAULT="rootfstype=ntfs3"</span>
grub-install
grub-mkconfig <span class="nt">-o</span> /boot/grub/grub.cfg
</code></pre>
			</div>
		</div>
		<p><img src="/image/linux/monster/install-arch-grub.png" alt="Install GRUB for Arch Linux" /></p>
		<p>To make things a bit more interesting, I’m adding a desktop environment:</p>
		<div class="language-shell highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code>pacman <span class="nt">-Sy</span> gnome
<span class="c"># select some items - not everything</span>
</code></pre>
			</div>
		</div>
		<p>And configure networking as well:</p>
		<div class="language-shell highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code><span class="nb">cd</span> /etc/systemd/network
vim ens18.network
<span class="nb">cd</span> ../system
<span class="nb">ln</span> <span class="nt">-s</span> /lib/systemd/system/systemd-networkd.service multi-user.target.wants/
</code></pre>
			</div>
		</div>
		<p>All set, let’s give it a try.</p>
		<h2 id="usage-experience">Usage experience</h2>
		<p>Arch Linux plays surprisingly well with the new NTFS3 filesystem driver.</p>
		<p><img src="/image/linux/monster/after-arch-neofetch.png" alt="System information in Arch Linux" /></p>
		<p>To keep things simple, I didn’t install too much software. During my testing, the only issue I encountered was that <code class="language-plaintext highlighter-rouge">ldconfig</code> never worked. It always aborts.</p>
		<p><img src="/image/linux/monster/arch-terminal-sigabrt.png" alt="ldconfig stops working" /></p>
		<p>A non-issue is that there’s no working <code class="language-plaintext highlighter-rouge">fsck</code> tool, and there’s a systemd service “Fsck at boot” that consequently fails. It’s not as useful so I just disabled it.</p>
		<p>The pioneer from r/archlinux said the system breaks after a few reboots, which didn’t happen to me. On the contrary, my Arch Linux was considerably resistant to Windows, and survived multiple Windows Updates, one Microsoft Update, and a few more. It even survived a CHKDSK despite a bunch of files being reported for “invalid filename” because <a href="https://stackoverflow.com/a/25477235/5958455">Windows dislikes colons in filenames</a> (not that NTFS doesn’t support).</p>
		<h2 id="thoughts">Thoughts</h2>
		<p>I must admit I’m amazed at how exquisitely NTFS is designed. It’s so mature that it hasn’t even been updated <a href="https://en.wikipedia.org/wiki/NTFS#Versions">since Windows XP</a>. One important part of NTFS is its Extended Attributes (EA) for files. Every NTFS filesystem contains a special file named <code class="language-plaintext highlighter-rouge">$MFT</code> located under its root directory. This is the metadata for all files, including file names, “normal attributes” and ACL, among which is the EA. Every file has an associated entry for EA, which can contain an arbitrary number of attributes (key-value pairs). In fact, the first generation of Windows Subsystem for Linux (WSL) stores Linux file modes and permissions <a href="https://docs.microsoft.com/en-us/windows/wsl/file-permissions">using custom EA keys</a>, which gets adapted by the new NTFS3 driver. Other EA keys are also used as needed, like <code class="language-plaintext highlighter-rouge">security.capability</code>, which is a 20-byte bitset. (Interestingly, EA was originally designed for compatibility with HPFS, which also has a similarly-extensible “Extended Attributes”.)</p>
		<p>The new NTFS3 driver is a delighting improvement to the Linux ecosystem. Complaints about the classic NTFS-3G driver <a href="https://superuser.com/q/613869/688600">have</a> <a href="https://www.reddit.com/r/linuxquestions/comments/73v5pi/why_is_ntfs_on_linux_so_slow/">always</a> <a href="https://askubuntu.com/q/187813/612877">been</a> <a href="https://unix.stackexchange.com/q/107978/211239">around</a>. Performance was one of the primary concerns because it not only is based on FUSE (Filesystem in USErspace), but also badly optimized. Use of FUSE means extra context switches when accessing files, which, paired with hard-coded 4 KiB read/write unit, delivers unusually slow access speeds.</p>
		<p>While the NTFS3 driver is a bit more optimized, concerns around compatibility are still encompassing. This is mainly because it’s still built on knowledge obtained from reverse engineering than technical documentation and standard. Fortunately, stability for NTFS-3G is already at a satisfactory level, and the new driver is thought to be more reliable than the old one.</p>
		<p>Besides, this is a perfect example of Linux’s inclusiveness. Years before the commencement of the new NTFS3 driver, <a href="https://github.com/CyanoHao/NTFS-as-rootfs">attempts were made</a> to run Linux on top of NTFS using NTFS-3G. This leads to an interesting question: Will Linux run on top of FAT32? Technical difficulties are more conspicuous and critical this time, like lack of support and extensibility for file modes and more. I’ll explore into this challenge and share my findings in a subsequent blog post. Stay tuned!</p>
		<h2 id="links--credits">Links &amp; Credits</h2>
		<ul>
			<li>Pioneer from r/archlinux: <a href="https://www.reddit.com/r/archlinux/comments/qwsftq/arch_linux_on_ntfs3/">Arch Linux on NTFS3!</a></li>
			<li>
				<p>Original idea by a GitHub user: <a href="https://gist.github.com/motorailgun/cc2c573f253d0893f429a165b5f851ee">Installing Windows and Linux into the same partition</a></p>
			</li>
		</ul>
		]]></content><author><name>iBug</name></author><category term="linux" /><category term="windows" /><summary type="html"><![CDATA[Linux 5.15 is shipped with a brand new driver for Microsoft’s classic NTFS filesystem, NTFS3. Unlike the decades-old open-source NTFS-3G project, which is based on FUSE and have always received criticism for breaking existing filesystems, NTFS3 is a new driver that is designed to be compatible with contemporary NTFS filesystems, while providing safer read/write operations. This makes it possible to install Linux onto NTFS (as is with most other filesystems), and opens up a whole new can of worms: run Linux alongside Windows, TOGETHER.]]></summary></entry><entry><title type="html">Reinstall Windows VPS into Linux with iPXE network boot</title><link href="https://ibug.io/blog/2021/11/convert-windows-vps-to-linux/" rel="alternate" type="text/html" title="Reinstall Windows VPS into Linux with iPXE network boot" /><published>2021-11-22T00:00:00+00:00</published><updated>2021-11-23T01:53:16+00:00</updated><id>https://ibug.io/blog/2021/11/convert-windows-vps-to-linux</id><content type="html" xml:base="https://ibug.io/blog/2021/11/convert-windows-vps-to-linux/"><![CDATA[<p>This November I found a discount from one of my favorite VPS providers, <a href="https://go.ibugone.com/vps-hk">NETfront</a>. They offered <strong>Linux VPS with 2 vCPUs and 2 GB RAM</strong> at HK$56/mo, and also <strong>Windows VPS with 4 vCPUs and 4 GB RAM</strong> at HK$49/mo. Looks strange, right? Why buy the crappy Linux VPS when you can have a better configuration with <em>less</em> money (if possible)?</p>
	<p class="notice--primary"><strong>Note</strong>: I knew this VPS provider ran <a href="https://www.proxmox.com/en/proxmox-ve">Proxmox VE</a> because I already had their VPSs. They’d give you a Proxmox VE noVNC console when you click “Console” to manage your VPS, from which you know they’re using QEMU/KVM as their virtualization platform. Direct access to QEMU screen is <em>awesome</em>!</p>
	<h2 id="get-vps">Get a VPS</h2>
	<p>First I head to the shopping cart to order a Windows VPS.</p>
	<p><img src="/image/linux/ipxe/vps-buy.png" alt="VPS SKU item" class="border" style="border-radius: 12px;" /></p>
	<p>Nice offer. It comes with unlimited traffic rate limited to 20 Mbps (BTW, it’s full duplex using Proxmox VE’s built-in “Rate Limit” feature for QEMU/KVM). I complete an order and get to create a VM for this service.</p>
	<p>Completely expected, only Windows images are available for choosing.</p>
	<p><img src="/image/linux/ipxe/vps-create.png" alt="VPS creation page" /></p>
	<p>That doesn’t matter, since I’m prepared to bypass the provided VM images and set it up on my own, so I picked <em>Disabled</em> for KVM OS Template. Hopefully it’ll speed up the VM creation process a bit, which, well, wouldn’t matter after all 😊.</p>
	<p>The next part involves a bit of patient waiting. The VM creation took quite a few minutes, perhaps to reserve that 128 GB of HDD? It would probably make sense to wipe the reserved area lest any previous data be left behind, which is a good practice in terms of security. Whatever, now the new VPS is ready, and I can see some basic information about it. I take down the IP address because later in iPXE environment I need to configure it as a static IP address.</p>
	<p><img src="/image/linux/ipxe/vps-status.png" alt="VPS ready" /></p>
	<p>Because I did not choose an OS template for the VPS, it must boot from network (which is true even if I <em>did</em> take a template).</p>
	<p><img src="/image/linux/ipxe/vps-boot-order.png" alt="Set boot order of VPS" style="border-radius: 6px;" /></p>
	<p>Now it’s time to start working!</p>
	<h2 id="network-booting-with-ipxe">Network booting with iPXE</h2>
	<p>iPXE is an open-source PXE (network boot) firmware, and is built into QEMU, ready for use.</p>
	<p>I open up the noVNC console and start the VPS. When I see “Press ESC for Boot Menu”, I go for it for the iPXE menu.</p>
	<p><img src="/image/linux/ipxe/ipxe-boot.png" alt="iPXE boot screen" /></p>
	<p>iPXE tries to configure network automatically using DHCP, but since the VPS environment does not have DHCP, I have to manually configure the network.</p>
	<p><img src="/image/linux/ipxe/ipxe-config.png" alt="iPXE configure IP address" /></p>
	<p>Now it’s time to load some boot source. <a href="https://netboot.xyz/docs/booting/ipxe">Netboot.xyz</a> is the first Google result for “publix pxe boot server”, so I’ll trust it for good.</p>
	<div class="notice--danger">
		<h4 class="no_toc" id="trap"><i class="fas fa-bug"></i> Trap</h4>
		<p>I previously got trapped following its <a href="https://netboot.xyz/docs/quick-start">quick start</a> guide. It didn’t boot for me and just dropped network connection mid-way. Turns out the <a href="https://netboot.xyz/docs/booting/ipxe"><em>Boot using iPXE</em></a> guide is the one I should follow.</p>
	</div>
	<p>According to <a href="https://netboot.xyz/docs/booting/ipxe">Netboot.xyz documentation</a>, the only command needed after network is up is <code class="language-plaintext highlighter-rouge">chain</code>. Noting that the iPXE firmware built into QEMU does not support HTTPS, I use plaintext HTTP instead. The final commands used in iPXE environment are here:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="nb">set </span>net0/ip 192.0.2.2           <span class="c"># Replace with your IP address</span>
<span class="nb">set </span>net0/netmask 255.255.255.0  <span class="c"># Replace as needed</span>
<span class="nb">set </span>net0/gateway 192.0.2.1      <span class="c"># Replace with your gateway address</span>
<span class="nb">set </span>dns 8.8.8.8
ifopen net0
chain <span class="nt">--autofree</span> http://boot.netboot.xyz
</code></pre>
		</div>
	</div>
	<p>Within a few seconds, I see the OS selection screen.</p>
	<p><img src="/image/linux/ipxe/ipxe-netboot.xyz.png" alt="Loaded Netboot.xyz from iPXE" /></p>
	<p>Debian has always been my #1 choice for servers, no reason to miss it. Select Linux Network Installs and look for Debian Bullseye.</p>
	<p><img src="/image/linux/ipxe/ipxe-install-debian.png" alt="Debian network installer" /></p>
	<p>Now I’m halfway to success as Debian installer shows up. There’s still a small note: the Debian installer doesn’t “inherit” network settings from the iPXE firmware, so it must be configured again for Debian. The auto configuration attempt will fail and Debian will prompt for manual configuration. Not any difficult.</p>
	<p><img src="/image/linux/ipxe/ipxe-install-debian-network.png" alt="Configure network for Debian installer" /></p>
	<p>Now it’s time to wipe Windows (where’s Windows?) and install Linux!</p>
	<p><img src="/image/linux/ipxe/ipxe-install-debian-disk.png" alt="Configure disk partitions for Debian" /></p>
	<p>Select <code class="language-plaintext highlighter-rouge">deb.debian.org</code> as package source since this is a Hong Kong VPS and not a mainland China one, and proceed through the rest of the process. After a reboot, I can see the login screen of the newly installed OS. Hooray!</p>
	<p><img src="/image/linux/ipxe/debian-ok.png" alt="Debian ready" /></p>
	<p>If I replace <code class="language-plaintext highlighter-rouge">linux-image-amd64</code> with <code class="language-plaintext highlighter-rouge">linux-image-cloud-amd64</code>, I can free up some 100 MB disk space than the default setup:</p>
	<p><img src="/image/linux/ipxe/debian-df.png" alt="Debian DF" /></p>
	<p>That’s it. With just some small efforts, this is now an afforable, high-spec Linux VPS.</p>
	<p>While the VPS control panel would never offer Linux templates should anything go wrong, it’s always possible to boot from iPXE again for a “rescue environment”.</p>
	<h2 id="easter-egg">Easter Egg</h2>
	<p>During Debian installation, the installer automatically added the <code class="language-plaintext highlighter-rouge">hyperv-daemon</code> package after examining hardware. After booting into Debian, <code class="language-plaintext highlighter-rouge">systemd-detect-virt</code> reports “microsoft” (i.e. Windows Hyper-V). This VPS hosting provider may have some black magic with their Windows VPS cluster so that QEMU/KVM behaves so. This issue doesn’t seem to exist in their “native” Linux VPS, but it’s worth noting.</p>
	]]></content><author><name>iBug</name></author><category term="linux" /><category term="networking" /><summary type="html"><![CDATA[This November I found a discount from one of my favorite VPS providers, NETfront. They offered Linux VPS with 2 vCPUs and 2 GB RAM at HK$56/mo, and also Windows VPS with 4 vCPUs and 4 GB RAM at HK$49/mo. Looks strange, right? Why buy the crappy Linux VPS when you can have a better configuration with less money (if possible)?]]></summary></entry><entry><title type="html">Secure site-to-site connection with Linux IPsec VPN</title><link href="https://ibug.io/blog/2021/10/linux-ipsec-with-ip-xfrm/" rel="alternate" type="text/html" title="Secure site-to-site connection with Linux IPsec VPN" /><published>2021-10-23T00:00:00+00:00</published><updated>2021-10-24T00:43:55+00:00</updated><id>https://ibug.io/blog/2021/10/linux-ipsec-with-ip-xfrm</id><content type="html" xml:base="https://ibug.io/blog/2021/10/linux-ipsec-with-ip-xfrm/"><![CDATA[<p>Linux has a built-in framework for Internet Protocol Security (IPsec), which is often combined with other tunneling technologies (e.g. <a href="https://en.wikipedia.org/wiki/Layer_2_Tunneling_Protocol">L2TP</a> and <a href="https://en.wikipedia.org/wiki/Generic_Routing_Encapsulation">GRE</a>) to create secure cross-site network connections. As an innovative attempt to a lab in this semester’s Network Security course, which was designed to work over multiple Windows Server 2003 virtual machines (VM), I decided to go on my own and proceed with Linux VMs.</p>
	<p>As covered in <a href="/blog/2021/01/linux-container-explained/#namespaces">my previous blog</a>, one of the fundamentals of a Linux container is namespaces, among which the network namespace is of great interest here. Since a network namespace creates a copy of the entire network stack, it’s suitable as a substitute for a full VM for this lab. This enables me to work on this lab with lightweight containers on my Proxmox VE cluster.</p>
	<h2 id="setting-up-network">Setting up network</h2>
	<p>The lab is designed to work on VirtualBox platform, and the network structure is laid out as follows:</p>
	<p><img src="/image/linux/ipsec/network-structure-vbox.png" alt="VirtualBox network structure" /></p>
	<p>As <a href="https://pve.proxmox.com/wiki/Network_Configuration#_naming_conventions">Proxmox VE requires</a> bridges to be named as <code class="language-plaintext highlighter-rouge">vmbr#</code> where <code class="language-plaintext highlighter-rouge">#</code> is a number, I renamed the networks as follows:</p>
	<p><img src="/image/linux/ipsec/network-structure-pve.png" alt="Proxmox VE network structure" /></p>
	<p>To create the networks, I edit <code class="language-plaintext highlighter-rouge">/etc/network/interfaces</code> to append these lines:</p>
	<div class="language-plaintext highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>auto vmbr91
iface vmbr91 inet manual
    bridge_ports none
    bridge_stp off
    bridge_fd 0

auto vmbr92
iface vmbr92 inet manual
    bridge_ports none
    bridge_stp off
    bridge_fd 0

auto vmbr95
iface vmbr95 inet manual
    bridge_ports none
    bridge_stp off
    bridge_fd 0

auto vmbr96
iface vmbr96 inet manual
    bridge_ports none
    bridge_stp off
    bridge_fd 0
</code></pre>
		</div>
	</div>
	<p>The <code class="language-plaintext highlighter-rouge">bridge_stp</code> and <code class="language-plaintext highlighter-rouge">bridge_fd</code> options turns off <a href="https://en.wikipedia.org/wiki/Spanning_Tree_Protocol">STP</a>, which is <a href="https://wiki.debian.org/BridgeNetworkConnections#Configuring_bridging_in_.2Fetc.2Fnetwork.2Finterfaces">usually a better choice</a> in a virtualized environment.</p>
	<p>I then bring up the new bridges so VMs can later be attached to:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>ifup vmbr91 vmbr92 vmbr95 vmbr96
</code></pre>
		</div>
	</div>
	<p>Now it’s time to set up the VMs.</p>
	<h2 id="setting-up-containers">Setting up containers</h2>
	<p>As explained above, container is an excellent replacement for full-fledged virtual machines for this lab, so I create containers using the Proxmox VE web interface.</p>
	<p><img src="/image/linux/ipsec/create-ct.png" alt="Create CT" /></p>
	<p>It’s also helpful to make a plan for the container IDs first, since I will heavily utilize <code class="language-plaintext highlighter-rouge">pct enter</code> to get into the container. The web console won’t work with some shortcut keys, notably <kbd>Ctrl</kbd>+<kbd>W</kbd> and <kbd>Ctrl</kbd>+<kbd>T</kbd>.</p>
	<table>
		<thead>
			<tr>
				<th>Container (Name)</th>
				<th>ID</th>
				<th>Network</th>
				<th>IP Address</th>
			</tr>
		</thead>
		<tbody>
			<tr>
				<td>Router</td>
				<td>980</td>
				<td>vmbr95<br />
					vmbr96</td>
				<td>10.55.55.55/24<br />
					10.66.66.66/24</td>
			</tr>
			<tr>
				<td>Server A</td>
				<td>981</td>
				<td>vmbr91<br />
					vmbr95</td>
				<td>192.168.1.1/24<br />
					10.55.55.1/24<br />
					Gateway 10.55.55.55</td>
			</tr>
			<tr>
				<td>Server B</td>
				<td>982</td>
				<td>vmbr92<br />
					vmbr96</td>
				<td>192.168.2.1/24<br />
					10.66.66.1/24<br />
					Gateway 10.66.66.66</td>
			</tr>
			<tr>
				<td>Client A</td>
				<td>983</td>
				<td>vmbr91</td>
				<td>192.168.1.2<br />
					Gateway 192.168.1.1</td>
			</tr>
			<tr>
				<td>Client B</td>
				<td>984</td>
				<td>vmbr92</td>
				<td>192.168.2.2<br />
					Gateway 192.168.2.1</td>
			</tr>
		</tbody>
	</table>
	<p>Also I’m more comfortable with newer software, so I go with the Debian 11 template provided by Proxmox.</p>
	<p><img src="/image/linux/ipsec/create-ct-template.png" alt="Select template" /></p>
	<p>The rest of the settings aren’t of much interest, and the default settings should suffice. On a side note, 2 GB is more than abundant for Root Disk because I need virtually no extra software to work on this lab.</p>
	<p><img src="/image/linux/ipsec/create-ct-confirm.png" alt="CT configuration" /></p>
	<p>Don’t start the container right now, because there’s another network interface to be added. I head to the page to add <code class="language-plaintext highlighter-rouge">eth6</code> for the router, connecting to <code class="language-plaintext highlighter-rouge">vmbr96</code> as illustrated in the graph.</p>
	<p><img src="/image/linux/ipsec/router-add-network.png" alt="Add network interface to Router" /></p>
	<p>To save some time, I created the remaining containers using <code class="language-plaintext highlighter-rouge">pct</code> command. The command for creating CT 981 is as follows and the others are similar (omitted for brevity).</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>pct create 981 nfs-template:vztmpl/debian-11-standard_11.0-1_amd64.tar.gz <span class="se">\</span>
  <span class="nt">--rootfs</span> local-lvm:2 <span class="se">\</span>
  <span class="nt">--hostname</span> ibug-ServerA <span class="se">\</span>
  <span class="nt">--net0</span> <span class="nv">name</span><span class="o">=</span>eth1,bridge<span class="o">=</span>vmbr91,firewall<span class="o">=</span>0,ip<span class="o">=</span>192.168.1.1/24 <span class="se">\</span>
  <span class="nt">--net1</span> <span class="nv">name</span><span class="o">=</span>eth5,bridge<span class="o">=</span>vmbr95,firewall<span class="o">=</span>0,ip<span class="o">=</span>10.55.55.1/24,gw<span class="o">=</span>10.55.55.55 <span class="se">\</span>
  <span class="nt">--unprivileged</span> 1
</code></pre>
		</div>
	</div>
	<p>Now that the containers have been created, it’s time to get some extra software ready for the lab.</p>
	<p><img src="/image/linux/ipsec/cts.png" alt="Containers ready" /></p>
	<h3 id="configure-containers">Configure containers</h3>
	<p>The lab originally requires capturing traffic with Wireshark on Windows Server, but on Linux it’s more typical to do this with <code class="language-plaintext highlighter-rouge">tcpdump</code>, which needs to be installed on the Router. Additionally to make working and debugging easier, <code class="language-plaintext highlighter-rouge">tcpdump</code> and a text editor of your choice should also go on <strong>the Router and the two Servers</strong>. So I install Vim and <code class="language-plaintext highlighter-rouge">tcpdump</code> on all three containers mentioned. No extra software is needed for the two Clients.</p>
	<p>You may find it easier to temporarily change the network setting to allow the container to connect to the APT repository, install the software and then change it back.</p>
	<p>But for me I’d rather “just do it”, so I connect the Router container to the external network and run <code class="language-plaintext highlighter-rouge">apt install</code> as needed.</p>
	<p><img src="/image/linux/ipsec/install-software.png" alt="Install software on Router" /></p>
	<p>And then I configure the router to perform NAT for other containers to reach the outer world, so that I can do <code class="language-plaintext highlighter-rouge">apt install</code> directly (<code class="language-plaintext highlighter-rouge">iptables</code> lines). It’s also helpful to configure the routing table so the Clients can reach each other easily (<code class="language-plaintext highlighter-rouge">ip route</code> lines).</p>
	<p><img src="/image/linux/ipsec/setup-nat.png" alt="Configure firewall and routing" /></p>
	<p>I also need to enable IP forwarding on the Router and both Servers.</p>
	<p><img src="/image/linux/ipsec/enable-ip-forward.png" alt="Enable IP forwarding" /></p>
	<p>I can now see that Client A can reach Client B correctly. If I do packet capturing on the Router or either Server, I can see plaintext traffic going through.</p>
	<p><img src="/image/linux/ipsec/tcpdump-plain.png" alt="tcpdump plain traffic" /></p>
	<p>If you can reach here, it means your lab environment is now ready as I do.</p>
	<h2 id="ipsec-rules">IPsec rules</h2>
	<p>Linux provides native support for IPsec via the XFRM framework, and the (primitive) tool to manage it is the <code class="language-plaintext highlighter-rouge">ip xfrm</code> command. The XFRM framework matches packets with <strong>policies</strong> (as <strong>Security Policies, SP</strong>) and transforms (hence the name) packets with <strong>states</strong> (as <strong>Security Associations, SA</strong>). SP and SA are managed through two subcommands, <code class="language-plaintext highlighter-rouge">ip xfrm policy</code> and <code class="language-plaintext highlighter-rouge">ip xfrm state</code>, and there’s one last subcommand <code class="language-plaintext highlighter-rouge">ip xfrm monitor</code> that may come in handy from time to time.</p>
	<h3 id="ip-xfrm-command">ip-xfrm command</h3>
	<p>The syntax for <code class="language-plaintext highlighter-rouge">ip xfrm policy</code> is as follows. Only <code class="language-plaintext highlighter-rouge">add</code> and <code class="language-plaintext highlighter-rouge">delete</code> are given because we’re not interested in others. The full syntax can always be seen via <code class="language-plaintext highlighter-rouge">ip xfrm policy help </code> and <a href="https://man7.org/linux/man-pages/man8/ip-xfrm.8.html">the man page</a>.</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>ip xfrm policy add SELECTOR <span class="nb">dir </span>DIR tmpl TMPL <span class="o">[</span> tmpl TMPL <span class="o">]</span>...
ip xfrm policy delete SELECTOR <span class="nb">dir </span>DIR
ip xfrm policy flush  <span class="c"># deletes everything</span>

SELECTOR :<span class="o">=</span> <span class="o">[</span> src IP/CIDR <span class="o">]</span> <span class="o">[</span> dst IP/CIDR <span class="o">]</span> <span class="o">[</span> dev DEV <span class="o">]</span> <span class="o">[</span> UPSPEC <span class="o">]</span>
DIR :<span class="o">=</span> <span class="k">in</span> | out | fwd
TMPL :<span class="o">=</span> <span class="o">[</span> src IP <span class="o">]</span> <span class="o">[</span> dst IP <span class="o">]</span> <span class="o">[</span> proto PROTO <span class="o">]</span>
        <span class="o">[</span> spi SPI <span class="o">]</span> <span class="o">[</span> mode MODE <span class="o">]</span> <span class="o">[</span> reqid REQID <span class="o">]</span>
MODE :<span class="o">=</span> transport | tunnel
</code></pre>
		</div>
	</div>
	<p>The syntax for <code class="language-plaintext highlighter-rouge">ip xfrm state</code> is as follows. Similarly, <code class="language-plaintext highlighter-rouge">ip xfrm state help</code> gives the full syntax.</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>ip xfrm state add TMPL ALGO <span class="o">[</span> ALGO <span class="o">]</span>...
ip xfrm state delete TMPL
ip xfrm state flush  <span class="c"># deletes everything</span>

ALGO :<span class="o">=</span> <span class="o">{</span> enc | auth <span class="o">}</span> ALGO-NAME ALGO-KEY |
        aead ALGO-NAME ALGO-KEY ALGO-ICV-LEN
</code></pre>
		</div>
	</div>
	<h4 id="one-important-note">One important note</h4>
	<p>Among all the elements there’s one I’d like to specifically note: the direction <code class="language-plaintext highlighter-rouge">dir</code> isn’t quite the same as <code class="language-plaintext highlighter-rouge">INPUT</code> / <code class="language-plaintext highlighter-rouge">OUTPUT</code> / <code class="language-plaintext highlighter-rouge">FORWARD</code> as in the iptables firewall. Instead it carries the following meaning (<a href="https://serverfault.com/a/1048382/450575">source</a>):</p>
	<table>
		<thead>
			<tr>
				<th>Security Policy</th>
				<th>Meaning</th>
			</tr>
		</thead>
		<tbody>
			<tr>
				<td>Output policy (dir out)</td>
				<td>SP works as a selector on <strong>outgoing packets</strong> to select which are to be encrypted+encapsulated (analogous to firewall <code class="language-plaintext highlighter-rouge">POSTROUTING</code> chain)</td>
			</tr>
			<tr>
				<td>Input policy (dir in)</td>
				<td>SP works as a selector on <strong>incoming packets which already have been decrypted+decapsulated</strong> and have a destination IP local to the system (analogous to firewall <code class="language-plaintext highlighter-rouge">INPUT</code> chain)</td>
			</tr>
			<tr>
				<td>Forward policy (dir fwd)</td>
				<td>SP works as a selector on <strong>incoming packets which already have been decrypted+decapsulated</strong> and have a destination IP not local to the system (analogous to firewall <code class="language-plaintext highlighter-rouge">FORWARD</code> chain)</td>
			</tr>
		</tbody>
	</table>
	<p>So the direction works like this:</p>
	<ul>
		<li>The <code class="language-plaintext highlighter-rouge">dir out</code> is for encryption policies</li>
		<li>The <code class="language-plaintext highlighter-rouge">dir in</code> and <code class="language-plaintext highlighter-rouge">dir fwd</code> is to select and filter encrypted packets</li>
	</ul>
	<p>The curious may now ask: Where are the decryption policies?</p>
	<p>The answer is: The Security Associations! (Surprise!)</p>
	<p>Incoming IPsec packets (ESP, AH etc.) that match a SA will <em>always</em> be decrypted, regardless of configured SPs (so SA is analogous to the firewall <code class="language-plaintext highlighter-rouge">PREROUTING</code> chain). <strong>However</strong>, if the decrypted packet (or plain traffic) does not match a valid SP, it’s silently dropped and no further processing in the Linux network stack is done.</p>
	<p>I got trapped in this part for an hour in my initial experiments because it’s just too intuitive to misunderstand how <code class="language-plaintext highlighter-rouge">dir</code> works. And that’s why I’m taking a special note on this.</p>
	<h3 id="configure-ipsec-rules">Configure IPsec rules</h3>
	<p>Because I want to enable the Clients to connect to each other via the Servers, I configure <strong>an output policy and a forwarding policy</strong> on both Servers (with the opposite directions, of course).</p>
	<p>I add the Security Associations on Server A with the following commands. Note that it’s often better to generate the keys randomly than using a easily guessable value.</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="nv">SPI</span><span class="o">=</span>0x69427567
<span class="nv">AUTHKEY</span><span class="o">=</span>0x0123456789ABCDEF0123456789ABCDEF
<span class="nv">ENCKEY</span><span class="o">=</span>0xFEDCBA9876543210FEDCBA9876543210

ip xfrm state add <span class="se">\</span>
  src 10.55.55.1 dst 10.66.66.1 proto esp spi <span class="nv">$SPI</span> mode tunnel <span class="se">\</span>
  auth sha256 <span class="nv">$AUTHKEY</span> enc aes <span class="nv">$ENCKEY</span>
ip xfrm state add <span class="se">\</span>
  src 10.66.66.1 dst 10.55.55.1 proto esp spi <span class="nv">$SPI</span> mode tunnel <span class="se">\</span>
  auth sha256 <span class="nv">$AUTHKEY</span> enc aes <span class="nv">$ENCKEY</span>
</code></pre>
		</div>
	</div>
	<p>As the encrypted packets will be transported through the virtual “public Internet”, the source and destination addresses must be those of the public interfaces on the Servers.</p>
	<p>You can of course use different Security Parameter Indices and keys for both directions, but I choose the same parameters for simplicity.</p>
	<p>I then add the Security Policies on Server A with the following commands:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>ip xfrm policy add <span class="se">\</span>
  src 192.168.1.0/24 dst 192.168.2.0/24 <span class="nb">dir </span>out <span class="se">\</span>
  tmpl src 10.55.55.1 dst 10.66.66.1 proto esp spi <span class="nv">$SPI</span> mode tunnel
ip xfrm policy add <span class="se">\</span>
  src 192.168.2.0/24 dst 192.168.1.0/24 <span class="nb">dir </span>fwd <span class="se">\</span>
  tmpl src 10.66.66.1 dst 10.55.55.1 proto esp spi <span class="nv">$SPI</span> mode tunnel
</code></pre>
		</div>
	</div>
	<p>I also add the Security Associations on Server B with the same Security Parameter Index, Authentication Key and Encryption Key. The commands are identical to those run on Server A.</p>
	<p>The Security Policies require minimal changes: <code class="language-plaintext highlighter-rouge">dir out</code> and <code class="language-plaintext highlighter-rouge">dir fwd</code> should be swapped on Server B. The <code class="language-plaintext highlighter-rouge">ip xfrm policy add</code> commands are otherwise identical.</p>
	<p>Now I enter Client A to see if Client B is still reachable:</p>
	<p><img src="/image/linux/ipsec/ping-with-ipsec.png" alt="Client A still reaches Client B" /></p>
	<p>However, <code class="language-plaintext highlighter-rouge">tcpdump</code> on the Router shows Encrypted Security Payload instead of any plain traffic:</p>
	<p><img src="/image/linux/ipsec/tcpdump-esp.png" alt="tcpdump showing ESP packets" /></p>
	<p>The packet capturing shows that traffic between Server A and Server B is correctly encrypted with IPsec, so that communication between the two “sites” are now secured (except the key is weak).</p>
	<h2 id="inspecting-traffic-with-wireshark">Inspecting traffic with Wireshark</h2>
	<p>In fact, <code class="language-plaintext highlighter-rouge">tcpdump</code> supports dumping captured packets to file in Pcap format, which is a universal format also supported by the popular GUI software Wireshark.</p>
	<p>To start over again with a “clean” IPsec tunnel, I reset the Security Policies and Security Associations with</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>ip xfrm policy flush
ip xfrm state flush
</code></pre>
		</div>
	</div>
	<p>And then I reapply all Policies and Associations with the commands shown in the previous section.</p>
	<p>I start capturing packets to file with <code class="language-plaintext highlighter-rouge">tcpdump</code>:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>tcpdump <span class="nt">-ni</span> eth5 <span class="nt">-w</span> a.pcap ip and not arp
</code></pre>
		</div>
	</div>
	<p>I add filter expression to reduce noise (get rid of ARP and IPv6 NDP stuff), and again I send some traffic from Client A to Client B. I capture 10 packets here, which is enough for illustration purposes.</p>
	<p>I take the Pcap file from the container to my (Windows) computer, and open it with Wireshark:</p>
	<p><img src="/image/linux/ipsec/wireshark-no-decryption.png" alt="Pcap file in Wireshark" /></p>
	<p>The captured packets are correct - they’re encrypted in ESP format.</p>
	<p>I then head to <strong>Edit → Preferences</strong>, locate <strong>Protocol » ESP</strong> on the left, and add the Security Associations used in this experiment. I also tick the “<em>Attempt to detect/decode ecnrypted ESP payloads</em>” checkbox.</p>
	<p><img src="/image/linux/ipsec/wireshark-import-esp-sa.png" alt="Add ESP SA in Wireshark" /></p>
	<p>Now I go back to the main screen, and I can see that Wireshark decrypts the ESP payload using the SAs I just supplied. The inner packet data is revealed to be ICMP packets because I use Ping to perform the reachability test all the way.</p>
	<p><img src="/image/linux/ipsec/wireshard-decrypted.png" alt="Wireshark showing decrypted ESP data" /></p>
	<p>Wireshark also highlights all packets because they are identified to belong to the same “connection” (ICMP session).</p>
	<p>If you’re wondering, the decrypted payload content (shown in the “Decrypted Data” tab at the bottom) is a complete IPv4 packet, plus ESP metadata like authentication information and a “Next Header” value. The Next Header is the same as the “Protocol” field in an ordinary IPv4 packet. For an IPv4 packet encapsulated, the Next Header value is 4, which is the same value as “IP-in-IP tunnel”. For carried IPv6 traffic, the Next Header value is 41, the value for “IP6-in-IP tunnel” (or Simple Internet Transition, SIT).</p>
	<h3 id="easter-egg">Easter egg</h3>
	<p>Before loading SAs into Wireshark, I noticed it showing an interesting note for every other packet:</p>
	<p><img src="/image/linux/ipsec/wireshark-expected-sn.png" alt="Wireshark suggesting alternative sequence number" /></p>
	<p>This is because Wireshark is identifying streams by SPI, which is normally different for every IPsec stream, including both directions between the same pair of tunnel endpoints. When I’m using the same SPI for both directions, Wireshark gets confused and mistakes them for one stream, and suggests incrementing sequence numbers for “repeated” packets.</p>
	<h2 id="bonus-ipsec-tunnel-mode-vs-ip-in-ip-tunneling-inside-ipsec-transport-mode">Bonus: IPsec tunnel mode vs. IP-in-IP tunneling inside IPsec transport mode</h2>
	<p class="notice--primary">Big shoutout to my friend <a href="https://github.com/RTXUX">@RTXUX</a> who originally came up with this idea!</p>
	<p>Notice how Wireshark shows the “decrypted data” as a complete IP packet, and that the “Next Header” field in the outer ESP packet is 4 (<a href="https://en.wikipedia.org/wiki/IP_in_IP">IP-in-IP tunneling protocol</a>):</p>
	<p><img src="/image/linux/ipsec/bonus-wireshark-decrypted-data.png" alt="Wireshark decrypted payload" /></p>
	<p>Recalling the differences between IPsec transport mode and tunnel mode as taught in class or covered by <a href="https://docs.oracle.com/cd/E36784_01/html/E36838/ipsecov-13.html">Oracle’s documentation</a>:</p>
	<blockquote>
		<ul>
			<li>In transport mode, the IP addresses in the outer header are used to determine the IPsec policy that will be applied to the packet.</li>
			<li>In tunnel mode, two IP headers are sent. The inner IP packet determines the IPsec policy that protects its contents.</li>
		</ul>
	</blockquote>
	<p>It’s reasonable to wonder if the tunnel mode is equivalent to the transport mode with an identical IP-in-IP tunnel inside. This wouldn’t sound too silly because with an IP-based tunneling protocol like IP-in-IP or GRE, we’re literally wrapping up the inner payload and using the tunneling protocol as a means of transport (at Transport Layer), and the Transport Layer is exactly what’s carried in an IPsec transport mode packet. The only way to find this out is with practice.</p>
	<p>To test if they’re compatible, continuing from the end state of the course lab, I reset all Security Policies and Security Associations on Server A while leaving Server B intact.</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="c"># on Server A</span>
ip xfrm policy flush
ip xfrm state flush
</code></pre>
		</div>
	</div>
	<p>The test setup would be an IP-in-IP tunnel as it has the same protocol number (4) as the ESP payload, so I create one on Server A first.</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>ip tunnel add ipip0 mode ipip <span class="nb">local </span>10.55.55.1 remote 10.66.66.1 ttl 64
ip <span class="nb">link set </span>ipip0 up
</code></pre>
		</div>
	</div>
	<p>I also need to setup routing, since I don’t have IPsec policies to wrap it up for me. (Note: You can add a network address to this tunnel interface, but it’s not necessary.)</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>ip route add 192.168.2.0/24 dev ipip0
</code></pre>
		</div>
	</div>
	<p>Then I wrap it up with the same IPsec policies, except that the mode has been switched to “transport” and there’s no longer a “forward” direction, since the transported packets are IP-in-IP packets with the two servers being the source and the destination:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>ip xfrm policy add <span class="se">\</span>
  src 10.55.55.1 dst 10.66.66.1 <span class="nb">dir </span>out <span class="se">\</span>
  tmpl src 10.55.55.1 dst 10.66.66.1 proto esp spi <span class="nv">$SPI</span> mode transport
ip xfrm policy add <span class="se">\</span>
  src 10.66.66.1 dst 10.55.55.1 <span class="nb">dir </span><span class="k">in</span> <span class="se">\</span>
  tmpl src 10.66.66.1 dst 10.55.55.1 proto esp spi <span class="nv">$SPI</span> mode transport
</code></pre>
		</div>
	</div>
	<p>The Security Associations need no change as the encrypted packets will have the same source, destination and SPI.</p>
	<p>With Server B retaining its original setup, I can confirm that Client A can still reach Client B:</p>
	<p><img src="/image/linux/ipsec/bonus-ping-with-ipsec.png" alt="Client A still reaches Client B" /></p>
	<p>This phenomenon at least proves that IPsec tunnel mode is compatible with IP-in-IP tunnel inside IPsec transport mode.</p>
	<p>Same as above, I perform packet capturing on the Router and compare the results in Wireshark:</p>
	<p><img src="/image/linux/ipsec/bonus-wireshark-compare.png" alt="Comparing packet streams in Wireshark" /></p>
	<p>Seeing how they have identical structures, I can now draw the conclusion that the two modes are fully equivalent, <em>if properly set up</em>.</p>
	<h3 id="caveats">Caveats</h3>
	<p>I emphasized <em>properly set up</em> at the end of the last line above. This is because Linux implements IPsec as a <em>policy-based</em> VPN (and so does Windows), as opposed to <em>route-based</em> VPNs (with OpenVPN being a common example). There’s a difference worth noting.</p>
	<ul>
		<li>
			<p><strong>Policy-based VPN</strong> matches and works on <em>outgoing packets</em>, which may have already gone through multiple levels of routing decisions, and are recaptured before they leave the network processing stack.</p>
			<p>Wikipedia has an excellent graph showing the packet flow in Linux network stack, and you can see that “xfrm lookup” happens right before the packet processing ends.</p>
			<p><img src="https://upload.wikimedia.org/wikipedia/commons/3/37/Netfilter-packet-flow.svg" alt="Packet flow in Linux network stack" /></p>
			<p>Policy-based VPN has the advantage of minimizing the setup job, as it works as a tunnel and handles transport policies on its own, but is sometimes less convenient for being a separate facility from the already-complicated routing policies and NAT rules that a common network gateway may already have. Also, you may want to avoid multiple levels of encryption for both performance reasons and <a href="https://security.stackexchange.com/a/18104/168307">security concerns</a>, which further adds to the complexity of your Security Policies and management efforts.</p>
		</li>
		<li>
			<p><strong>Route-based VPN</strong> creates a virtual network interface (usually either TUN or TAP) and applies cryptographic transformations to traffic sent to or received from this interface. It has the advantage of integrating perfectly with existing routing policies, NAT rules, firewall (if the firewall is configured on the tunnel endpoint) and even packet capturing. As route-based VPNs use the same routing policy database (RPDB) as the main network stack, you can even run dynamic routing protocols inside, like OSPF or BGP. In fact, it is a very common modus operandi in <a href="https://en.wikipedia.org/wiki/Decentralized_network_42">DN42</a> to connect with <a href="https://en.wikipedia.org/wiki/WireGuard">WireGuard</a> and run BGP inside.</p>
			<p>Depending on the software used, it may be even easier to setup a route-based VPN (like OpenVPN), but traffic filtering needs to be done from inside. This is virtually the only disadvantage of route-based VPN.</p>
		</li>
	</ul>
	<p>It’s often a matter of choice between these options. There are more route-based VPN implementations (OpenVPN, WireGuard etc.) but enterprise support for policy-based VPN is more mature, so a decision is to be made when it comes to deployment. I personally never used policy-based VPN outside this lab because I often need complex routing policies and NAT rules that policy VPNs are bad at, but YMMV.</p>
	<h2 id="troubleshooting">Troubleshooting</h2>
	<p>Finally, if you are going to use my article as a hands-on tutorial for setting up a similar lab, some troubleshooting experiences and tips would certainly turn useful.</p>
	<ul>
		<li>Creating <code class="language-plaintext highlighter-rouge">ip xfrm state</code> results in <em>Protocol not supported</em>: Check on the Proxmox VE host if <code class="language-plaintext highlighter-rouge">modprobe xfrm4_tunnel</code> works correctly. It may fail with <em>Unknown symbol in module</em> or <em>Invalid argument</em>. In either case, update the Linux kernel package to the latest and reboot the host.</li>
		<li>Decrypted packets not found except in <code class="language-plaintext highlighter-rouge">tcpdump</code>: Check <code class="language-plaintext highlighter-rouge">/proc/net/xfrm_stat</code> and see which number is going up. This kernel interface provides statistics for packets dropped by the XFRM framework. Refer to <a href="https://www.kernel.org/doc/Documentation/networking/xfrm_proc.txt">the kernel documentation</a> to see what each number means.</li>
		<li><strong>Bonus section:</strong>
			<ul>
				<li><code class="language-plaintext highlighter-rouge">ip tunnel add</code> showing <code class="language-plaintext highlighter-rouge">add tunnel "tunl0": failed: No such device</code>: The <code class="language-plaintext highlighter-rouge">ipip</code> and <code class="language-plaintext highlighter-rouge">tunnel4</code> modules need to be loaded on the host. A simple <code class="language-plaintext highlighter-rouge">modprobe</code> command should do it</li>
			</ul>
		</li>
	</ul>
	]]></content><author><name>iBug</name></author><category term="linux" /><category term="networking" /><summary type="html"><![CDATA[Linux has a built-in framework for Internet Protocol Security (IPsec), which is often combined with other tunneling technologies (e.g. L2TP and GRE) to create secure cross-site network connections. As an innovative attempt to a lab in this semester’s Network Security course, which was designed to work over multiple Windows Server 2003 virtual machines (VM), I decided to go on my own and proceed with Linux VMs.]]></summary></entry><entry><title type="html">Disassembling a hardware RAID 1 array in Proxmox VE</title><link href="https://ibug.io/blog/2021/08/proxmox-disassemble-hardware-raid1/" rel="alternate" type="text/html" title="Disassembling a hardware RAID 1 array in Proxmox VE" /><published>2021-08-15T00:00:00+00:00</published><updated>2021-08-16T01:05:26+00:00</updated><id>https://ibug.io/blog/2021/08/proxmox-disassemble-hardware-raid1</id><content type="html" xml:base="https://ibug.io/blog/2021/08/proxmox-disassemble-hardware-raid1/"><![CDATA[<p>Yesterday in a server maintenance period, we decided to tune the storage layout of our Proxmox VE server, which included disassembling a RAID 1 array and adjusting the size of the root filesystem.</p>
	<h2 id="backup-data">Backup data</h2>
	<p class="notice--danger">As is always, potentially destructive disk operations should be preceded with a backup of anything necessary for recovery.</p>
	<p>Proxmox VE uses a kind of “standard” partition layout, with the first 512 MB of the primary disk allocated for the EFI System Partition (ESP), and the rest forming an LVM physical volume (PV), which then becomes a volume group (VG) named <code class="language-plaintext highlighter-rouge">pve</code>. In the <code class="language-plaintext highlighter-rouge">pve</code> VG, a fifth of total available space is allocated to the root filesystem for the Proxmox VE system, and the rest goes to a thin pool named <code class="language-plaintext highlighter-rouge">data</code>.</p>
	<p>The initial disk layout on our server is like this:</p>
	<p><img src="/image/proxmox-raid1/initial-fdisk.png" alt="Initial disk layout" /></p>
	<p>The system is booted with UEFI, so the first partition can be safely ignored. The second partition is the ESP and contains no critical data, as it can be rebuilt when needed. The only thing left for backup is the rootfs since we haven’t made use of the <code class="language-plaintext highlighter-rouge">data</code> volume. A good news is that the rootfs only has less then 3.5 GB of content (we have separate storages for the system and our virtual machines), so backing up is as easy as allocating a 4 GB volume on our data storage and copying the whole rootfs over with <a href="https://www.samba.org/rsync/">Rsync</a>:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>rsync <span class="nt">-aHAXx</span> / /mnt/backup/
</code></pre>
		</div>
	</div>
	<p>In addition, it’s been said in <a href="https://superuser.com/a/137310/688600">this Super User answer</a> that</p>
	<blockquote>
		<p>Of course, it may be a complete jerk for you and wipe the drives for no good reason, but this is very unlikely.</p>
	</blockquote>
	<p>So we might not even need that backup (in fact we didn’t). After all, it’s better safe than sorry, isn’t it?</p>
	<h2 id="disassemble-array">Disassembling the RAID array</h2>
	<p>The standard procedure for this is to reboot into BIOS setup and change the settings there.</p>
	<p>I reboot the server, hitting F9 on its POST screen.</p>
	<p><img src="/image/proxmox-raid1/hpe-enter-bios.png" alt="HPE POST Screen" /></p>
	<p>Next, I locate the built-in RAID controller. It’s called “HPE Smart Array”. I navigate into the options, locate the RAID-1 array, and select “Delete Array”. It completes just in a flash.</p>
	<p><img src="/image/proxmox-raid1/hpe-bios-array-setting.png" alt="HPE Array Setting" /></p>
	<p>To ensure the changes take effect, I reboot the server again.</p>
	<h2 id="restore-partitions">Restore the partition table</h2>
	<p>Because the disks may previously contain some RAID information at their start, their content may not be recognized now, so I insert a virtual CD-ROM drive using the “Virtual Media” feature provided by the Baseboard Management Controller (BMC, also known as IPMI). It’s good we have a file server providing these handy resources. As the host system has been updated to <a href="https://pve.proxmox.com/wiki/Roadmap#Proxmox_VE_7.0">Proxmox VE 7</a>, I picked the new Debian Bullseye Live CD instead of Buster. This ensures I can start the server for disk recovery jobs.</p>
	<p><img src="/image/proxmox-raid1/set-virtual-media.png" alt="Insert ISO from IPMI" /></p>
	<p>This time I enter “One-Time Boot Menu” to boot from the CD-ROM. I select “iLO Virtual CD-ROM” and it starts up.</p>
	<p><img src="/image/proxmox-raid1/hpe-bios-boot-from-iso.png" alt="Select boot item" /></p>
	<p>In a few seconds, the Debian boot screen shows up.</p>
	<p><img src="/image/linux/debian-11-livecd.png" alt="Debian Bullseye GRUB screen" /></p>
	<p>Now I can run <code class="language-plaintext highlighter-rouge">fdisk</code> to check the disk status. As expected, no partitions are found.</p>
	<p>Given that the “Delete Array” operation completes so quickly, I’m sure it did nothing to data stored on the disk, so I can try recovering the partition table. <a href="https://linux.die.net/man/1/testdisk"><code class="language-plaintext highlighter-rouge">testdisk</code></a> is one of the utilities that do this job.</p>
	<p><img src="/image/proxmox-raid1/after-disassembly-fdisk.png" alt="Disk layout after disassembly" /></p>
	<p>The terminal interface of testdisk is straightforward. Select the only disk given (<code class="language-plaintext highlighter-rouge">/dev/sda</code>, the one you gave it as CLI argument), select the previous partition table type (testdisk tells you if it can find out, which matches that in the first image of this article), and select “Analyze”.</p>
	<p><img src="/image/proxmox-raid1/testdisk-disk-type.png" alt="Testdisk select disk type" /></p>
	<p>If testdisk found a partition table in the previous screen, the analyze step doesn’t need a second - it will just show the discovered partition. If it didn’t find anything, you can still run “Quick Search” and get your partition table back.</p>
	<p><img src="/image/proxmox-raid1/testdisk-analysis.png" alt="Testdisk partition analysis" /></p>
	<p>In my case, I just select “Backup” and proceed to next step. Testdisk is smart enough to discard the first nonsense partition (it’s completely redundant on a UEFI system), and I’m left with two.</p>
	<p><img src="/image/proxmox-raid1/testdisk-overview.png" alt="Testdisk found partitions" /></p>
	<p>There’s no change I need to make at this stage, so I just proceed to the final screen and let testdisk write the partition table.</p>
	<p><img src="/image/proxmox-raid1/testdisk-confirm.png" alt="Testdisk confirm partitions" /></p>
	<p>Although testdisk tells me “<em>You will have to reboot for the change to take effect</em>”, calling <code class="language-plaintext highlighter-rouge">partprobe</code> is all that’s necessary. Now I can confirm with <code class="language-plaintext highlighter-rouge">fdisk</code> that the partition table has been restored.</p>
	<p><img src="/image/proxmox-raid1/restored-fdisk.png" alt="Restored disk layout" /></p>
	<p class="notice--info"><code class="language-plaintext highlighter-rouge">partprobe</code> doesn’t come with Debian Bullseye live CD (it did with Debian Buster). To get the command I installed <code class="language-plaintext highlighter-rouge">parted</code> package.</p>
	<h2 id="shrink-rootfs">Shrinking the root filesystem</h2>
	<p>It’s a complete waste to give the rootfs a whopping 96 GB when we only use some 3.5 GB, so I go to shrink it down to 16 GB.</p>
	<p>Before shrinking the volume, it’s necessary to shrink the <em>filesystem</em> first. Yes, a “partition” and a “filesystem” are two different concepts.</p>
	<p>The rootfs of Proxmox VE resides in LVM, so the first thing is to get LVM tools up and running. I tried <code class="language-plaintext highlighter-rouge">apt install lvm2</code>, and was (a bit) surprised to found that it came with Debian Bullseye Live CD.</p>
	<p>I get back the VG <code class="language-plaintext highlighter-rouge">pve</code> by <code class="language-plaintext highlighter-rouge">vgscan</code>, and make all LVs available for operation by <code class="language-plaintext highlighter-rouge">vgchange -ay pve</code>. I can then mount <code class="language-plaintext highlighter-rouge">/dev/pve/root</code> somewhere and check the volume usage with <code class="language-plaintext highlighter-rouge">df -h</code>. Just around 4 gigs, we’re good.</p>
	<p>Many years ago I read <a href="https://matt.berther.io/2015/02/03/how-to-resize-aws-ec2-ebs-volumes/">this blog by Matt Berther</a> about shrinking EBS volumes on AWS EC2. The same solution is still applicable here (though years of Linux experience relieved me of the need for the blog as a reference).</p>
	<p>I unmount the rootfs and run <code class="language-plaintext highlighter-rouge">e2fsck -f /dev/pve/root</code> to ensure a clean state of the filesystem, followed by <code class="language-plaintext highlighter-rouge">resize2fs -M -p /dev/pve/root</code> to perform the shrinking.</p>
	<p><img src="/image/proxmox-raid1/shrink-rootfs.png" alt="Shrinking rootfs" /></p>
	<p>After the filesystem is shrunk, I shrink the logical volume with <code class="language-plaintext highlighter-rouge">lvresize -L 16G pve/root</code>. Then I grow the filesystem back to the full size of the volume with <code class="language-plaintext highlighter-rouge">resize2fs -p /dev/pve/root</code> (without the <code class="language-plaintext highlighter-rouge">-M</code> option).</p>
	<p><img src="/image/proxmox-raid1/grow-rootfs.png" alt="Restore rootfs" /></p>
	<h2 id="convert-rootfs-to-mirrored">Restoring rootfs to “RAID” state</h2>
	<p>The main reason we set up RAID 1 for these disks is to provide resilience against disk failures, so we can still have the system running if either disk dies. Completely breaking up the RAID array defeats this purpose, so it’s helpful to at least add the rootfs back to the mirrored state.</p>
	<p>Luckily, <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/logical_volume_manager_administration/mirror_create">LVM provides the ability</a> to create mirrored volumes. Converting an existing one is even easier:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>lvconvert <span class="nt">-m1</span> pve/root
</code></pre>
		</div>
	</div>
	<p>The command failed for an obvious reason: There’s only one disk in the VG.</p>
	<p>Recalling that a RAID 1 array has just been broken up, there’s <code class="language-plaintext highlighter-rouge">/dev/sdb</code> with an identical partition structure available. I repeat the same steps to recover the partition table on <code class="language-plaintext highlighter-rouge">/dev/sdb</code>, and wiped <code class="language-plaintext highlighter-rouge">/dev/sdb2</code> to avoid conflict. I can then add it to the VG as a second PV:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="nb">dd </span><span class="k">if</span><span class="o">=</span>/dev/zero <span class="nv">of</span><span class="o">=</span>/dev/sdb2 <span class="nv">bs</span><span class="o">=</span>1M <span class="nv">count</span><span class="o">=</span>1
pvcreate /dev/sdb2
vgextend pve /dev/sdb2
</code></pre>
		</div>
	</div>
	<p>Now I can convert the rootfs to “mirrored” volume.</p>
	<p><img src="/image/proxmox-raid1/extend-vg.png" alt="Extend volume group" /></p>
	<p>The “data” volume can also be extended to take all remaining space as well:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>lvextend <span class="nt">-l</span> +100%FREE pve/data
</code></pre>
		</div>
	</div>
	<h2 id="fix-grub">Fixing up GRUB</h2>
	<p>To ensure the system can boot up normally, GRUB should be updated. This needs to be done in chroot inside the original system environment. A bunch of mounts must be setup for GRUB reinstallation to work.</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>mount /dev/pve/root /srv

<span class="c"># systemd-udev requires these two directories to be available</span>
mount <span class="nt">-o</span> rbind /run /srv/run
mount <span class="nt">-o</span> rbind /tmp /srv/tmp

<span class="nb">chroot</span> /srv
mount <span class="nt">-t</span> devtmpfs _ /dev
mount /dev/sda1 /boot/efi
mount <span class="nt">-t</span> proc _ /proc
mount <span class="nt">-t</span> sysfs _ /sys
</code></pre>
		</div>
	</div>
	<p>Now I can replace <code class="language-plaintext highlighter-rouge">grub-pc</code> with <code class="language-plaintext highlighter-rouge">grub-efi</code> with <code class="language-plaintext highlighter-rouge">apt install grub-efi</code>, and then run <code class="language-plaintext highlighter-rouge">grub-install</code> on both <code class="language-plaintext highlighter-rouge">/dev/sda1</code> and <code class="language-plaintext highlighter-rouge">/dev/sdb1</code> so that both disks are bootable.</p>
	<h2 id="fix-initrd">Fixing up ramdisk</h2>
	<div class="notice--info">
		<h4 class="no_toc" id="save-yourself-some-hassle"><i class="fas fa-lightbulb"></i> Save yourself some hassle</h4>
		<p>This paragraph tells a trap I encountered. If you’re following this article as a step-by-step guide, you can skip this paragraph and do this instead:</p>
		<ol>
			<li>Either install <code class="language-plaintext highlighter-rouge">mdadm</code>, or</li>
			<li>Edit <code class="language-plaintext highlighter-rouge">/etc/initramfs-tools/modules</code> and append two lines <code class="language-plaintext highlighter-rouge">dm_raid</code> and <code class="language-plaintext highlighter-rouge">raid1</code>.</li>
		</ol>
		<p>After picking an action above, run <code class="language-plaintext highlighter-rouge">update-initramfs -u -k all</code> and you can proceed to rebooting from the live CD.</p>
	</div>
	<p>Looking at the checklist, everything should have been taken care of, so I reboot the server. The Proxmox GRUB screen passed as normal. To my surprise, the server is stuck at <em>Loading initial ramdisk</em>.</p>
	<p>To display more information for troubleshooting, I reboot the server again, pressing <code class="language-plaintext highlighter-rouge">e</code> on the GRUB screen so I can edit the boot item. I remove <code class="language-plaintext highlighter-rouge">quiet</code> and added <code class="language-plaintext highlighter-rouge">nomodeset</code> to the kernel command line (see <a href="https://askubuntu.com/q/716957/612877">Ask Ubuntu</a>), and hit Ctrl-X to boot. This does turn up something useful:</p>
	<p><img src="/image/proxmox-raid1/loading-initial-ramdisk-nomodeset.png" alt="Debug output for Loading initial ramdisk" /></p>
	<p>Google search for “raid: failed to run raid array” brings me to <a href="https://askubuntu.com/q/292092/612877">this Ask Ubuntu question</a>. Checking the answers and the comments, I reboot again into Debian Live CD, mount the rootfs, install <code class="language-plaintext highlighter-rouge">mdadm</code>, and <code class="language-plaintext highlighter-rouge">update-initramfs</code> again. The next reboot proved correct, and the Proxmox VE server is back up now.</p>
	<h2 id="other-stuff">Other stuff</h2>
	<p>At this point, this server maintenance job has been concluded. If you’re stumbling upon this article and find a mistake or have other questions, feel free to leave a comment below.</p>
	]]></content><author><name>iBug</name></author><category term="linux" /><summary type="html"><![CDATA[Yesterday in a server maintenance period, we decided to tune the storage layout of our Proxmox VE server, which included disassembling a RAID 1 array and adjusting the size of the root filesystem.]]></summary></entry><entry><title type="html">I switched from Google Chrome to Microsoft Edge</title><link href="https://ibug.io/blog/2021/06/switch-from-google-chrome-to-microsoft-edge/" rel="alternate" type="text/html" title="I switched from Google Chrome to Microsoft Edge" /><published>2021-06-12T00:00:00+00:00</published><updated>2021-06-12T03:08:23+00:00</updated><id>https://ibug.io/blog/2021/06/switch-from-google-chrome-to-microsoft-edge</id><content type="html" xml:base="https://ibug.io/blog/2021/06/switch-from-google-chrome-to-microsoft-edge/"><![CDATA[<p>Last year (maybe September? I don’t remember now) I switched my primary browser from Google Chrome to the new Microsoft Edge. It turned out to be a wise move and I’ve been with Edge for more than half a year now. In this article I’ll share my ideas with this move.</p>
	<h3 id="same-chromium-kernel">Same Chromium kernel</h3>
	<p>The moment Microsoft Edge went attractive was when I learned that <a href="https://www.browserstack.com/blog/chromium-based-edge/"><strong>it started to be based on Chromium</strong></a>, so that web pages will behave identially as if they were on Google Chrome or the Chromium browser. This is particularly important as I often engineer for Chrome when developing front-end applications.</p>
	<p>Beside that, the seamless availability of existing Chrome extensions is also a great plus. I rely heavily on several extensions to enhance my surfing experience, some of which are:</p>
	<ul>
		<li><a href="https://microsoftedge.microsoft.com/addons/detail/tampermonkey/iikmkjmpaadaobahmlepeloendndfphd">Tampermonkey</a></li>
		<li><a href="https://microsoftedge.microsoft.com/addons/detail/ublock-origin/odfafepnkmbhccpbejgmiehpchacaeak">uBlock Origin</a></li>
		<li>Proxy SwitchyOmega</li>
		<li><a href="https://microsoftedge.microsoft.com/addons/detail/https-everywhere/fchjpkplmbeeeaaogdbhjbgbknjobohb">HTTPS Everywhere</a></li>
	</ul>
	<p>Needless to say, the old EdgeHTML Edge browser was just disappointing, lacking many common browser features and a buggy rendering engine. I surely take it as a sensible move to replace the old kernel.</p>
	<h3 id="windows-integration">Integration with Windows</h3>
	<p>As for everything else designed for or ships with Windows, Microsoft Edge integrates excellently into Windows and other Microsoft online products.</p>
	<p>You can log in to Microsoft Edge with your Microsoft account with just one click, if you have the account set up with your Windows user. Then the syncing launches automatically, and your saved bookmarks, histories, forms etc. are readily available.</p>
	<p>A logged-in Microsoft Edge browser also eases the login process of most Microsoft products, like Office Online, OneDrive, or whatever web application using Microsoft OAuth login. As long as the browser is authenticated, the <code class="language-plaintext highlighter-rouge">login.microsoftonline.com</code> page proceeds automatically. This comes in handy when you want to maximize your operation on the web.</p>
	<p>For sensitive access like <code class="language-plaintext highlighter-rouge">account.microsoft.com</code>, Microsoft Edge will prompt you for your PIN (if you have it set up on the computer) or password via the native Windows authentication system, bringing the same level of security of your Windows login to browser Microsoft account access.</p>
	<h3 id="data-syncing">Data syncing</h3>
	<p>Since I’m already using OneDrive for my document storage and syncing, I feel my data safer with Microsoft, and so does my browser information. Just like Google Chrome, the new Microsoft Edge syncs everything across computers and mobile devices. For the best connected experience, I also fetched Microsoft Edge (Android) from Google Play Store and signed in there. This enabled me to continue where I left off from my computer right on my phone.</p>
	<p>One extra bonus point for mainland China users: Browser data sync for Microsoft Edge doesn’t require “over-the-wall” internet access. But for power users of Google Chrome (and Google search), I believe this isn’t an issue already.</p>
	<h3 id="better-pdf-reader">Better PDF reader</h3>
	<p>As with the old EdgeHTML version, the built-in PDF reader of Microsoft Edge outperforms that of all other browsers. Given its good performance and lower power consumption, it’s my PDF reader of choice on a business laptop that focuses on battery-run duration, so that I don’t need Adobe Acrobat for all its fancy features and battery hogging. Microsoft Edge provides all the basic functionalities I need on-the-go, like bookmarks nagivation and pen drawing.</p>
	<h3 id="better-performance">Better performance</h3>
	<p>Microsoft Edge, as promised, eats around 20% to 30% less memory than Google Chrome under the same load. This may not be a problem for beefy workstations with a lot of memory, but it surely plays a role in common househeld desktops and laptops. At a minimum, even if you don’t need to keep more tabs at the same time, the extra memory allows you to run other applications, or simply gives the computer a breath.</p>
	<h2 id="disadvantages">Disadvantages</h2>
	<p>Being relatively new as a consumer product, the new Microsoft Edge is still distant from perfection. There are quite a number of bugs or incomplete functionalities to spot.</p>
	<h3 id="missing-favicons">Missing favicons</h3>
	<p>The first thing it should fix is loading favicons for Favorites website. <strong>It doesn’t, at all.</strong> With a newly imported Favorites library from another browser, <strong>all favicons are missing</strong>. On contrary, Google Chrome tries to load as many as possible after importing bookmarks, which is usually done in a few minutes. This makes the initial setup particularly bothersome, as you now have to read every bookmark title to determine its target, when you <em>could have</em> done so just by skimming through the icons.</p>
	<p><img src="/image/microsoft-edge/missing-favicons.png" alt="image" /></p>
	<p>I really appreciate these blank icons. Thank you for reminding me of the 90’s nostagia of the web’s simplicity, Microsoft.</p>
	<h3 id="new-tab-page-search-locked-to-bing">“New Tab” page search locked to Bing</h3>
	<p>This one is obvious: Whatever you enter into the most noticeable input form will be searches <strong>via Bing</strong>. While in the settings Edge does allow you to choose a search provider for the <em>address bar</em>, it doesn’t, however, for the New Tab page. Google Chrome, however, does this with more sanity: The search provider for the address bar is also used for the New Tab page, giving you a consistent experience for searching.</p>
	<p>To be honest, I would’ve stood with it had Chrome also locked the New Tab page search to Google, which is what I’m using extensively. But Bing just never gives the same level of precision with its search results, so locking a search form to Bing gives me the impression that Microsoft is <em>condescending</em>.</p>
	<h2 id="summary">Summary</h2>
	<p>So far so good. I’ve stayed with Microsoft Edge since and overall it’s quite satisfactory. There are many other differences that makes my experiences with Edge subtly better than with Chrome, like larger UI buttons and menus. So unless you’re a 100% Google power user, I’d recommend the new Microsoft Edge to you, too.</p>
	]]></content><author><name>iBug</name></author><category term="software" /><category term="web" /><summary type="html"><![CDATA[Last year (maybe September? I don’t remember now) I switched my primary browser from Google Chrome to the new Microsoft Edge. It turned out to be a wise move and I’ve been with Edge for more than half a year now. In this article I’ll share my ideas with this move.]]></summary></entry><entry><title type="html">Tunight talk</title><link href="https://ibug.io/blog/2021/04/tunight-talk/" rel="alternate" type="text/html" title="Tunight talk" /><published>2021-04-17T00:00:00+00:00</published><updated>2021-04-17T21:55:43+00:00</updated><id>https://ibug.io/blog/2021/04/tunight-talk</id><content type="html" xml:base="https://ibug.io/blog/2021/04/tunight-talk/"><![CDATA[<p>class: center, middle</p>
	<h1 id="tech-talk">Tech Talk</h1>
	<p><a href="//ibug.io">iBug</a>
		<br />
		<a href="https://lug.ustc.edu.cn">LUG @ USTC</a>
		<br />
		April 17, 2021</p>
	<hr />
	<h2 id="overview">Overview</h2>
	<ul>
		<li>Intranet of USTCLUG</li>
		<li>Auto SSL certificate</li>
		<li>Vlab</li>
		<li>Miscellaneous</li>
	</ul>
	<hr />
	<h2 id="intranet-of-ustclug">Intranet of USTCLUG</h2>
	<ul>
		<li>Multiple cloud and on-premises servers in different datacenters</li>
		<li>Public and internal services
			<ul>
				<li>Public: Mirrors, Auth DNS, Homepage</li>
				<li>Internal: LDAP, Mail gateway, InfluxDB</li>
			</ul>
		</li>
	</ul>
	<p>–</p>
	<!-- -->
	<ul>
		<li>Layer 2 overlay network
			<ul>
				<li><a href="//www.tinc-vpn.org">Tinc VPN</a></li>
			</ul>
		</li>
	</ul>
	<hr />
	<h2 id="tinc-vpn">Tinc VPN</h2>
	<ul>
		<li>Configured in switch mode</li>
		<li>Mesh layout</li>
		<li><strong>Bridged within one datacenter (cluster)</strong></li>
		<li>Secured over the Internet</li>
	</ul>
	<hr />
	<iframe src="https://www.draw.io/?lightbox=1&amp;highlight=0000ff&amp;edit=_blank&amp;layers=1&amp;nav=1&amp;title=LUG%20Network.html#Uhttps%3A%2F%2Fdrive.google.com%2Fa%2F0x01.me%2Fuc%3Fid%3D1WAROAPB8ThTkIjMyFnGvtGgbH-TV4FWh%26export%3Ddownload" frameborder="0" style="width: 100%; height: 100%;"></iframe>
	<hr />
	<p>layout: true</p>
	<h2 id="automatic-ssl-certificate-issue--renewal">Automatic SSL certificate issue &amp; renewal</h2>
	<hr />
	<hr />
	<p>Compliance:</p>
	<ul>
		<li>Our friend sponsored us a Japan VPS so we resolve most of <code class="language-plaintext highlighter-rouge">ustclug.org</code> (from outside USTCnet) to it
			<ul>
				<li>We resolve <code class="language-plaintext highlighter-rouge">ustclug.org</code> to USTCnet when source is also in USTCnet</li>
			</ul>
		</li>
	</ul>
	<!-- -->
	<ul>
		<li>USTC Mirrors has 4 ISP connections (CERNET, Telecom, Mobile, Unicom) and we want to route users by source</li>
	</ul>
	<p>–</p>
	<!-- -->
	<ul>
		<li>Solution: Self-hosted Bind9 server
			<ul>
				<li>Return different answers based on source IP (views)</li>
			</ul>
		</li>
	</ul>
	<hr />
	<ul>
		<li>Solution: Self-hosted Bind9 server
			<ul>
				<li>Return different answers based on source IP (views)</li>
			</ul>
		</li>
		<li>Custom authoritative DNS servers</li>
	</ul>
	<p>–</p>
	<ul>
		<li>Git-based DNS management</li>
		<li>Integration into existing applications?
			<ul>
				<li>We have no easy-to-use API</li>
			</ul>
		</li>
	</ul>
	<hr />
	<p>layout: true</p>
	<h2 id="automatic-ssl-certificate-issue--renewal-1">Automatic SSL certificate issue &amp; renewal</h2>
	<p>Use an existing API!</p>
	<hr />
	<hr />
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="c"># apt list ~npython3-certbot-dns</span>
python3-certbot-dns-cloudflare    - Doesn<span class="s1">'t support sub-zones
python3-certbot-dns-digitalocean  - [OK]
python3-certbot-dns-dnsimple      - Paid
python3-certbot-dns-gandi         - Doesn'</span>t support sub-zones
python3-certbot-dns-gehirn        - <span class="o">[</span>Couldn<span class="s1">'t determine]
python3-certbot-dns-google        - Doesn'</span>t support sub-zones
python3-certbot-dns-linode        - No account, couldn<span class="s1">'t determine
python3-certbot-dns-ovh           - Could not register account
python3-certbot-dns-rfc2136       - Performance?
python3-certbot-dns-route53       - Paid
python3-certbot-dns-sakuracloud   - Could not register account
</span></code></pre>
		</div>
	</div>
	<p><code class="language-plaintext highlighter-rouge">acme.sh</code>?</p>
	<hr />
	<pre><code class="language-dns">_acme-challenge.lug.ustc.edu.cn.     600 IN CNAME  lug.ssl-digitalocean.ustclug.org.
_acme-challenge.ustclug.org.         600 IN CNAME  lug.ssl-digitalocean.ustclug.org.
_acme-challenge.proxy.ustclug.org.   600 IN CNAME  lug.ssl-digitalocean.ustclug.org.
_acme-challenge.mirrors.ustc.edu.cn. 600 IN CNAME  mirrors.ssl-digitalocean.ustclug.org.
</code></pre>
	<pre><code class="language-dns">ssl-digitalocean.ustclug.org.  86400 IN NS  ns1.digitalocean.com.
                               86400 IN NS  ns2.digitalocean.com.
                               86400 IN NS  ns3.digitalocean.com.
</code></pre>
	<hr />
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>acme.sh <span class="nt">--issue</span> <span class="se">\</span>
  <span class="nt">--dns</span> dns_dgon <span class="se">\</span>
  <span class="nt">--domain-alias</span> lug.ssl-digitalocean.ustclug.org <span class="se">\</span>
  <span class="nt">-d</span> lug.ustc.edu.cn <span class="se">\</span>
  <span class="nt">-d</span> <span class="se">\*</span>.lug.ustc.edu.cn <span class="se">\</span>
  <span class="nt">-d</span> ustclug.org <span class="se">\</span>
  <span class="nt">-d</span> <span class="se">\*</span>.ustclug.org <span class="se">\</span>
  <span class="nt">-d</span> <span class="se">\*</span>.proxy.ustclug.org <span class="se">\</span>
  <span class="nt">--cert-file</span> cert/lug/cert.pem <span class="se">\</span>
  <span class="nt">--key-file</span> cert/lug/privkey.pem <span class="se">\</span>
  <span class="nt">--fullchain-file</span> cert/lug/fullchain.pem
</code></pre>
		</div>
	</div>
	<hr />
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>acme.sh <span class="nt">--issue</span> <span class="se">\</span>
  <span class="nt">--dns</span> dns_dgon <span class="se">\</span>
  <span class="nt">--domain-alias</span> mirrors.ssl-digitalocean.ustclug.org <span class="se">\</span>
  <span class="nt">-d</span> mirrors.ustc.edu.cn <span class="se">\</span>
  <span class="nt">-d</span> <span class="se">\*</span>.mirrors.ustc.edu.cn <span class="se">\</span>
  <span class="nt">--cert-file</span> cert/mirrors/cert.pem <span class="se">\</span>
  <span class="nt">--key-file</span> cert/mirrors/privkey.pem <span class="se">\</span>
  <span class="nt">--fullchain-file</span> cert/mirrors/fullchain.pem
</code></pre>
		</div>
	</div>
	<hr />
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>git <span class="nt">-C</span> cert add <span class="nt">--all</span>
git <span class="nt">-C</span> cert <span class="nt">-c</span> user.name<span class="o">=</span>GitHub <span class="nt">-c</span> user.email<span class="o">=</span>noreply@github.com commit <span class="se">\</span>
    <span class="nt">-m</span> <span class="s2">"Update certificates on </span><span class="si">$(</span><span class="nb">date</span> +%Y-%m-%d<span class="si">)</span><span class="s2">"</span> <span class="se">\</span>
    <span class="nt">-m</span> <span class="s2">"</span><span class="si">$(</span>git log <span class="nt">-1</span> <span class="nt">--pretty</span><span class="o">=</span><span class="s1">'tformat:[%h] %an: %s'</span> HEAD<span class="si">)</span><span class="s2">"</span>
git <span class="nt">-C</span> cert push
</code></pre>
		</div>
	</div>
	<hr />
	<p>layout: true</p>
	<h2 id="vlab">Vlab</h2>
	<hr />
	<p><img src="https://vlab.ustc.edu.cn/docs/images/home.png" alt="" /></p>
	<hr />
	<p>layout: false
		class: center, middle</p>
	<div><img src="https://vlab.ustc.edu.cn/docs/images/vlab-in-browser.jpg" /></div>
	<hr />
	<p>layout: true</p>
	<h2 id="vlab-1">Vlab</h2>
	<hr />
	<ul>
		<li>Xilinx Vivado
			<ul>
				<li>Multiple GBs of <em>slow</em> downloading</li>
				<li>Hard to setup and maintain</li>
			</ul>
		</li>
		<li>Other software (MATLAB, Wolfram Mathematica etc.)
			<ul>
				<li>Same size &amp; complexity issues</li>
			</ul>
		</li>
	</ul>
	<p>–</p>
	<!-- -->
	<ul>
		<li>
			<s>Another VPS provider</s>
		</li>
		<li>LXC containers
			<ul>
				<li>Lightweight</li>
				<li>Host-manageable</li>
				<li>System container (<s>application container</s>)</li>
			</ul>
		</li>
	</ul>
	<hr />
	<ul>
		<li>Sharing &amp; Isolation</li>
	</ul>
	<p>–</p>
	<!-- -->
	<ul>
		<li>Storage allocation: LVM
			<ul>
				<li>iSCSI isn’t multi-mount-aware</li>
				<li>ZFS doesn’t support</li>
				<li>NFS = SPOF</li>
			</ul>
		</li>
	</ul>
	<p>–</p>
	<ul>
		<li>But why does LVM work?</li>
	</ul>
	<p>–</p>
	<ul>
		<li><strong>“Activated volume”</strong>
			<ul>
				<li>PVE native support: Only activate volumes in use by VMs/CTs</li>
			</ul>
		</li>
	</ul>
	<p>–</p>
	<!-- -->
	<ul>
		<li>Network isolation: VXLAN
			<ul>
				<li><span style="color: salmon;">❤</span> -50</li>
				<li>Solution: Increase host <span style="color: salmon;">❤</span> to 1550</li>
			</ul>
		</li>
	</ul>
	<hr />
	<p>User access:</p>
	<ul>
		<li>VNC unified login
			<ul>
				<li>10,000 lines of C++ (by <a href="//github.com/pdlan">pdlan</a>)
					<ul>
						<li>Identify users via VNC login username
							<ul>
								<li>Multi VM selection: <code class="language-plaintext highlighter-rouge">username:id</code></li>
							</ul>
						</li>
						<li>Queries Django for VM information</li>
					</ul>
				</li>
			</ul>
		</li>
		<li>Browser login: noVNC</li>
	</ul>
	<p>–</p>
	<ul>
		<li>SSH unified login
			<ul>
				<li>Modified from <a href="//github.com/tg123/sshpiper">tg123/sshpiper</a></li>
				<li>Pubkey-based user identificaion
					<ul>
						<li>Certificate-based VM access</li>
					</ul>
				</li>
			</ul>
		</li>
		<li>Browser login: Wetty (alpha)</li>
	</ul>
	<hr />
	<p>layout: false</p>
	<iframe src="https://vlab.ustc.edu.cn/grafana/d-solo/2/vlab-usage-statistics?orgId=1&amp;from=1587065070291&amp;to=1618601070291&amp;theme=light&amp;panelId=2" frameborder="0" style="width: 100%; height: 100%;"></iframe>
	<hr />
	<p>layout: true</p>
	<h2 id="miscellaneous">Miscellaneous</h2>
	<hr />
	<ul>
		<li>Protect ports of VM from host (iptables)
			<ul>
				<li>SSH-based “authentication” ✔</li>
			</ul>
		</li>
	</ul>
	<hr />
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>:INPUT DROP <span class="o">[</span>0:0]
<span class="c"># ...</span>
:iBug - <span class="o">[</span>0:0]
<span class="nt">-A</span> INPUT <span class="nt">-m</span> conntrack <span class="nt">--ctstate</span> RELATED,ESTABLISHED <span class="nt">-j</span> ACCEPT
<span class="nt">-A</span> INPUT <span class="nt">-i</span> lo <span class="nt">-j</span> ACCEPT
<span class="nt">-A</span> INPUT <span class="nt">-j</span> iBug
<span class="nt">-A</span> INPUT <span class="nt">-g</span> BLOCK

<span class="c"># ...</span>
<span class="nt">-A</span> iBug <span class="nt">-p</span> icmp <span class="nt">-j</span> ACCEPT
<span class="nt">-A</span> iBug <span class="nt">-p</span> tcp <span class="nt">-m</span> multiport <span class="nt">--dports</span> 22,80,443,8888,25565 <span class="nt">-j</span> ACCEPT
<span class="nt">-A</span> iBug <span class="nt">-m</span> <span class="nb">set</span> <span class="o">!</span> <span class="nt">--match-set</span> home src <span class="nt">-p</span> tcp <span class="nt">--dport</span> 3389 <span class="nt">-j</span> BLOCK
</code></pre>
		</div>
	</div>
	<p><code class="language-plaintext highlighter-rouge">/etc/iptables/ipsets</code>:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>create home <span class="nb">hash</span>:ip family inet <span class="nb">timeout </span>600
</code></pre>
		</div>
	</div>
	<hr />
	<p><code class="language-plaintext highlighter-rouge">~/.ssh/rc</code>:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="k">if</span> <span class="o">[</span> <span class="nt">-z</span> <span class="s2">"</span><span class="nv">$BASH</span><span class="s2">"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then
  </span><span class="nb">exec</span> /bin/bash <span class="nt">--</span> <span class="s2">"</span><span class="nv">$0</span><span class="s2">"</span> <span class="s2">"</span><span class="nv">$@</span><span class="s2">"</span>
  <span class="nb">exit </span>1
<span class="k">fi

</span><span class="nv">_ssh_client</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">SSH_CONNECTION</span><span class="p">%% *</span><span class="k">}</span><span class="s2">"</span>
<span class="nv">_ppid</span><span class="o">=</span><span class="s2">"</span><span class="si">$(</span>ps <span class="nt">-o</span> <span class="nv">ppid</span><span class="o">=</span> <span class="si">$(</span>ps <span class="nt">-o</span> <span class="nv">ppid</span><span class="o">=</span> <span class="nv">$PPID</span><span class="si">))</span><span class="s2">"</span>

<span class="nb">nohup</span> /home/ubuntu/.local/bin/_ssh_refresh_client <span class="s2">"</span><span class="nv">$_ssh_client</span><span class="s2">"</span> <span class="s2">"</span><span class="nv">$_ppid</span><span class="s2">"</span> &amp;&gt;/dev/null &amp; <span class="nb">exit </span>0
</code></pre>
		</div>
	</div>
	<hr />
	<p><code class="language-plaintext highlighter-rouge">_ssh_refresh_client</code>:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="k">if</span> <span class="o">[</span> <span class="nt">-z</span> <span class="s2">"</span><span class="nv">$BASH</span><span class="s2">"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then
  </span><span class="nb">exec</span> /bin/bash <span class="nt">--</span> <span class="s2">"</span><span class="nv">$0</span><span class="s2">"</span> <span class="s2">"</span><span class="nv">$@</span><span class="s2">"</span>
<span class="k">fi

</span><span class="nv">_ssh_client</span><span class="o">=</span><span class="s2">"</span><span class="nv">$1</span><span class="s2">"</span>
<span class="nv">_ppid</span><span class="o">=</span><span class="s2">"</span><span class="nv">$2</span><span class="s2">"</span>

<span class="k">while </span><span class="nb">kill</span> <span class="nt">-0</span> <span class="s2">"</span><span class="nv">$_ppid</span><span class="s2">"</span> 2&gt;/dev/null<span class="p">;</span> <span class="k">do
  </span><span class="nb">sudo </span>ipset <span class="nt">-exist</span> add home <span class="s2">"</span><span class="nv">$_ssh_client</span><span class="s2">"</span> <span class="nb">timeout </span>300
  <span class="nb">sleep </span>60
<span class="k">done
</span><span class="nb">exit </span>0
</code></pre>
		</div>
	</div>
	<hr />
	<p>layout: false</p>
	<h2 id="your-notification-center"><em>Your</em> notification center</h2>
	<p><a href="https://github.com/iBug/rss-to-telegram">iBug/rss-to-telegram</a></p>
	<p><img src="/image/rss-to-telegram.png" alt="" /></p>
	<hr />
	<h2 id="cloudflare-worker-makes-free-file-sharing-site">Cloudflare Worker makes free file sharing site</h2>
	<p><a href="https://github.com/iBug/cf-github-releases">iBug/cf-github-releases</a></p>
	<p><a href="https://download.ibugone.com">My demo site</a> (<a href="https://github.com/iBug/Archive/releases">Repository</a>)</p>
	<p><img src="/image/cloudflare/cf-github-releases.png" alt="" /></p>
	<hr />
	<p>class: center, middle
		layout: false</p>
	<h1 id="thank-you">Thank you!</h1>
	]]></content><author><name>iBug</name></author><summary type="html"><![CDATA[Slides for my talk at Tunight]]></summary></entry><entry><title type="html">Setting up a GitHub webhook on AWS Lambda</title><link href="https://ibug.io/blog/2021/02/github-webhook-on-aws-lambda/" rel="alternate" type="text/html" title="Setting up a GitHub webhook on AWS Lambda" /><published>2021-02-19T00:00:00+00:00</published><updated>2021-02-27T03:04:22+00:00</updated><id>https://ibug.io/blog/2021/02/github-webhook-on-aws-lambda</id><content type="html" xml:base="https://ibug.io/blog/2021/02/github-webhook-on-aws-lambda/"><![CDATA[<p>Last month I set up my own Telegram bot for GitHub event notification. To receive GitHub events via webhook, a receiver is needed. True, it isn’t hard to write a <a href="https://palletsprojects.com/p/flask/">Flask</a> or <a href="http://sinatrarb.com/">Sinatra</a> server and throw the whole thing onto a VPS, but thinking about the complexity and maintenance efforts, serverless platforms like AWS Lambda smells like a better fit. So I decided to take this opportunity to begin my exploration to “the serverless industry”.</p>
	<p><small><a href="/p/41-cn">There’s a Chinese version of this article / 本文还有中文版</a></small></p>
	<h2 id="aws-lambda">Setting up AWS Lambda</h2>
	<p>I have had an AWS account for years, so I’ll skip the sign-up process in this article and head straight to <a href="https://console.aws.amazon.com/">AWS Management Console</a>.</p>
	<p>Locate the <a href="https://console.aws.amazon.com/lambda/home"><strong>Lambda</strong></a> entry in the list of AWS services. It’s in the first group so should be easy to spot.</p>
	<p><img src="/image/aws/console-home-1.png" alt="AWS Management Console Home" /></p>
	<p>And then we create a new Lambda function, selecting Python 3.8 as the runtime environment</p>
	<p><img src="/image/aws/lambda-create-function-1.png" alt="Create new Lambda function" class="border" /></p>
	<p>After clicking “Create”, you’ll be brought to the edit page of that function, with the following code filled in as a starting point.</p>
	<div class="language-python highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="kn">import</span> <span class="nn">json</span>

<span class="k">def</span> <span class="nf">lambda_handler</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="c1"># TODO implement
</span>    <span class="k">return</span> <span class="p">{</span>
        <span class="s">'statusCode'</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
        <span class="s">'body'</span><span class="p">:</span> <span class="n">json</span><span class="p">.</span><span class="n">dumps</span><span class="p">(</span><span class="s">'Hello from Lambda!'</span><span class="p">)</span>
    <span class="p">}</span>
</code></pre>
		</div>
	</div>
	<p>We don’t know what this code can do for now, so let’s put it aside and turn to the API Gateway part, since eventually we’ll use it as the webhook receiver endpoint.</p>
	<h2 id="api-gateway">Setting up AWS API Gateway</h2>
	<p>Open the <a href="https://console.aws.amazon.com/apigateway/main">AWS API Gateway console</a> and click <strong>Create API</strong> on the top right.</p>
	<p><img src="/image/aws/api-gateway-new-1.png" alt="Create API" class="border" /></p>
	<p>On the next screen, we add our Lambda function created earlier as an integration here.</p>
	<p><img src="/image/aws/api-gateway-new-2.png" alt="Configure integrations" class="border" /></p>
	<p>Then it turns to Routes. Routes describe how HTTP endpoints are mapped to integrations (receivers). An example (default) route is pre-filled in the dialog.</p>
	<p><img src="/image/aws/api-gateway-routes-1.png" alt="Configure routes (1)" class="border" /></p>
	<p>Since we have our Lambda function as the only integration here, we want to process actual routes by ourselves. Delete that path <code class="language-plaintext highlighter-rouge">/myGitHubWebhook</code> and enter <code class="language-plaintext highlighter-rouge">$default</code> into that box. <code class="language-plaintext highlighter-rouge">$default</code> is a special value that once entered, the “method” dropdown greys out.</p>
	<p><img src="/image/aws/api-gateway-routes-2.png" alt="Configure routes (2)" class="border" /></p>
	<p>We can now visit our API to see if it works.</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">ubuntu@iBug-Server:~ $</span><span class="w"> </span>curl https://nad73szpz7.execute-api.us-east-1.amazonaws.com/
<span class="go">"Hello from Lambda!"
</span><span class="gp">ubuntu@iBug-Server:~ $</span><span class="w">
</span></code></pre>
		</div>
	</div>
	<h2 id="lambda-code">Coding for Lambda</h2>
	<p>With the infrastructure set up, we should now write our code for the GitHub webhook receiver.</p>
	<p>We need to first know how the client request is passed to our Lambda function. This is not hard to figure out with some simple code that just spits out what it receives. To save some time, I’ve done this so you don’t have to. Here’s what you’d receive via the <code class="language-plaintext highlighter-rouge">event</code> object passed to the Lambda function entry. Keep in mind that it’s a dictionary in Python.</p>
	<details>
		<summary>
			<p>Example content of <code class="language-plaintext highlighter-rouge">event</code> object</p>
		</summary>
		<div class="language-json highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"version"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2.0"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"routeKey"</span><span class="p">:</span><span class="w"> </span><span class="s2">"$default"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"rawPath"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/api-test"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"rawQueryString"</span><span class="p">:</span><span class="w"> </span><span class="s2">"taoky=strong"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"headers"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"accept"</span><span class="p">:</span><span class="w"> </span><span class="s2">"*/*"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"accept-encoding"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gzip"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"cdn-loop"</span><span class="p">:</span><span class="w"> </span><span class="s2">"cloudflare"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"cf-connecting-ip"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2001:db8::1"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"cf-ipcountry"</span><span class="p">:</span><span class="w"> </span><span class="s2">"XX"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"cf-pseudo-ipv4"</span><span class="p">:</span><span class="w"> </span><span class="s2">"255.255.255.255"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"cf-ray"</span><span class="p">:</span><span class="w"> </span><span class="s2">"8b8cca72b23e09a5-NRT"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"cf-request-id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"d2160d7f1100000738c5e62000000001"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"cf-visitor"</span><span class="p">:</span><span class="w"> </span><span class="s2">"{</span><span class="se">\"</span><span class="s2">scheme</span><span class="se">\"</span><span class="s2">:</span><span class="se">\"</span><span class="s2">https</span><span class="se">\"</span><span class="s2">}"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"content-length"</span><span class="p">:</span><span class="w"> </span><span class="s2">"0"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"host"</span><span class="p">:</span><span class="w"> </span><span class="s2">"api.example.com"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"user-agent"</span><span class="p">:</span><span class="w"> </span><span class="s2">"curl/7.68.0"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"x-amzn-trace-id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Root=1-8dab11ae-d63d4eec890259ddab5a7709"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"x-forwarded-for"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2001:db8::1, 162.158.118.243"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"x-forwarded-port"</span><span class="p">:</span><span class="w"> </span><span class="s2">"443"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"x-forwarded-proto"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"x-custom-header"</span><span class="p">:</span><span class="w"> </span><span class="s2">"hello"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"queryStringParameters"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"taoky"</span><span class="p">:</span><span class="w"> </span><span class="s2">"strong"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"requestContext"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"accountId"</span><span class="p">:</span><span class="w"> </span><span class="s2">"166333366666"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"apiId"</span><span class="p">:</span><span class="w"> </span><span class="s2">"nad73szpz7"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"domainName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"api.example.com"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"domainPrefix"</span><span class="p">:</span><span class="w"> </span><span class="s2">"api"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"http"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"method"</span><span class="p">:</span><span class="w"> </span><span class="s2">"POST"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"path"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/api-test"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"protocol"</span><span class="p">:</span><span class="w"> </span><span class="s2">"HTTP/1.1"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"sourceIp"</span><span class="p">:</span><span class="w"> </span><span class="s2">" 162.158.118.243"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"userAgent"</span><span class="p">:</span><span class="w"> </span><span class="s2">"curl/7.68.0"</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="nl">"requestId"</span><span class="p">:</span><span class="w"> </span><span class="s2">"ZcOQCw-WICLEQdg="</span><span class="p">,</span><span class="w">
    </span><span class="nl">"routeKey"</span><span class="p">:</span><span class="w"> </span><span class="s2">"$default"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"stage"</span><span class="p">:</span><span class="w"> </span><span class="s2">"$default"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"time"</span><span class="p">:</span><span class="w"> </span><span class="s2">"20/Jan/2021:16:40:00 +0000"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"timeEpoch"</span><span class="p">:</span><span class="w"> </span><span class="mi">1611160800000</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"body"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Cg=="</span><span class="p">,</span><span class="w">
  </span><span class="nl">"isBase64Encoded"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
			</div>
  </div>
	</details>
	<p>A few notes about the content:</p>
	<ul>
		<li><code class="language-plaintext highlighter-rouge">isBase64Encoded</code> refers to the <code class="language-plaintext highlighter-rouge">body</code> item. In the above example, the actual POST content is a single newline.-</li>
		<li><code class="language-plaintext highlighter-rouge">body</code> may be absent for requests that doesn’t send data, like a GET request.</li>
		<li><code class="language-plaintext highlighter-rouge">headers</code> are all in lowercase which is in line with HTTP/2 specifications. <strong>It could be due to me placing my custom domain behind Cloudflare.</strong></li>
	</ul>
	<p>With that in mind, we can expand the boilerplate Lambda function:</p>
	<div class="language-python highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">def</span> <span class="nf">lambda_handler</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="n">route</span> <span class="o">=</span> <span class="n">event</span><span class="p">[</span><span class="s">"rawPath"</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">route</span> <span class="o">==</span> <span class="s">"/api-test"</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s">'statusCode'</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
            <span class="s">'headers'</span><span class="p">:</span> <span class="p">{</span><span class="s">'Content-Type'</span><span class="p">:</span> <span class="s">'application/json'</span><span class="p">},</span>
            <span class="s">'body'</span><span class="p">:</span> <span class="n">json</span><span class="p">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">event</span><span class="p">),</span>
        <span class="p">}</span>
    <span class="k">elif</span> <span class="n">route</span> <span class="o">==</span> <span class="s">"/github-webhook"</span><span class="p">:</span>
        <span class="c1"># TODO Write webhook receiver code
</span>        <span class="k">pass</span>
</code></pre>
		</div>
	</div>
	<p>The actual webhook processing code shouldn’t be too difficult to write. For example, here’s an example of verifying GitHub via the HMAC signature:</p>
	<div class="language-python highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="kn">import</span> <span class="nn">base64</span>
<span class="kn">import</span> <span class="nn">hashlib</span>
<span class="kn">import</span> <span class="nn">hmac</span>
<span class="kn">import</span> <span class="nn">os</span>
</code></pre>
		</div>
	</div>
	<div class="language-python highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="n">secret</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'MY_ENV_VAR'</span><span class="p">]</span>
<span class="n">signature</span> <span class="o">=</span> <span class="n">event</span><span class="p">[</span><span class="s">'headers'</span><span class="p">][</span><span class="s">'x-hub-signature'</span><span class="p">].</span><span class="n">split</span><span class="p">(</span><span class="s">"="</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">body</span> <span class="o">=</span> <span class="n">event</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'body'</span><span class="p">,</span> <span class="s">""</span><span class="p">)</span>
<span class="k">if</span> <span class="n">event</span><span class="p">[</span><span class="s">'isBase64Encoded'</span><span class="p">]:</span>
    <span class="n">body</span> <span class="o">=</span> <span class="n">base64</span><span class="p">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">body</span><span class="p">)</span>

<span class="n">hashsum</span> <span class="o">=</span> <span class="n">hmac</span><span class="p">.</span><span class="n">new</span><span class="p">(</span><span class="n">signature</span><span class="p">,</span> <span class="n">secret</span><span class="p">,</span> <span class="n">hashlib</span><span class="p">.</span><span class="n">sha1</span><span class="p">).</span><span class="n">hexdigest</span><span class="p">()</span>
<span class="k">if</span> <span class="n">hashsum</span> <span class="o">!=</span> <span class="n">signature</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s">'statusCode'</span><span class="p">:</span> <span class="mi">401</span><span class="p">,</span>
        <span class="s">'body'</span><span class="p">:</span> <span class="s">"Bad signature"</span><span class="p">,</span>
    <span class="p">}</span>

<span class="c1"># Do whatever you want
</span>
<span class="k">return</span> <span class="p">{</span>
  <span class="s">'statusCode'</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
  <span class="s">'body'</span><span class="p">:</span> <span class="s">"OK"</span><span class="p">,</span>
<span class="p">}</span>
</code></pre>
		</div>
	</div>
	<h3 id="lambda-environment-variables">Adding environment variables</h3>
	<p>As shown in the example above, I put the webhook secret in an environment variable. We need to add it to our Lambda function before it could be used.</p>
	<p>Doing so is straightforward. Head to Lambda console and select the function, then scroll down to <em>Environment variables</em> section, where you can manage variables for this Lambda function.</p>
	<p><img src="/image/aws/lambda-environment-variables-1.png" alt="Lambda - Environment variables" class="border" /></p>
	<h2 id="customization">Customizing the webhook</h2>
	<p>Now we’ve got all the foundation established, we can do whatever we want with it. Here are some ideas that could try with:</p>
	<ul>
		<li>Connect to Slack and send a notification for every push or CI run result (<a href="https://docs.github.com/en/developers/webhooks-and-events/webhook-events-and-payloads#check_run">the event is <code class="language-plaintext highlighter-rouge">check_run</code></a>)</li>
		<li>Connect to a Telegram bot and send a message to you for your subscribed events</li>
		<li>Start a Netlify or Vercel build or deployment</li>
		<li>Start GitHub Actions on another repository</li>
		<li>and many more possibilities…</li>
	</ul>
	<h2 id="custom-domain">Bonus: Adding a custom domain</h2>
	<p>Before calling this an article, there’s one more thing I’d like to cover. A custom domain is handy so that you’re in full control of your API, and fortunately AWS API Gateway <em>does</em> support this.</p>
	<p>You may have already noticed the <em>Custom Domain Names</em> on the left pane of API Gateway console, so it’s time to pay that a visit.</p>
	<p>The box on the left with a title <em>Domain names</em> is where we need to start from. Click the big <strong>Create</strong> button and enter your custom domain dedicated for AWS API Gateway, like <code class="language-plaintext highlighter-rouge">api.example.com</code>, and click the bridge red button on the bottom right to save the settings. You don’t have to change any other things there as the defaults just work.</p>
	<p>Now you should see this screen:</p>
	<p><img src="/image/aws/api-gateway-custom-domain-1.png" alt="API Gateway - Custom domain" class="border" /></p>
	<p>Head to your DNS provider and add a CNAME record for <code class="language-plaintext highlighter-rouge">api.example.com</code> pointing to the <code class="language-plaintext highlighter-rouge">execute-api</code> domain shown there. If you’re using Cloudflare, you can safely turn on the CDN setting (the orange cloud icon) to enjoy Cloudflare’s faster global network.</p>
	<p>Next we’ll add “API mapping” for our custom domain. Select the <em>API mapping</em> tab in the center of the above image and click <strong>Configure API mappings</strong> on the right. Add a new mapping, select your API and the <code class="language-plaintext highlighter-rouge">$default</code> stage, and give it a subpath if you want, like shown below:</p>
	<p><img src="/image/aws/api-gateway-custom-domain-2.png" alt="API Gateway - Custom domain - API mapping" class="border" /></p>
	<div class="notice--primary">
		<h4 class="no_toc" id="dont-worry-about-your-subpath"><i class="fas fa-fw fa-sun"></i> Don’t worry about your subpath</h4>
		<p>API Gateway will automatically strip the path before passing it to the Lambda function. This means if you set the path to <code class="language-plaintext highlighter-rouge">/hello</code> and visit <code class="language-plaintext highlighter-rouge">https://api.example.com/hello/world</code>, your Lambda function will still see the <code class="language-plaintext highlighter-rouge">rawPath</code> key being <code class="language-plaintext highlighter-rouge">/world</code>. You don’t have to change your code to adapt this part. Very convenient, isn’t it?</p>
	</div>
	<p>Now our GitHub webhook receiver will start with <code class="language-plaintext highlighter-rouge">https://api.example.com/github</code>, and our “API test” endpoint will be <code class="language-plaintext highlighter-rouge">https://api.example.com/github/api-test</code>.</p>
	<p>You may need to configure AWS Certificate Manager to obtain a valid SSL certificate for use on AWS, so that your API is accessible through HTTPS, depending on your domain settings. With Cloudflare this is unnecessary and you can safely ignore it.</p>
	<h2 id="others">Other notes</h2>
	<p>AWS Lambda provides 400,000 GB-seconds of execution for free each month, and this Free Tier does not expire. However, AWS API Gateway doesn’t have a perpetual Free Tier offer, and their standard pricing is US$1 per 1M API calls. The cost on this part is generally low unless you’re making a public service (that becomes popular).</p>
	<p>Besides, AWS provides 1 GB of free outbound traffic each month, and bills you at US$0.09 per GB thereafter. This means you’ll need to be careful when generating a lot of traffic, like frequently uploading large images.</p>
	<p>All pricing examples are based on US East 1 (N. Virginia) region. Other regions are generally more expensive than this, so watch your bills if you make something big.</p>
	]]></content><author><name>iBug</name></author><category term="github" /><category term="aws" /><summary type="html"><![CDATA[Last month I set up my own Telegram bot for GitHub event notification. To receive GitHub events via webhook, a receiver is needed. True, it isn’t hard to write a Flask or Sinatra server and throw the whole thing onto a VPS, but thinking about the complexity and maintenance efforts, serverless platforms like AWS Lambda smells like a better fit. So I decided to take this opportunity to begin my exploration to “the serverless industry”.]]></summary></entry><entry><title type="html">Fix traceroute not showing intermediate results in a virtual machine on Windows</title><link href="https://ibug.io/blog/2021/02/traceroute-from-vmware/" rel="alternate" type="text/html" title="Fix traceroute not showing intermediate results in a virtual machine on Windows" /><published>2021-02-04T00:00:00+00:00</published><updated>2021-02-10T19:09:18+00:00</updated><id>https://ibug.io/blog/2021/02/traceroute-from-vmware</id><content type="html" xml:base="https://ibug.io/blog/2021/02/traceroute-from-vmware/"><![CDATA[<p>Today when I was running some networking diagnostics from an Ubuntu inside VMware Workstation, I noticed this strange result from <a href="https://en.wikipedia.org/wiki/MTR_(software)"><code class="language-plaintext highlighter-rouge">mtr</code> (My Traceroute)</a>:</p>
	<p><img src="/image/linux/traceroute-failure.png" alt="MTR with all intermediate hops blank" /></p>
	<p>This doesn’t look right. Googling around brought me to this page: <a href="https://communities.vmware.com/t5/VMware-Workstation-Player/traceroute-from-Ubuntu-just-shows-first-and-last-hops-on/m-p/1677263">traceroute from Ubuntu just shows first and last hops on VMPlayer 3.1.4 - VMware Technology Network VMTN</a></p>
	<p>The answers in that thread mentioned two points:</p>
	<ul>
		<li><em>On the other hand once I switched to bridge, everything works.</em></li>
		<li><em>What about the intermediary requests, well the answers come back but somehow they are blocked by the Windows firewall.</em></li>
	</ul>
	<p>I immediately realized that it’s because <strong>Windows Firewall blocked responses from the intermediate hops</strong>.</p>
	<h2 id="the-answer">The answer</h2>
	<div class="notice--primary">
		<h4 class="no_toc" id="the-short-answer"><i class="fas fa-shield-check"></i> The short answer</h4>
		<p>The responses from the intermediate routers aren’t “expected” and are blocked off by Windows Firewall.</p>
	</div>
	<h4 class="no_toc" id="the-long-answer">The long answer</h4>
	<p>Windows Firewall has a built-in connection tracking mechanism, similar to that of Linux (conntrack). Since <code class="language-plaintext highlighter-rouge">mtr</code> sends <a href="https://en.wikipedia.org/wiki/Ping_(networking_utility)#Echo_request">pings (ICMP Echo Requests)</a> to the target host, Windows Firewall is expecting ICMP Echo Replies from the target host as the correct response. However, traceroute works by sending packets with TTL starting from 1 until it reaches the target host, and receiving “timed out” notices from the intermediate routers when the packet “dies from time”. This creates two discrepancies:</p>
	<ul>
		<li>The responses are ICMP Time Exceeded packets, not Echo Replies.</li>
		<li>The responses come from the intermediate routers, not the target host.</li>
	</ul>
	<p>This unfortunately somehow “broke” the connection tracking mechanism in Windows Firewall, and leads to the responses being blocked off by Windows Firewall by default.</p>
	<h2 id="the-solution">The solution</h2>
	<div class="notice--warning">
		<h4 class="no_toc" id="the-short-solution"><i class="fas fa-shield-check"></i> The short solution</h4>
		<p>Just turn off Windows Firewall entirely. <strong>You probably don’t want to or shouldn’t do this.</strong> Read on for the complete and real solution.</p>
	</div>
	<p>The correct solution to this problem is to let the intermediary responses through Windows Firewall. To actually do this, we’ll <strong>create a new firewall rule that allows ICMP Time Exceeded packets to come in</strong>. You can stop here now if you know how to configure Windows Firewall.</p>
	<p>Step-by-step solution:</p>
	<ol>
		<li>Open <strong>Windows Defender Firewall with Advanced Security</strong> (at least it’s called as such on my Windows 10). This can be done in two ways:
			<ul>
				<li>Go to <strong>Start</strong> → <strong>Windows Administrative Tools</strong> → <strong>Windows Defender Firewall with Advanced Security</strong></li>
				<li>Or hit <strong><kbd><i class="fab fa-fw fa-windows"></i>Win</kbd>+<kbd>R</kbd></strong>, enter <code class="language-plaintext highlighter-rouge">WF.msc</code> and hit Enter.</li>
			</ul>
		</li>
		<li>
			<p>Select <strong>Inbound Rules</strong> on the left and then <strong>New Rule…</strong> on the right.</p>
			<p><img src="https://i.stack.imgur.com/m1suMs.png" alt="Screenshot" /></p>
		</li>
		<li>
			<p>Follow the prompt to create a new rule. Select the following options for each step. Note that the desired options are selected by default in some steps so you can simply click <strong>Next</strong>.</p>
			<ul>
				<li>Rule Type: <strong>Custom</strong></li>
				<li>Program: <strong>All programs</strong> (just click Next)</li>
				<li>Protocol and Ports:
					<ul>
						<li>Protocol type: <strong>ICMPv4</strong></li>
						<li><em>(Optional)</em> Internet Control Message Protocol (ICMP) settings: Click <strong>Customize</strong> → Select <strong>Specific ICMP types</strong> and tick <strong>Time Exceeded</strong></li>
					</ul>
				</li>
				<li>Scope: <strong>Any IP address</strong> for both (just click Next)</li>
				<li>Action: <strong>Allow</strong> (just click Next)</li>
				<li>Profile: Select all (just click Next)</li>
				<li>Name: <strong>Core Networking - Time Exceeded (ICMPv4-In)</strong> (apparently just any name you prefer)</li>
			</ul>
			<p>Click <strong>Finish</strong> and you should immediately see intermediate hops if you’re using <code class="language-plaintext highlighter-rouge">mtr</code>. For example:</p>
			<p><img src="/image/linux/traceroute-ok.png" alt="MTR correctly functioning" /></p>
		</li>
		<li>
			<p><em>(Optional)</em> Repeat the above steps but select <strong>ICMPv6</strong> for <em>Protocol type</em> if you want to enable IPv6 traceroute. Don’t forget to give it a different name (e.g. <em>(ICMPv6-In)</em> at the end).</p>
			<ul>
				<li>In my case there’s already a built-in rule named <strong>Core Networking - Time Exceeded (ICMPv6-In)</strong> which is even enabled by default. If you find it there, you can simply enable it.</li>
			</ul>
		</li>
	</ol>
	<h3 id="bonus">Bonus</h3>
	<p>If you want to make your rule <em>more solid</em> and <em>look</em> “canonical”, you can add it to the built-in system group <strong>Core Networking</strong> with the help of PowerShell.</p>
	<div class="language-powershell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="nv">$rule</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Get-NetFirewallRule</span><span class="w"> </span><span class="nt">-DisplayName</span><span class="w"> </span><span class="s2">"Core Networking - Time Exceeded (ICMPv4-In)"</span><span class="w">
</span><span class="nv">$rule</span><span class="o">.</span><span class="nf">Group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Core Networking"</span><span class="w">
</span><span class="nv">$rule</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Set-NetFirewallRule</span><span class="w">
</span></code></pre>
		</div>
	</div>
	<p>Your new rule will look like this after running the above commands. You may need to restart the Windows Firewall window to see changes.</p>
	<p><img src="/image/windows/core-networking-time-exceeded-icmpv4-in.png" alt="New Rule" /></p>
	<hr />
	<p>This article was originally written as <a href="https://superuser.com/a/1623001/688600">an answer on Super User</a>.</p>
	]]></content><author><name>iBug</name></author><category term="networking" /><category term="windows" /><summary type="html"><![CDATA[Today when I was running some networking diagnostics from an Ubuntu inside VMware Workstation, I noticed this strange result from mtr (My Traceroute):]]></summary></entry><entry><title type="html">A Deep Dive into Containers</title><link href="https://ibug.io/blog/2021/01/linux-container-explained/" rel="alternate" type="text/html" title="A Deep Dive into Containers" /><published>2021-01-31T00:00:00+00:00</published><updated>2021-02-05T15:47:37+00:00</updated><id>https://ibug.io/blog/2021/01/linux-container-explained</id><content type="html" xml:base="https://ibug.io/blog/2021/01/linux-container-explained/"><![CDATA[<p>Since years ago, containers have been a hot topic everywhere. There are many container softwares like <a href="https://www.docker.com/">Docker</a>, <a href="https://linuxcontainers.org/">Linux Containers</a> and <a href="https://sylabs.io/singularity/">Singularity</a>. It’s hard to say one <em>understand</em> what containers are without diving into all the gory details of them, so I decided to go on this exploration myself.</p>
	<p>The actual motivation was (quite) a bit different, though, as I was a TA of <em>Operating Systems (H)</em> in Spring 2020, and I wanted to bring a wave of innovation into the course labs, so I worked this out very early.</p>
	<p>The contents in this article are listed in the Table of Contents <span class="wide-only">on the right</span><span class="nonwide-only">at the top of this page</span>. My implementation in my GitHub repository and the original lab documents (which is also written primarily by me, in Chinese) are linked right above.</p>
	<p>My test environment is Ubuntu 18.04 LTS (Kernel 5.3, HWE 18.04). In case of any difference, you can consult Google for details.</p>
	<p>If you want to find out the exact system calls involved in a command-line tool, <a href="https://strace.io/"><code class="language-plaintext highlighter-rouge">strace</code></a> is your friend.</p>
	<div class="notice--warning">
		<h4 class="no_toc" id="code-samples-have-a-different-license-than-this-article"><i class="fas fa-exclamation-triangle"></i> Code samples have a different license than this article</h4>
		<p>While this article is licensed under the CC BY-SA 4.0 license, code samples and snippets are taken from the GitHub repository, which is licensed under <a href="https://github.com/iBug/iSpawn/blob/master/LICENSE">the GPL-3.0 license</a>.</p>
	</div>
	<h2 id="experimenting">Experimenting with isolation</h2>
	<p>Before we jump straight to writing code, let’s warm ourselves up by playing with an existing, minimal container implementation, to get a better idea of our target.</p>
	<h3 id="rootfs">Preparing the root filesystem</h3>
	<p>To keep things simple, we’re going to use the system images from the LXC project. Grab the latest Ubuntu image from <a href="https://images.linuxcontainers.org/images/ubuntu/">https://images.linuxcontainers.org/images/ubuntu/</a>, unzip it to somewhere convenient for you, and this part is <em>almost</em> done.</p>
	<p>If you’re on a “modern” distro like latest Ubuntu, Debian or Fedora, you need to populate the <code class="language-plaintext highlighter-rouge">/etc/machine-id</code> file in the container image with a valid “machine ID”, because systemd needs it. A simple way to do this is</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>systemd-machine-id-setup <span class="nt">--root</span><span class="o">=</span>/path/to/your/rootfs
</code></pre>
		</div>
	</div>
	<p>If you’re running systemd 240 or later, there’s a better neat tool for this job:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>systemd-id128 new <span class="o">&gt;</span> /path/to/your/rootfs/etc/machine-id
</code></pre>
		</div>
	</div>
	<h3 id="chroot">Playing with chroot</h3>
	<p><a href="https://wiki.debian.org/chroot">chroot</a> is an old way to limit the directory tree a process (and its subprocesses) can see to a specific subtree. Under normal circumstances, processes cannot see anything outsite the chroot’d directory. This is called a <em>chroot jail</em>. Understanding the concepts of chroot is an important first step to understanding containers, though a typical container does <em>not</em> use chroot (more on this below).</p>
	<p>Using chroot is very easy:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="nb">chroot</span> /path/to/your/rootfs
</code></pre>
		</div>
	</div>
	<p>You now get a shell inside the <em>chroot jail</em>. You can perform file-based operation like running “regular” commands and editing system files. All changes are saved in this “container rootfs”. You can even try <code class="language-plaintext highlighter-rouge">apt update</code> and <code class="language-plaintext highlighter-rouge">apt install vim</code> and see if it works.</p>
	<p>As you’re probably aware, chroot is just too simple and sometimes naive to be secure. You can try the following commands, but be sure to save your work. <strong>Proceed with caution!</strong></p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>reboot
mount
<span class="nb">dd </span><span class="k">if</span><span class="o">=</span>/dev/sda <span class="nv">of</span><span class="o">=</span><span class="nb">test </span><span class="nv">bs</span><span class="o">=</span>4k <span class="nv">count</span><span class="o">=</span>1
<span class="nb">echo</span> <span class="nv">$$</span>
</code></pre>
		</div>
	</div>
	<h3 id="systemd-nspawn">Playing with systemd-nspawn</h3>
	<p>As you can see, chroot lacks too many security constaints. <a href="https://wiki.debian.org/nspawn">Systemd-nspawn</a>, on the other hand, is a <em>complete</em> container implementation and is thus secure against random programs.</p>
	<p>Using systemd-nspawn is equally easy:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="nb">cd</span> /path/to/your/rootfs
systemd-nspawn
</code></pre>
		</div>
	</div>
	<p>Now repeat your experiments in the chroot section and carefully observe the differences.</p>
	<h2 id="base-program">The base program</h2>
	<p>After getting your rootfs up for rocking, we’ll start with a fairly simple chroot-based program, modify it step-by-step, until it becomes the container we want.</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;unistd.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;sys/types.h&gt;</span><span class="c1"> // For wait(2)</span><span class="cp">
#include</span> <span class="cpf">&lt;sys/wait.h&gt;</span><span class="c1">  // For wait(2)</span><span class="cp">
</span>
<span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">usage</span> <span class="o">=</span>
<span class="s">"Usage: %s &lt;directory&gt; &lt;command&gt; [args...]</span><span class="se">\n</span><span class="s">"</span>
<span class="s">"</span><span class="se">\n</span><span class="s">"</span>
<span class="s">"  Run &lt;directory&gt; as a container and execute &lt;command&gt;.</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>

<span class="kt">void</span> <span class="nf">error_exit</span><span class="p">(</span><span class="kt">int</span> <span class="n">code</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">message</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">perror</span><span class="p">(</span><span class="n">message</span><span class="p">);</span>
    <span class="n">_exit</span><span class="p">(</span><span class="n">code</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="n">usage</span><span class="p">,</span> <span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
        <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">chdir</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">error_exit</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>

    <span class="n">pid_t</span> <span class="n">pid</span> <span class="o">=</span> <span class="n">fork</span><span class="p">();</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">pid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// Child goes for target program</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">chroot</span><span class="p">(</span><span class="s">"."</span><span class="p">)</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">error_exit</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s">"chroot"</span><span class="p">);</span>
        <span class="n">execvp</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">argv</span> <span class="o">+</span> <span class="mi">2</span><span class="p">);</span>
        <span class="n">error_exit</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="s">"exec"</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="c1">// Parent waits for child</span>
    <span class="kt">int</span> <span class="n">status</span><span class="p">,</span> <span class="n">ecode</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="n">wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">WIFEXITED</span><span class="p">(</span><span class="n">status</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"Exited with status %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">WEXITSTATUS</span><span class="p">(</span><span class="n">status</span><span class="p">));</span>
        <span class="n">ecode</span> <span class="o">=</span> <span class="n">WEXITSTATUS</span><span class="p">(</span><span class="n">status</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">WIFSIGNALED</span><span class="p">(</span><span class="n">status</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"Killed by signal %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">WTERMSIG</span><span class="p">(</span><span class="n">status</span><span class="p">));</span>
        <span class="n">ecode</span> <span class="o">=</span> <span class="o">-</span><span class="n">WTERMSIG</span><span class="p">(</span><span class="n">status</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">ecode</span><span class="p">;</span>
<span class="p">}</span>
</code></pre>
		</div>
	</div>
	<h2 id="namespaces">Namespaces</h2>
	<p><a href="https://en.wikipedia.org/wiki/Linux_namespaces">Namespaces</a> are a fundamental aspect of Linux containers. They provide isolation for a variety of mission-critical system resources like process IDs, hostnames, network stacks and inter-process communication. They are the key to making containers “look independent” from the host system.</p>
	<p>As of Linux kernel 5.6 released in April 2020, there are 8 kinds of namespaces present:</p>
	<ul>
		<li><strong>Mount namespace</strong> isolates mount points (visibility) from the parent. New mount activities in the parent namespace won’t be visible in child namespaces. However, to achieve the reverse, a separate thing called “mount propagation” is involved. First appeared in 2002, Linux 2.4.19.</li>
		<li><strong>UTS namespace</strong> provides isolated hostnames. UTS stands for <a href="https://en.wikipedia.org/wiki/History_of_Unix">“<strong>U</strong>NIX <strong>T</strong>ime-<strong>S</strong>haring system”</a>. First appeared in 2006, Linux 2.6.19.</li>
		<li><strong>IPC namespace</strong> isolates traditional System V-style IPC methods. First appeared in 2006, Linux 2.6.19.</li>
		<li><strong>PID namespace</strong> provides a separate set of process IDs so that a process may look different inside. This is important for certain programs to function properly, most notably the init process, which must be PID 1. First appeared in 2008, Linux 2.6.24.</li>
		<li><strong>Networking namespace</strong> provides a full set of network stack. Suitable for creating isolated network environments for containers. First appeared in 2009, Linux 2.6.29.</li>
		<li><strong>User namespace</strong> allows mapping UIDs / GIDs from containers to hosts, so that unpriviledged users can perform certain tasks that normally require the superuser privilege, without actually elevating themselves or posing risks to the host. First appeared in 2013, Linux 3.8.</li>
		<li><strong>Cgroup namespace</strong> provides isolated cgroup hierarchies so containers can safely utilize cgroup functionalities without affecting the host. First appeared in 2016, Linux 4.6.</li>
		<li><strong>Time namespace</strong> allows different processes to “see” different system times. First appeared in 2020, Linux 5.6.</li>
	</ul>
	<p>There are two ways to get namespaces isolated, <a href="https://man7.org/linux/man-pages/man2/unshare.2.html"><code class="language-plaintext highlighter-rouge">unshare()</code></a> and <a href="https://man7.org/linux/man-pages/man2/clone.2.html"><code class="language-plaintext highlighter-rouge">clone()</code></a>. A brief difference is that <code class="language-plaintext highlighter-rouge">unshare</code> isolates for the calling process (except PID namespace, check the manual for more details), while <code class="language-plaintext highlighter-rouge">clone</code> creates a new process with isolated namespaces. We’ll go for <code class="language-plaintext highlighter-rouge">clone</code> because it’s the system call underneath Go’s <code class="language-plaintext highlighter-rouge"><span class="n">exec</span><span class="o">.</span><span class="n">Command</span></code>, and that Go is used for popular container software like Docker and Singularity.</p>
	<p>To utilize the <code class="language-plaintext highlighter-rouge">clone</code> system call, we need some adaptions, among which the most notable ones are the entry function and the child stack (using <code class="language-plaintext highlighter-rouge">mmap()</code>, I had problems later with <code class="language-plaintext highlighter-rouge">malloc()</code> in my early testing). The rest are covered pretty well in the manual so there’s no need to repeat them here (e.g. <code class="language-plaintext highlighter-rouge">SIGCHLD</code> appearing in <code class="language-plaintext highlighter-rouge">flags</code> parameter).</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="kt">int</span> <span class="nf">child</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">arg</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"My name is %s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span><span class="n">arg</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">3</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="kt">char</span> <span class="n">name</span><span class="p">[]</span> <span class="o">=</span> <span class="s">"child"</span><span class="p">;</span>

<span class="cp">#define STACK_SIZE (1024 * 1024) // 1 MiB
</span>    <span class="kt">void</span> <span class="o">*</span><span class="n">child_stack</span> <span class="o">=</span> <span class="n">mmap</span><span class="p">(</span><span class="nb">NULL</span><span class="p">,</span> <span class="n">STACK_SIZE</span><span class="p">,</span>
                             <span class="n">PROT_READ</span> <span class="o">|</span> <span class="n">PROT_WRITE</span><span class="p">,</span>
                             <span class="n">MAP_PRIVATE</span> <span class="o">|</span> <span class="n">MAP_ANONYMOUS</span> <span class="o">|</span> <span class="n">MAP_STACK</span><span class="p">,</span>
                             <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
    <span class="c1">// Assume stack grows downwards</span>
    <span class="kt">void</span> <span class="o">*</span><span class="n">child_stack_start</span> <span class="o">=</span> <span class="n">child_stack</span> <span class="o">+</span> <span class="n">STACK_SIZE</span><span class="p">;</span>

    <span class="kt">int</span> <span class="n">ch</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">child</span><span class="p">,</span> <span class="n">child_stack_start</span><span class="p">,</span> <span class="n">SIGCHLD</span><span class="p">,</span> <span class="n">name</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">status</span><span class="p">;</span>
    <span class="n">wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"Child exited with code %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">WEXITSTATUS</span><span class="p">(</span><span class="n">status</span><span class="p">));</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre>
		</div>
	</div>
	<p>And for the include headers as well.</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="cp">#define _GNU_SOURCE    // Required for enabling clone(2)
#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;sched.h&gt;</span><span class="c1">     // For clone(2)</span><span class="cp">
#include</span> <span class="cpf">&lt;signal.h&gt;</span><span class="c1">    // For SIGCHLD constant</span><span class="cp">
#include</span> <span class="cpf">&lt;sys/mman.h&gt;</span><span class="c1">  // For mmap(2)</span><span class="cp">
#include</span> <span class="cpf">&lt;sys/types.h&gt;</span><span class="c1"> // For wait(2)</span><span class="cp">
#include</span> <span class="cpf">&lt;sys/wait.h&gt;</span><span class="c1">  // For wait(2)</span><span class="cp">
</span></code></pre>
		</div>
	</div>
	<p>Now that we have <code class="language-plaintext highlighter-rouge">clone</code> ready, adding support for namespace isolation is as simple as adding flags to the parameters.</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="kt">int</span> <span class="n">ch</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">child</span><span class="p">,</span> <span class="n">child_stack_start</span><span class="p">,</span> <span class="n">CLONE_NEWNS</span> <span class="o">|</span> <span class="n">CLONE_NEWUTS</span> <span class="o">|</span> <span class="n">CLONE_NEWIPC</span> <span class="o">|</span> <span class="n">CLONE_NEWPID</span> <span class="o">|</span> <span class="n">CLONE_NEWCGROUP</span> <span class="o">|</span> <span class="n">SIGCHLD</span><span class="p">,</span> <span class="n">name</span><span class="p">);</span>
</code></pre>
		</div>
	</div>
	<h2 id="mounts">Mounts</h2>
	<p>Traditionally, mounting is a way to map raw disks to accessible filesystems. Since then, its usage has evolved and supports much more than disk mapping. We’re particularly interested in using special filesystems like <code class="language-plaintext highlighter-rouge">/proc</code> (the FS that provides runtime information like processes and kernel parameters), <code class="language-plaintext highlighter-rouge">/sys</code> (system settings, device information etc.), <code class="language-plaintext highlighter-rouge">/tmp</code> (a temporary filesystem backed by RAM) etc., without which a container won’t function properly.</p>
	<p>For a minimal example, we’ll mount 4 essential filesystems with correct mount options for our container. They are the three mentioned above plus <code class="language-plaintext highlighter-rouge">/dev</code> as a tmpfs. We’ll also create a few device nodes under <code class="language-plaintext highlighter-rouge">/dev</code> so things can go smoothly when they’re needed (e.g. <code class="language-plaintext highlighter-rouge">some_command &gt; /dev/null</code>).</p>
	<div class="notice--primary">
		<h4 class="no_toc" id="were-not-using-devtmpfs-here"><i class="fas fa-times-circle"></i> We’re not using <code class="language-plaintext highlighter-rouge">devtmpfs</code> here</h4>
		<p>If you examine current mounts in your host system, you’ll probably see that <code class="language-plaintext highlighter-rouge">/dev</code> is mounted as <code class="language-plaintext highlighter-rouge">devtmpfs</code>. While it may appear straightforward to employ that, it’s unacceptable for <strong>a container</strong>, as it exposes <em>all</em> device nodes to the container, which violates the purpose of isolation of containers. See <a href="https://unix.stackexchange.com/q/77933/211239">this answer</a> on Unix &amp; Linux Stack Exchange.</p>
	</div>
	<p>To do this manually, you’ll issue the following commands in a shell.</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>mount <span class="nt">-t</span> tmpfs tmpfs /dev
mount <span class="nt">-t</span> proc proc /proc
mount <span class="nt">-t</span> sysfs sysfs /sys
mount <span class="nt">-t</span> tmpfs tmpfs /tmp
</code></pre>
		</div>
	</div>
	<p>You can then run <code class="language-plaintext highlighter-rouge">mount</code> without arguments to see the mount results.</p>
	<div class="language-text highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>sysfs on /sys type sysfs (rw,relatime)
proc on /proc type proc (rw,relatime)
tmpfs on /dev type devtmpfs (rw,relatime)
tmpfs on /tmp type tmpfs (rw,relatime)
</code></pre>
		</div>
	</div>
	<p>If you compare this with the mount points in your host system, you may notice something different.</p>
	<div class="language-text highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>sysfs on /sys type sysfs (rw,nosuid,nodev,noexec,relatime)
proc on /proc type proc (rw,nosuid,nodev,noexec,relatime)
udev on /dev type devtmpfs (rw,nosuid,noexec,relatime,size=65895752k,nr_inodes=16473938,mode=755)
tmpfs on /run type tmpfs (rw,nosuid,nodev,noexec,relatime,size=13191916k,mode=755)
</code></pre>
		</div>
	</div>
	<p>The extra flags (<code class="language-plaintext highlighter-rouge">nosuid,nodev,noexec</code>) control the behavior of the mount point. For example, <code class="language-plaintext highlighter-rouge">nosuid</code> means the set-uid bit will be ignored for entries under the mount point, while <code class="language-plaintext highlighter-rouge">noexec</code> prevents any execution of programs from inside.</p>
	<p>Now we’re going to do it in C. The system call is also named <code class="language-plaintext highlighter-rouge">mount</code>, and has the following signature:</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="kt">int</span> <span class="nf">mount</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">source</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">target</span><span class="p">,</span>
          <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">filesystemtype</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">mountflags</span><span class="p">,</span>
          <span class="k">const</span> <span class="kt">void</span> <span class="o">*</span><span class="n">data</span><span class="p">);</span>
</code></pre>
		</div>
	</div>
	<p>It should be intuitive enough what the first three parameters are for, so for now we can just write</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="n">mount</span><span class="p">(</span><span class="s">"tmpfs"</span><span class="p">,</span> <span class="s">"/dev"</span><span class="p">,</span> <span class="s">"tmpfs"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span>
<span class="n">mount</span><span class="p">(</span><span class="s">"proc"</span><span class="p">,</span> <span class="s">"/proc"</span><span class="p">,</span> <span class="s">"proc"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span>
<span class="n">mount</span><span class="p">(</span><span class="s">"sysfs"</span><span class="p">,</span> <span class="s">"/sys"</span><span class="p">,</span> <span class="s">"sysfs"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span>
<span class="n">mount</span><span class="p">(</span><span class="s">"tmpfs"</span><span class="p">,</span> <span class="s">"/tmp"</span><span class="p">,</span> <span class="s">"tmpfs"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span>
</code></pre>
		</div>
	</div>
	<p>The fourth parameter corresponds to the flags we discussed above. All applicable flags can be found in the man page for <a href="https://man7.org/linux/man-pages/man2/mount.2.html"><code class="language-plaintext highlighter-rouge">mount(2)</code></a>.</p>
	<p id="mount-data-parameter">Keep in mind that, however, the last parameter isn’t entirely useless. It’s simply not used for now, but it’ll play a role later. (Actually, you may have noticed already. Good job for that.)</p>
	<h3 id="device-nodes">Creating device nodes</h3>
	<p>Now that we have an empty <code class="language-plaintext highlighter-rouge">/dev</code> directory, we should populate it with some device nodes so that software expecting their presence could work. At a minimum, we need <code class="language-plaintext highlighter-rouge">null</code>, <code class="language-plaintext highlighter-rouge">zero</code>, <code class="language-plaintext highlighter-rouge">random</code> and <code class="language-plaintext highlighter-rouge">urandom</code>, but you can add <code class="language-plaintext highlighter-rouge">tty</code> and <code class="language-plaintext highlighter-rouge">console</code> if you want (these two are a bit different - you have been warned).</p>
	<p>Device nodes are created with <a href="https://man7.org/linux/man-pages/man2/mknod.2.html"><code class="language-plaintext highlighter-rouge">mknod(2)</code></a>, whose prototype is:</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="kt">int</span> <span class="nf">mknod</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">path</span><span class="p">,</span> <span class="n">mode_t</span> <span class="n">mode</span><span class="p">,</span> <span class="n">dev_t</span> <span class="n">dev</span><span class="p">);</span>
</code></pre>
		</div>
	</div>
	<p>With a little research effort, we know we’ll call it like this:</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="n">mknod</span><span class="p">(</span><span class="s">"/dev/something"</span><span class="p">,</span> <span class="n">S_IFCHR</span> <span class="o">|</span> <span class="mo">0666</span><span class="p">,</span> <span class="n">makedev</span><span class="p">(</span><span class="n">MAJOR</span><span class="p">,</span> <span class="n">MINOR</span><span class="p">));</span>
</code></pre>
		</div>
	</div>
	<p>To determine the device node numbers, you can take a look at the same nodes in the host system, using <code class="language-plaintext highlighter-rouge">ls -l</code> or <code class="language-plaintext highlighter-rouge">stat</code>. Don’t worry, the numbers for special devices remain the same across Linux distros, <a href="https://unix.stackexchange.com/a/354985/211239">unlike BSD systems</a>. It shouldn’t take long before you come to this:</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="n">mknod</span><span class="p">(</span><span class="s">"dev/null"</span><span class="p">,</span> <span class="n">S_IFCHR</span> <span class="o">|</span> <span class="mo">0666</span><span class="p">,</span> <span class="n">makedev</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">));</span>
<span class="n">mknod</span><span class="p">(</span><span class="s">"dev/zero"</span><span class="p">,</span> <span class="n">S_IFCHR</span> <span class="o">|</span> <span class="mo">0666</span><span class="p">,</span> <span class="n">makedev</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">));</span>
<span class="n">mknod</span><span class="p">(</span><span class="s">"dev/random"</span><span class="p">,</span> <span class="n">S_IFCHR</span> <span class="o">|</span> <span class="mo">0666</span><span class="p">,</span> <span class="n">makedev</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">));</span>
<span class="n">mknod</span><span class="p">(</span><span class="s">"dev/urandom"</span><span class="p">,</span> <span class="n">S_IFCHR</span> <span class="o">|</span> <span class="mo">0666</span><span class="p">,</span> <span class="n">makedev</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">));</span>
</code></pre>
		</div>
	</div>
	<h2 id="pivot-root">pivot_root</h2>
	<p>We’re ready with mounts, so now we can take a look at switching the root filesystem for our container.</p>
	<p>The <a href="#base-program">base program</a> used <code class="language-plaintext highlighter-rouge">chroot()</code> for the time being, but talking about a (baseline) secure container, <a href="https://github.com/earthquake/chw00t">it’s terrible</a>. We have to resort to another Linux feature, <code class="language-plaintext highlighter-rouge">pivot_root</code>, for this purpose.</p>
	<p>Let’s first take a look at <a href="https://man7.org/linux/man-pages/man2/pivot_root.2.html">its man page</a> to determine its prototype.</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="kt">int</span> <span class="nf">pivot_root</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">new_root</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">put_old</span><span class="p">);</span>
</code></pre>
		</div>
	</div>
	<p>This system call is special enough that we must also take care of its notes and requirements. For example, <code class="language-plaintext highlighter-rouge">new_root</code> must be a mount point. While the man page does provide a solution to this problem by mounting the directory on top of itself, it’s too prone to errors for us to adopt. Instead we’ll be creating a temporary directory to use as the mount point.</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">newroot</span> <span class="o">=</span> <span class="s">"/tmp/ispawn"</span><span class="p">;</span>
<span class="n">mkdir</span><span class="p">(</span><span class="n">newroot</span><span class="p">,</span> <span class="mo">0755</span><span class="p">);</span>
</code></pre>
		</div>
	</div>
	<p>We also need a value for the second parameter to <code class="language-plaintext highlighter-rouge">pivot_root</code>, the <code class="language-plaintext highlighter-rouge">put_old</code> directory. The manual says the following:</p>
	<blockquote>
		<p><code class="language-plaintext highlighter-rouge">put_old</code> must be at or underneath <code class="language-plaintext highlighter-rouge">new_root</code></p>
	</blockquote>
	<p>A direct interpretation is that <code class="language-plaintext highlighter-rouge">put_old</code> must be at a subpath under <code class="language-plaintext highlighter-rouge">new_root</code>, which means we can simply create (or reuse an existing) a directory under <code class="language-plaintext highlighter-rouge">new_root</code> to use.</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">put_old</span> <span class="o">=</span> <span class="s">"/tmp/ispawn/oldroot"</span><span class="p">;</span>
<span class="n">mkdir</span><span class="p">(</span><span class="n">put_old</span><span class="p">);</span>
</code></pre>
		</div>
	</div>
	<p>And now we can do <code class="language-plaintext highlighter-rouge">pivot_root</code> with the directories we just set up:</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="n">pivot_root</span><span class="p">(</span><span class="n">newroot</span><span class="p">,</span> <span class="n">put_old</span><span class="p">);</span>
</code></pre>
		</div>
	</div>
	<p>If everything so far is correct, we should now be running inside the new root tree. The “old root”, or the root filesystem of the host system, is now available at <code class="language-plaintext highlighter-rouge">/oldroot</code>.</p>
	<p>Apparently, a container shouldn’t be able to access the host filesystem without explicit grants, so we’re going to “hide” the old root. It is, from the view from within the container, an ordinary mount point that we can just unmount. However, as there (definitely) are other processes in the host system still using the filesystem, it can’t be unmounted directly.</p>
	<p>There’s a technique called “lazy unmounting”, where existing processes continue to use the filesystem as usual, while other processes see it disappeared. It <a href="https://unix.stackexchange.com/q/390056/211239">could be dangerous</a>, but as we’re the one-and-only process inside the container, we know it’s safe for us.</p>
	<p>With that many information told, the actual code is really simple:</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="n">umount2</span><span class="p">(</span><span class="s">"/oldroot"</span><span class="p">,</span> <span class="n">MNT_DETACH</span><span class="p">);</span>
</code></pre>
		</div>
	</div>
	<p>We’re using the <code class="language-plaintext highlighter-rouge">umount2</code> system call because we need to pass the extra flags to it. Now that the host filesystem is gone, we can remove the now-empty directory (remember we’re doing clean-up jobs):</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="n">rmdir</span><span class="p">(</span><span class="s">"/oldroot"</span><span class="p">);</span>
</code></pre>
		</div>
	</div>
	<p>We’ve isolated our container filesystem from the host system, and then we can proceed to securing and fortifying our container.</p>
	<h2 id="capabilities">Capabilities</h2>
	<p>In the traditional UNIX era, there were only two privilege levels - <em>privileged</em> (root) and <em>unprivileged</em> (non-root), where a <em>privileged</em> process has every privilege to alter the system, while an <em>unprivileged</em> process has none. Since Linux 2.2 in 1999, <em>capabilities</em> have been added to the kernel so that unprivileged processes may acquire certain abilities needed for some task, while privileged processes may drop capabilities unneeded, allowing for privilege control at a finer granularity. A <code class="language-plaintext highlighter-rouge">ping</code> process doesn’t need any extra privileges than sending ICMP packets, and a web server (probably) doesn’t need any extra privileges than binding to a low port (1 to 1023), do they?</p>
	<p>With capabilities, unprivileged processes can be granted access to selected system functionalities, while privileged processes can be deprived of selected ones. For example, <code class="language-plaintext highlighter-rouge">CAP_NET_BIND_SERVICE</code> is the capability to bind to TCP or UDP ports between 1 and 1023, and <code class="language-plaintext highlighter-rouge">CAP_CHOWN</code> enables the use of <code class="language-plaintext highlighter-rouge">chown(2)</code>.</p>
	<p>Now turning our focus back to containers. Without privilege separation, a “root” process inside a container can still do dangerous things, like scanning your hard drive where the host filesystem resides, and manipulate it. This is definitely not anything expected, so we’re going to limit the capabilities the container can have as a whole.</p>
	<p>The system calls behind capabilities manipulation are very complicated, so unlike in previous sections, we’re going to use wrapped-up libraries to aid with this. There are two options available, <code class="language-plaintext highlighter-rouge">libcap</code> and <code class="language-plaintext highlighter-rouge">libcap-ng</code>, of which the latter is easier to understand and use. The documentations for <a href="https://linux.die.net/man/3/libcap">libcap</a> and <a href="https://people.redhat.com/sgrubb/libcap-ng/">libcap-ng</a> are given. Note that since they’re “external” libraries, extra flags need to be supplied when compiling. For libcap you’ll add <code class="language-plaintext highlighter-rouge">-lcap</code> to the compilation command, and similarly for libcap-ng you’ll add <code class="language-plaintext highlighter-rouge">-lcap-ng</code> to the command.</p>
	<p>As an easier starting point, we’ll use <a href="https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities">Docker’s capabilities set</a> to avoid having to sort everything out by ourselves. Before we start, there’s another thing to learn - the different “sets” of capabilities of a process. In a few short words,</p>
	<ul>
		<li>The <em>bounding</em> set restricts the maximum possible set of capabilities a process (and all its descendants) can have</li>
		<li>The <em>effective</em> set is what a process currently has and is effective</li>
		<li>The <em>permitted</em> set may be granted when “asked” (using the appropriate system calls)</li>
	</ul>
	<p>It’s noticeable that we want to limit all three sets for the container. Using libcap-ng, the code is very simple:</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="n">capng_clear</span><span class="p">(</span><span class="n">CAPNG_SELECT_BOTH</span><span class="p">);</span>
<span class="n">capng_updatev</span><span class="p">(</span><span class="n">CAPNG_ADD</span><span class="p">,</span> <span class="p">(</span><span class="n">capng_type_t</span><span class="p">)(</span><span class="n">CAPNG_EFFECTIVE</span> <span class="o">|</span> <span class="n">CAPNG_PERMITTED</span> <span class="o">|</span> <span class="n">CAPNG_BOUNDING_SET</span><span class="p">),</span>
    <span class="n">CAP_SETPCAP</span><span class="p">,</span>
    <span class="c1">// ...</span>
    <span class="n">CAP_SETFCAP</span><span class="p">,</span>
    <span class="o">-</span><span class="mi">1</span><span class="p">);</span>
<span class="n">capng_apply</span><span class="p">(</span><span class="n">CAPNG_SELECT_BOTH</span><span class="p">);</span>
</code></pre>
		</div>
	</div>
	<p>With <code class="language-plaintext highlighter-rouge">capng_clear</code>, we clear all capabilities from our pending changes, and add whitelisted capabilities, before finally applying the changes.</p>
	<p>Using libcap, however, is slightly more complicated to achieve the same, as there’s no direct “clear all” function, but instead you’ll have to list them by yourself. <a href="https://github.com/iBug/iSpawn/commit/bcf27bf42771e7fd8c7f24abbec5907f6f727fd7">Here</a>’s an older version of my attempted code if you want to learn. Nevertheless, it’s never bad to learn more.</p>
	<h2 id="seccomp">SecComp</h2>
	<p>SecComp (Secure Computing) is a security module in Linux that lets a process to transition one-way into a “secure state” where no system call other than <code class="language-plaintext highlighter-rouge">read()</code>, <code class="language-plaintext highlighter-rouge">write()</code>, <code class="language-plaintext highlighter-rouge">sigreturn()</code> and <code class="language-plaintext highlighter-rouge">exit()</code> is allowed. It’s easily noticeable that this feature is too strict for making something useful, and <strong>seccomp-bpf</strong> is an extension to the rescue.</p>
	<p>Seccomp BPF extends the seccomp module with Berkeley Packer Filter (BPF), an embedded instruction set that allows highly customized seccomp rules to be deployed. With BPF, you can create custom logic for system call filtering, including matching and testing individual system call arguments.</p>
	<h2 id="syscall-filter">System call filtering</h2>
	<p>To ensure full control, we’re using a whitelist for system calls. This means any unknown one will be rejected. So we’ll start by creating a new “SecComp filter context”, and set the default action to “reject”. By “reject”, we’ll return “permission denied” when a process tries to call it.</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="n">scmp_filter_ctx</span> <span class="n">ctx</span> <span class="o">=</span> <span class="n">seccomp_init</span><span class="p">(</span><span class="n">SCMP_ACT_ERRNO</span><span class="p">(</span><span class="mi">1</span><span class="p">));</span>
</code></pre>
		</div>
	</div>
	<p>The <code class="language-plaintext highlighter-rouge">SCMP_ACT_ERRNO(1)</code> refers exactly to “respond with EPERM”, which will be hit if no other filters apply.</p>
	<h3 id="syscall-whitelist">System call whitelist</h3>
	<p>We’ll now add each “safe” system call to our filter and set it to “allowed”. To save some time scratching your head examining each system call, we’ll adopt <a href="https://github.com/moby/moby/blob/master/profiles/seccomp/default.json">Docker’s syscall whitelist</a>. Each system call will be wrapped in <code class="language-plaintext highlighter-rouge">SCMP_SYS</code> so it’s turned into a suitable number used inside SecComp.</p>
	<p>We need to add the whole big list of “general” system calls, plus some platform- or scenario-specific ones, namely, two special system calls for <code class="language-plaintext highlighter-rouge">amd64</code> platform, and a few others for system administration, since we’ve allowed <code class="language-plaintext highlighter-rouge">CAP_SYS_ADMIN</code> inside the container.</p>
	<p>Use your favorite text processing toolstack to get the big list into a C-array so we can loop over, like <a href="https://github.com/iBug/iSpawn/blob/master/syscall_allow.c">this</a>:</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="kt">int</span> <span class="n">allowed_syscalls</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">SCMP_SYS</span><span class="p">(</span><span class="n">accept</span><span class="p">),</span>
    <span class="n">SCMP_SYS</span><span class="p">(</span><span class="n">accept4</span><span class="p">),</span>
    <span class="n">SCMP_SYS</span><span class="p">(</span><span class="n">access</span><span class="p">),</span>
    <span class="c1">// Many, many more...</span>
    <span class="n">SCMP_SYS</span><span class="p">(</span><span class="n">waitpid</span><span class="p">),</span>
    <span class="n">SCMP_SYS</span><span class="p">(</span><span class="n">write</span><span class="p">),</span>
    <span class="n">SCMP_SYS</span><span class="p">(</span><span class="n">writev</span><span class="p">),</span>
</code></pre>
		</div>
	</div>
	<p>And then append these special ones we want to include as well:</p>
	<div class="language-plaintext highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>    // amd64-specific required syscalls
    SCMP_SYS(arch_prctl),
    SCMP_SYS(modify_ldt),

    // CAP_SYS_ADMIN-specific syscalls
    SCMP_SYS(bpf),
    SCMP_SYS(clone),
    SCMP_SYS(fanotify_init),
    SCMP_SYS(lookup_dcookie),
    SCMP_SYS(mount),
    SCMP_SYS(name_to_handle_at),
    SCMP_SYS(perf_event_open),
    SCMP_SYS(quotactl),
    SCMP_SYS(setdomainname),
    SCMP_SYS(sethostname),
    SCMP_SYS(setns),
    SCMP_SYS(syslog),
    SCMP_SYS(umount),
    SCMP_SYS(umount2),
    SCMP_SYS(unshare)
};
</code></pre>
		</div>
	</div>
	<p>Find the number of items included, and save it for easier later use.</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="kt">size_t</span> <span class="n">allowed_syscalls_len</span> <span class="o">=</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">allowed_syscalls</span><span class="p">)</span> <span class="o">/</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">allowed_syscalls</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
</code></pre>
		</div>
	</div>
	<p>We can then add each system call to our new SecComp filter as “allowed” with a simple loop:</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">allowed_syscalls_len</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">seccomp_rule_add</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">SCMP_ACT_ALLOW</span><span class="p">,</span> <span class="n">allowed_syscalls</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">0</span><span class="p">);</span>
<span class="p">}</span>
</code></pre>
		</div>
	</div>
	<h3 id="loading-seccomp">Loading SecComp filter</h3>
	<p>After our filter has been constructed, we can load it onto our process for it to take effect.</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="n">seccomp_load</span><span class="p">(</span><span class="n">ctx</span><span class="p">);</span>
</code></pre>
		</div>
	</div>
	<p>And finally, release the workspace to avoid memory leaks.</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="n">seccomp_release</span><span class="p">(</span><span class="n">ctx</span><span class="p">);</span>
</code></pre>
		</div>
	</div>
	<h3 id="seccomp-caveats">Caveats</h3>
	<h4 id="seccomp-incompatible-syscalls">Incompatible system calls</h4>
	<p>As I worked this out on an Ubuntu 18.04 environment, some newer system calls weren’t available in my system headers, like the <code class="language-plaintext highlighter-rouge">io_uring</code>-related ones that are introduced in Linux 5.1. You can safely comment out any of them that your compiler complains about not recognizing. There shouldn’t be too many of them if your environment is up-to-date, though.</p>
	<h4 id="seccomp-checking">Precautionary checking</h4>
	<p>As it’s too common for one of the function calls to fail, I’ve added sanity checks for them. Here’s the complete code of this part.</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="kt">int</span> <span class="nf">filter_syscall</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">scmp_filter_ctx</span> <span class="n">ctx</span> <span class="o">=</span> <span class="n">seccomp_init</span><span class="p">(</span><span class="n">SCMP_ACT_ERRNO</span><span class="p">(</span><span class="mi">1</span><span class="p">));</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">ctx</span> <span class="o">==</span> <span class="nb">NULL</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">allowed_syscalls_len</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">if</span> <span class="p">((</span><span class="n">errno</span> <span class="o">=</span> <span class="n">seccomp_rule_add</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">SCMP_ACT_ALLOW</span><span class="p">,</span> <span class="n">allowed_syscalls</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="p">((</span><span class="n">errno</span> <span class="o">=</span> <span class="o">-</span><span class="n">seccomp_load</span><span class="p">(</span><span class="n">ctx</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">seccomp_release</span><span class="p">(</span><span class="n">ctx</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre>
		</div>
	</div>
	<h2 id="cgroups">Resource restriction</h2>
	<p>The last part we’ll visit is restricting container resources. Surely we don’t want a container to overuse system resources like CPU or RAM and make the host system less stable. Linux Control Groups (Cgroups) is designed for efficient resource constraint that we’re going to make use of. There are many “cgroup systems” for different aspects of system resources, including CPU, RAM and even disk I/O. Looks pretty neat, right?</p>
	<p>Unlike other parts we’ve built so far, cgroup doesn’t use system calls for setup and configuration, but a filesystem-based interface instead, like those in <code class="language-plaintext highlighter-rouge">/proc</code> or <code class="language-plaintext highlighter-rouge">/sys</code>. In fact, the cgroup control interface resides exactly under <code class="language-plaintext highlighter-rouge">/sys</code>, at <code class="language-plaintext highlighter-rouge">/sys/fs/cgroup</code>. With this interface, we read and write “files” to change configuration values, and create and delete directories to add or remove structures.</p>
	<p>There are multiple cgroup “controllers” working on different aspects of system resources, each having a distinct tree structure under <code class="language-plaintext highlighter-rouge">/sys/fs/cgroup</code>. So first we’ll examine what cgroup controllers are available:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">root@ubuntu:~#</span><span class="w"> </span><span class="nb">ls</span> /sys/fs/cgroup
<span class="go">blkio        cpuacct  freezer  net_cls           perf_event  systemd
cpu          cpuset   hugetlb  net_cls,net_prio  pids        unified
cpu,cpuacct  devices  memory   net_prio          rdma
</span></code></pre>
		</div>
	</div>
	<p>Here we’re interested in some of them, namely, <code class="language-plaintext highlighter-rouge">blkio</code>, <code class="language-plaintext highlighter-rouge">cpu</code>, <code class="language-plaintext highlighter-rouge">memory</code> and <code class="language-plaintext highlighter-rouge">pids</code>.</p>
	<p>Let’s first take a look at <code class="language-plaintext highlighter-rouge">pids</code>. We’ll create our own subtree to start with:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">root@ubuntu:~#</span><span class="w"> </span><span class="nb">mkdir</span> /sys/fs/cgroup/pids/ispawn
<span class="gp">root@ubuntu:~#</span><span class="w"> </span><span class="nb">ls</span> /sys/fs/cgroup/pids/ispawn
<span class="go">cgroup.clone_children  notify_on_release  pid.events  tasks
cgroup.procs           pid.current        pid.max
</span></code></pre>
		</div>
	</div>
	<p>It’s easily imagined that <code class="language-plaintext highlighter-rouge">pid.max</code> controls the maximum number of PIDs in this subsystem, so let’s write something to it:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">root@ubuntu:~#</span><span class="w"> </span><span class="nb">echo </span>16 <span class="o">&gt;</span> /sys/fs/cgroup/pids/ispawn/pid.max
</code></pre>
		</div>
	</div>
	<p>To verify that it’s working, make an attempt to exceed the limit. Open another shell and find its pid with <code class="language-plaintext highlighter-rouge">echo $$</code>. Write the number that you see (it’s the PID of the new shell) to <code class="language-plaintext highlighter-rouge">/sys/fs/cgroup/pids/ispawn/cgroup.procs</code>. You can verify that the new process has been added to the subsystem by reading that <code class="language-plaintext highlighter-rouge">cgroup.procs</code> files out, and you’ll see the PID you just written.</p>
	<p>Now switch to the new shell and try spawning a lot of subprocesses, for example:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..20<span class="o">}</span><span class="p">;</span> <span class="k">do</span> /bin/sleep 10<span class="p">;</span> <span class="k">done</span>
</code></pre>
		</div>
	</div>
	<p>You can see the shell output as <em>Operation not permitted</em> for 5 to 6 times. This means it has hit the PID cap and fails to spawn more processes.</p>
	<p>In our C-based container program, we’ll do this in the parent process. The code is intuitively simple.</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="n">mkdir</span><span class="p">(</span><span class="s">"/sys/fs/cgroup/pids/ispawn"</span><span class="p">,</span> <span class="mo">0777</span><span class="p">);</span>
<span class="kt">FILE</span> <span class="o">*</span><span class="n">fp</span> <span class="o">=</span> <span class="n">fopen</span><span class="p">(</span><span class="s">"/sys/fs/cgroup/pids/ispawn/pid.max"</span><span class="p">,</span> <span class="s">"w"</span><span class="p">);</span>
<span class="n">fprintf</span><span class="p">(</span><span class="n">fp</span><span class="p">,</span> <span class="s">"%d"</span><span class="p">,</span> <span class="mi">16</span><span class="p">);</span>
<span class="n">fclose</span><span class="p">(</span><span class="n">fp</span><span class="p">);</span>
<span class="kt">FILE</span> <span class="o">*</span><span class="n">fp</span> <span class="o">=</span> <span class="n">fopen</span><span class="p">(</span><span class="s">"/sys/fs/cgroup/pids/ispawn/cgroup.procs"</span><span class="p">,</span> <span class="s">"w"</span><span class="p">);</span>
<span class="n">fprintf</span><span class="p">(</span><span class="n">fp</span><span class="p">,</span> <span class="s">"%d"</span><span class="p">,</span> <span class="n">pid</span><span class="p">);</span> <span class="c1">// pid of the child process</span>
<span class="n">fclose</span><span class="p">(</span><span class="n">fp</span><span class="p">);</span>
</code></pre>
		</div>
	</div>
	<p>We can now proceed to setting other limits:</p>
	<ul>
		<li>To reduce CPU shares, we write to <code class="language-plaintext highlighter-rouge">cpu/cpu.shares</code>. Because CPU shares are relative to each other and the system default is usually 1024, setting the value to 256 for our container gives it 1/4 as much CPU as other processes when the system load goes up. (It still gets more CPU when needed and when the system is more idle.)</li>
		<li>To limit memory usage, we write to <code class="language-plaintext highlighter-rouge">memory/memory.limit_in_bytes</code> (for userspace memory) and <code class="language-plaintext highlighter-rouge">memory/memory.kmem.limit_in_bytes</code> (for kernel memory).
			<ul>
				<li>However, this limits only physical memory usage, so when swap is present, memory gets swapped out onto disk when it hits the limit. To completely disable swap for our container, set <code class="language-plaintext highlighter-rouge">memory/memory.swappiness</code> to zero.</li>
			</ul>
		</li>
		<li>To reduce disk I/O priority, we write to <code class="language-plaintext highlighter-rouge">blkio/weight</code>. This is relative to 100 so writing 50 will reduce its disk I/O priority to half.</li>
		<li>The last thing to note is that the tree hierarchies are independent among different cgroup controllers, so you have to create the same <code class="language-plaintext highlighter-rouge">ispawn</code> directory in <em>each</em> of them, and write <code class="language-plaintext highlighter-rouge">cgroup.procs</code> inside <em>each</em> of them.</li>
	</ul>
	<div class="notice--primary">
		<h4 class="no_toc" id="heads-up"><i class="fas fa-fw fa-lightbulb"></i> Heads up</h4>
		<p>The course lab at the time was based on Ubuntu 18.04 with Linux kernel 5.3 (18.04 HWE). The cgroup controllers in newer kernels may be very different from what’s presented in this article. For example, with Linux 5.4 on Ubuntu 20.04, the keys in PID cgroup begins with <code class="language-plaintext highlighter-rouge">pids.</code> instead of <code class="language-plaintext highlighter-rouge">pid.</code>, and <code class="language-plaintext highlighter-rouge">blkio</code> has a completely different set of available keys. Make sure you examine the cgroup directories before copying and pasting code.</p>
	</div>
	<h3 id="mount-cgroup-controllers">Mounting cgroup controllers inside the container</h3>
	<p>To enable applications in our container to use cgroup controllers, we must mount them inside. Like how we mounted <code class="language-plaintext highlighter-rouge">/sys</code>, <code class="language-plaintext highlighter-rouge">/tmp</code> and other filesystems, we check the output of <code class="language-plaintext highlighter-rouge">mount</code> to determine how we’re going to call <code class="language-plaintext highlighter-rouge">mount(2)</code>.</p>
	<div class="language-text highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)
</code></pre>
		</div>
	</div>
	<p>Everything looks similar to what we’ve just done, but there’s one different thing: There’s no mount flag for <code class="language-plaintext highlighter-rouge">pids</code>.</p>
	<p>Recalling <a href="#mount-data-parameter">we skipped the last parameter of <code class="language-plaintext highlighter-rouge">mount</code></a>, now it’s time to pick it back up. Fortunately, it isn’t too complicated. For our use case, we can just pass the string <code class="language-plaintext highlighter-rouge">"pids"</code> to that parameter, and we swap the string for another to mount another cgroup controller. You can read the man page for <a href="https://man7.org/linux/man-pages/man7/cgroups.7.html"><code class="language-plaintext highlighter-rouge">cgroups(7)</code></a> about this, look for <em>Mounting v1 controllers</em>.</p>
	<p>To mimic the monut points on our host system, we additionally mount a tmpfs at <code class="language-plaintext highlighter-rouge">/sys/fs/cgroup</code>, and remount this mountpoint as read-only after adding the controllers. The final result looks like this:</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="kt">void</span> <span class="nf">mount_cgroup</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">cgmountflags</span> <span class="o">=</span> <span class="n">MS_NOSUID</span> <span class="o">|</span> <span class="n">MS_NODEV</span> <span class="o">|</span> <span class="n">MS_NOEXEC</span> <span class="o">|</span> <span class="n">MS_RELATIME</span><span class="p">;</span>
    <span class="c1">// Mount a tmpfs first</span>
    <span class="n">mount</span><span class="p">(</span><span class="s">"none"</span><span class="p">,</span> <span class="s">"sys/fs/cgroup"</span><span class="p">,</span> <span class="s">"tmpfs"</span><span class="p">,</span> <span class="n">cgmountflags</span><span class="p">,</span> <span class="s">"mode=755"</span><span class="p">);</span>

    <span class="c1">// Prepare mount points</span>
    <span class="n">mkdir</span><span class="p">(</span><span class="s">"sys/fs/cgroup/blkio"</span><span class="p">,</span> <span class="mo">0755</span><span class="p">);</span>
    <span class="n">mkdir</span><span class="p">(</span><span class="s">"sys/fs/cgroup/cpu,cpuacct"</span><span class="p">,</span> <span class="mo">0755</span><span class="p">);</span>
    <span class="n">mkdir</span><span class="p">(</span><span class="s">"sys/fs/cgroup/memory"</span><span class="p">,</span> <span class="mo">0755</span><span class="p">);</span>
    <span class="n">mkdir</span><span class="p">(</span><span class="s">"sys/fs/cgroup/pids"</span><span class="p">,</span> <span class="mo">0755</span><span class="p">);</span>

    <span class="c1">// Mount cgroup subsystems</span>
    <span class="n">mount</span><span class="p">(</span><span class="s">"cgroup"</span><span class="p">,</span> <span class="s">"sys/fs/cgroup/blkio"</span><span class="p">,</span> <span class="s">"cgroup"</span><span class="p">,</span> <span class="n">cgmountflags</span><span class="p">,</span> <span class="s">"blkio"</span><span class="p">);</span>
    <span class="n">mount</span><span class="p">(</span><span class="s">"cgroup"</span><span class="p">,</span> <span class="s">"sys/fs/cgroup/cpu,cpuacct"</span><span class="p">,</span> <span class="s">"cgroup"</span><span class="p">,</span> <span class="n">cgmountflags</span><span class="p">,</span> <span class="s">"cpu,cpuacct"</span><span class="p">);</span>
    <span class="n">mount</span><span class="p">(</span><span class="s">"cgroup"</span><span class="p">,</span> <span class="s">"sys/fs/cgroup/memory"</span><span class="p">,</span> <span class="s">"cgroup"</span><span class="p">,</span> <span class="n">cgmountflags</span><span class="p">,</span> <span class="s">"memory"</span><span class="p">);</span>
    <span class="n">mount</span><span class="p">(</span><span class="s">"cgroup"</span><span class="p">,</span> <span class="s">"sys/fs/cgroup/pids"</span><span class="p">,</span> <span class="s">"cgroup"</span><span class="p">,</span> <span class="n">cgmountflags</span><span class="p">,</span> <span class="s">"pids"</span><span class="p">);</span>

    <span class="c1">// cpu and cpuacct need symlinks</span>
    <span class="n">symlink</span><span class="p">(</span><span class="s">"cpu,cpuacct"</span><span class="p">,</span> <span class="s">"sys/fs/cgroup/cpu"</span><span class="p">);</span>
    <span class="n">symlink</span><span class="p">(</span><span class="s">"cpu,cpuacct"</span><span class="p">,</span> <span class="s">"sys/fs/cgroup/cpuacct"</span><span class="p">);</span>

    <span class="c1">// Remount the tmpfs as R/O</span>
    <span class="n">mount</span><span class="p">(</span><span class="nb">NULL</span><span class="p">,</span> <span class="s">"sys/fs/cgroup"</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="n">MS_REMOUNT</span> <span class="o">|</span> <span class="n">MS_RDONLY</span> <span class="o">|</span> <span class="n">cgmountflags</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre>
		</div>
	</div>
	<h3 id="cgroup-namespace-caveat">A small problem with cgroup namespace</h3>
	<p>During my experiments, I noticed a strange issue where I could see the host cgroup hierarchies in my container implementation. It turns out that the cgroup “root” inside a cgroup namespace is the subtree the process belongs in when this cgroup namespace is created / isolated. Once the namespaces is created, its root is determined and fixed, even if the “root” process is moved into another subtree later.</p>
	<p>This means the child process must be “moved” to the desired cgroup subtree before the cgroup namespace is isolated. This leaves us with two options:</p>
	<ol>
		<li>The parent process moves itself to the target cgroup subtree before calling <code class="language-plaintext highlighter-rouge">clone()</code> with <code class="language-plaintext highlighter-rouge">CLONE_NEWCGROUP</code></li>
		<li>The parent process calls <code class="language-plaintext highlighter-rouge">clone()</code> without <code class="language-plaintext highlighter-rouge">CLONE_NEWCGROUP</code>, moves the child process to the target cgroup subtree, and then tells the child process to isolate the cgroup namespace.</li>
	</ol>
	<p>It should be noted that with the second option, some kind of “syncing” is needed to avoid the child process going too quickly to perform the cgroup namespace isolation before the parent process finishes its job. It’s easy to come up with a solution that just works: We can create a pipe between the processes, where the parent process can send something to tell the child process that it’s ready.</p>
	<p>With this in mind, the second option is actually <a href="https://github.com/iBug/iSpawn/commit/cc4dcb1032e2a4d4fc57491cc904f126b719ba88">easier to implement</a>, since there’s another system call for isolating namespaces in-place (i.e. without creating a new process), that we put away earlier. It’s <code class="language-plaintext highlighter-rouge">unshare(2)</code>. It’s simple to use, too, just call <code class="language-plaintext highlighter-rouge">unshare(CLONE_NEWCGROUP)</code> when ready.</p>
	<p>To verify that this issue is handled correctly, check the content in <code class="language-plaintext highlighter-rouge">/proc/1/cgroup</code>. The correct result should look like this, where every line ends with a single <code class="language-plaintext highlighter-rouge">/</code>:</p>
	<div class="language-text highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>12:cpuset:/
11:rdma:/
10:blkio:/
9:pids:/
8:devices:/
7:net_cls,net_prio:/
6:memory:/
5:hugetlb:/
4:perf_event:/
3:cpu,cpuacct:/
2:freezer:/
1:name=systemd:/
0::/
</code></pre>
		</div>
	</div>
	<p>With an incorrectly written container, certain lines may have an unexpected value, generally starting with <code class="language-plaintext highlighter-rouge">/../</code>, for example:</p>
	<div class="language-text highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>12:cpuset:/
11:rdma:/
10:blkio:/../user.slice
9:pids:/../user.slice/user-0.slice/
8:devices:/
7:net_cls,net_prio:/
6:memory:/../user.slice/user-0.slice/
5:hugetlb:/
4:perf_event:/
3:cpu,cpuacct:/../user.slice
2:freezer:/
1:name=systemd:/
0::/
</code></pre>
		</div>
	</div>
	<p>As explained above, these paths are “paths to the cgroup location of PID 1 relative to the ‘root’ of the cgroup namespace”. When properly done, the PID 1 should have all of its cgroup hierarchies belonging at “root”.</p>
	<p>Don’t be surprised to see the inconsistent lines from <code class="language-plaintext highlighter-rouge">/proc/1/cgroup</code>, as a process can be at different locations in different cgroup controllers.</p>
	<h2 id="conclusion">Conclusion</h2>
	<p>Now here, at this point, we’ve gone through all technologies required for a functional and secure Linux container, although our “container” isn’t necessarily functional and secure. It’s going to be hard work examining and patching all the loopholes for the best security, if you’d like, but the fundamentals have been covered already so there won’t be anything new.</p>
	<p>There are two namespaces we’ve skipped in the beginning (three if you count <code class="language-plaintext highlighter-rouge">CLONE_NEWTIME</code>). They are slightly more complicated to set up and isn’t necessary for a container, as Docker doesn’t use User Namespaces and systemd-nspawn doesn’t use Network Namespaces by default.</p>
	<p>There are also more to consider if you want multiple containers to run simultaneously. One notable thing is that each should have a separete cgroup subtree. Avoiding mount point conflict in race conditions is another thing to take into account.</p>
	<p>Should you want a ready-to-use example to play with, here’s the complete code that I wrote, with some bells and whistles added: <a href="https://github.com/iBug/iSpawn"><i class="fab fa-github"></i> iBug/iSpawn</a>. Keep in mind that it’s wrote for Ubuntu 18.04 and things could have been changed drastically, so it may not work in your system.</p>
	<h3 id="further-reading">Further reading</h3>
	<ul>
		<li><strong>Linux containers in 500 lines of code</strong> by <em>Lizzie Dixon</em> - <a href="https://blog.lizzie.io/linux-containers-in-500-loc.html">https://blog.lizzie.io/linux-containers-in-500-loc.html</a></li>
		<li>Wikipedia articles on …
			<ul>
				<li><a href="https://en.wikipedia.org/wiki/Linux_namespaces">Linux Namespaces</a></li>
				<li><a href="https://en.wikipedia.org/wiki/Capability-based_security">Capability-based security</a></li>
				<li><a href="https://en.wikipedia.org/wiki/Seccomp">SecComp</a></li>
				<li><a href="https://en.wikipedia.org/wiki/Cgroups">Cgroups</a></li>
				<li><a href="https://en.wikipedia.org/wiki/Security-Enhanced_Linux">SELinux</a>, which we didn’t touch here</li>
			</ul>
		</li>
	</ul>
	]]></content><author><name>iBug</name></author><category term="linux" /><category term="container" /><category term="c" /><summary type="html"><![CDATA[Let's write our own container in C, from scratch]]></summary></entry></feed>