<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://ibug.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ibug.io/" rel="alternate" type="text/html" /><updated>2022-03-18T06:23:08+00:00</updated><id>https://ibug.io/feed.xml</id><title type="html">iBug</title><subtitle>The little personal site for iBug</subtitle><author><name>iBug</name></author><entry><title type="html">Centralized Linux authentication with OpenLDAP</title><link href="https://ibug.io/blog/2022/03/linux-openldap-server/" rel="alternate" type="text/html" title="Centralized Linux authentication with OpenLDAP" /><published>2022-03-18T00:00:00+00:00</published><updated>2022-03-18T14:22:38+00:00</updated><id>https://ibug.io/blog/2022/03/linux-openldap-server</id><content type="html" xml:base="https://ibug.io/blog/2022/03/linux-openldap-server/"><![CDATA[<p>LDAP, <del>the #1 way to get your graduation delayed</del> (as has always been the meme around Tsinghua University), is every SysAdmin’s dream tool for their servers. As mighty as its rumors fly, LDAP takes the most serious dedication to set up and maintain, yet the slightest agitation to fail.</p>
			<p>The <em>correct</em> story behind this opens up with our lab’s messy machine management. While home directories across machines are shared from a common NFS server, user and group information is managed manually. To start with, whenever someone joins our lab, the other admin (thankfully not yet me) creates a user for them on <em>every</em> machine they’d access, while paying attention to the consistency of UID and GID. What’s worse, we often grant temporary access to a selected set of machines to guest students to enable them to work on certain projects, or to participate in competitions on behalf of our lab. Not to mention the other admin himself has literally 5 different UIDs on different hosts.</p>
			<p>LDAP solves this agony and saves a lot of sysadmins’ souls by providing centralized management to users, groups and some other organizational resources using a directory-structured database. While I previously used an existing GOsa² setup for simple management tasks, our lab’s new cluster provides an excellent opportunity to try out LDAP anew.</p>
			<h2 id="prerequisites">Prerequisites</h2>
			<p>Thanks to a network outage a few days ago, I get to reinstall our NFS server into Proxmox VE (yes again) to allow more specialized applications to be deployed in a more flexible manner. So I can just launch a new Debian Bullseye (11) virtual machine and begin this journey. The rest of this blog post assumes this environment.</p>
			<h2 id="i-389ds">Interlude: 389 Directory Server</h2>
			<p>A friend recommended Fedora’s <a href="https://directory.fedoraproject.org/">389 Directory Server</a> after learning that I wanted to set up some LDAP server, indicating that it’s easier to use and maintain.</p>
			<p>So I followed the documentation and got a 389DS up and running. Everything looked simple and straightforward until I went on configuring TLS certificates. I created a self-signed certificate with extra Subject Alternative Names (as needed) and tried to import them to 389DS. <a href="https://directory.fedoraproject.org/docs/389ds/howto/howto-ssl-archive.html#importing-an-existing-self-sign-keycert-or-3rd-party-cacert">Their documentation on this</a> is completely unhelpful, and I struggled for two tedious hours before landing on <a href="https://access.redhat.com/documentation/en-us/red_hat_directory_server/11/html/administration_guide/managing_the_nss_database_used_by_directory_server">Red Hat’s documentation</a> that actually worked. 389DS’s default “group” object doesn’t support POSIX GID, either.</p>
			<p>All those failures led to one question: Why bother with 389DS when it still uses <code class="language-plaintext highlighter-rouge">slapd</code> behind? So I ditched this VM and gave it up.</p>
			<h2 id="server">Server setup</h2>
			<p>Installation is easy:</p>
			<div class="language-shell highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code>apt <span class="nb">install </span>slapd
</code></pre>
				</div>
			</div>
			<p>This installs the OpenLDAP server with all recommended packages that’ll aid configuration. During installation, you’ll be prompted for the admin password. Ignore that for now as we’ll (probably) have to reconfigure this later.</p>
			<p>This is because slapd tries to automatically determine the base Distinguished Name for the server, which often fails and falls back to the unpleasant <code class="language-plaintext highlighter-rouge">dc=nodomain</code>.</p>
			<p>Run <code class="language-plaintext highlighter-rouge">dpkg-reconfigure slapd</code> to specify a domain name that will be used to construct the base DN from. It’s perfectly fine to have a short name like just <code class="language-plaintext highlighter-rouge">ibug</code>, or you can choose to be serious on this and use <code class="language-plaintext highlighter-rouge">example.com</code>. Either way, you probably don’t want to have a long DN like <code class="language-plaintext highlighter-rouge">dc=protonlab,dc=research,dc=google,dc=com</code>, which will make manual querying a nightmare.</p>
			<p>Now we have an empty OpenLDAP server. The admin user’s DN is <code class="language-plaintext highlighter-rouge">cn=admin</code> followed by your base DN, so most data manipulation tasks require the role to be bound to <code class="language-plaintext highlighter-rouge">cn=admin,dc=ibug</code> for me.</p>
			<p>The additional package <code class="language-plaintext highlighter-rouge">ldap-utils</code> provides tools like <code class="language-plaintext highlighter-rouge">ldapadd</code>, <code class="language-plaintext highlighter-rouge">ldapmodify</code> and <code class="language-plaintext highlighter-rouge">ldapdelete</code> which we’ll be mostly using later. <code class="language-plaintext highlighter-rouge">slapd</code> provides <code class="language-plaintext highlighter-rouge">slapcat</code> that dumps the whole database and <code class="language-plaintext highlighter-rouge">ldapvi</code> provides an interactive editor, both of which come in handy for management and debugging.</p>
			<h3 id="ldap-utils">Configuring LDAP tools</h3>
			<p>All interactions with the server are done through <code class="language-plaintext highlighter-rouge">ldap*</code> commands submitting text in LDIF (LDAP Data Interchange Format).</p>
			<p>Before moving on to the next step, there are config files for common settings that simplifies later tasks.</p>
			<p>Open <code class="language-plaintext highlighter-rouge">/etc/ldap/ldap.conf</code> (the system-wide settings) and set these options:</p>
			<div class="language-text highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code>BASE    dc=ibug
URI     ldapi:///
</code></pre>
				</div>
			</div>
			<p>There are 3 ways to connect to an LDAP server</p>
			<ul>
				<li><code class="language-plaintext highlighter-rouge">ldap://</code> (plaintext TCP, default port 389)</li>
				<li><code class="language-plaintext highlighter-rouge">ldaps://</code> (over SSL/TLS, default port 636)</li>
				<li><code class="language-plaintext highlighter-rouge">ldapi://</code> (over IPC, or Unix domain socket, usually <code class="language-plaintext highlighter-rouge">/var/run/slapd/ldapi</code>)</li>
			</ul>
			<p>Once you have this file set up, you can omit the <code class="language-plaintext highlighter-rouge">-H &lt;host&gt;</code> option from all <code class="language-plaintext highlighter-rouge">ldap*</code> commands. Similarly, <code class="language-plaintext highlighter-rouge">BASE</code> is useful in <code class="language-plaintext highlighter-rouge">ldapsearch</code> or like.</p>
			<h3 id="seeding">Populating the database</h3>
			<p>Now that we have an empty database, we can create two directories for our users and groups. This is the first LDIF file to have.</p>
			<div class="language-yaml highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="na">dn</span><span class="pi">:</span> <span class="s">ou=user,dc=ibug</span>
<span class="na">objectClass</span><span class="pi">:</span> <span class="s">organizationalUnit</span>
<span class="na">ou</span><span class="pi">:</span> <span class="s">user</span>

<span class="na">dn</span><span class="pi">:</span> <span class="s">ou=group,dc=ibug</span>
<span class="na">objectClass</span><span class="pi">:</span> <span class="s">organizationalUnit</span>
<span class="na">ou</span><span class="pi">:</span> <span class="s">group</span>
</code></pre>
				</div>
			</div>
			<p>Use <code class="language-plaintext highlighter-rouge">ldapadd -D cn=admin,dc=ibug -W -f base.ldif</code> to load the “change request” into the database.</p>
			<h3 id="users-and-groups">Managing users and groups</h3>
			<p>Now create the first user and group:</p>
			<div class="language-yaml highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="na">dn</span><span class="pi">:</span> <span class="s">uid=ibug,ou=user,dc=ibug</span>
<span class="na">objectClass</span><span class="pi">:</span> <span class="s">posixAccount</span>
<span class="na">objectClass</span><span class="pi">:</span> <span class="s">shadowAccount</span>
<span class="na">objectClass</span><span class="pi">:</span> <span class="s">inetOrgPerson</span>
<span class="na">cn</span><span class="pi">:</span> <span class="s">iBug</span>
<span class="na">sn</span><span class="pi">:</span> <span class="s">iBug</span>
<span class="na">uid</span><span class="pi">:</span> <span class="s">ibug</span>
<span class="na">uidNumber</span><span class="pi">:</span> <span class="m">1000</span>
<span class="na">gidNumber</span><span class="pi">:</span> <span class="m">1000</span>
<span class="na">homeDirectory</span><span class="pi">:</span> <span class="s">/home/ibug</span>
<span class="na">loginShell</span><span class="pi">:</span> <span class="s">/bin/bash</span>
<span class="na">gecos</span><span class="pi">:</span> <span class="s">iBug</span>

<span class="na">dn</span><span class="pi">:</span> <span class="s">cn=staff,ou=group,dc=ibug</span>
<span class="na">objectClass</span><span class="pi">:</span> <span class="s">posixGroup</span>
<span class="na">cn</span><span class="pi">:</span> <span class="s">staff</span>
<span class="na">gidNumber</span><span class="pi">:</span> <span class="m">1000</span>
<span class="na">description</span><span class="pi">:</span> <span class="s">My staff group</span>
</code></pre>
				</div>
			</div>
			<p>For user objects, <code class="language-plaintext highlighter-rouge">inetOrgPerson</code> is a required “object class”, and therefore the <code class="language-plaintext highlighter-rouge">cn</code> and <code class="language-plaintext highlighter-rouge">sn</code> fields. Linux uses <code class="language-plaintext highlighter-rouge">posixAccount</code> and <code class="language-plaintext highlighter-rouge">shadowAccount</code> for authentication, and the <code class="language-plaintext highlighter-rouge">gecos</code> field is the one that’ll appear in output from commands like <code class="language-plaintext highlighter-rouge">getent passwd</code>.</p>
			<p>To add a user to a group, use <code class="language-plaintext highlighter-rouge">ldapmodify</code> with this LDIF file:</p>
			<div class="language-yaml highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="na">dn</span><span class="pi">:</span> <span class="s">cn=staff,ou=group,dc=ibug</span>
<span class="na">changetype</span><span class="pi">:</span> <span class="s">modify</span>
<span class="na">add</span><span class="pi">:</span> <span class="s">memberUid</span>
<span class="na">memberUid</span><span class="pi">:</span> <span class="s">ibug</span>
</code></pre>
				</div>
			</div>
			<p>Similarly, to change user information, just use <code class="language-plaintext highlighter-rouge">replace</code> with <code class="language-plaintext highlighter-rouge">changetype: modify</code>:</p>
			<div class="language-yaml highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="na">dn</span><span class="pi">:</span> <span class="s">cn=staff,ou=group,dc=ibug</span>
<span class="na">changetype</span><span class="pi">:</span> <span class="s">modify</span>
<span class="na">replace</span><span class="pi">:</span> <span class="s">gecos</span>
<span class="na">gecos</span><span class="pi">:</span> <span class="s">New iBug</span>
</code></pre>
				</div>
			</div>
			<p>If you’re importing users and groups from an existing system, you may find the ability to preload the group with an initial set of users useful. When creating the group, you may supply any number of <code class="language-plaintext highlighter-rouge">memberUid</code>s. This has the same effect as adding them one by one.</p>
			<div class="language-yaml highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="na">dn</span><span class="pi">:</span> <span class="s">cn=staff,ou=group,dc=ibug</span>
<span class="na">objectClass</span><span class="pi">:</span> <span class="s">posixGroup</span>
<span class="na">cn</span><span class="pi">:</span> <span class="s">staff</span>
<span class="na">gidNumber</span><span class="pi">:</span> <span class="m">1000</span>
<span class="na">description</span><span class="pi">:</span> <span class="s">My staff group</span>
<span class="na">memberUid</span><span class="pi">:</span> <span class="s">ibug</span>
<span class="na">memberUid</span><span class="pi">:</span> <span class="s">user1</span>
<span class="na">memberUid</span><span class="pi">:</span> <span class="s">user2</span>
<span class="na">memberUid</span><span class="pi">:</span> <span class="s">user3</span>
<span class="na">memberUid</span><span class="pi">:</span> <span class="s">user4</span>
</code></pre>
				</div>
			</div>
			<p>Last but not least, <code class="language-plaintext highlighter-rouge">ldappasswd</code> sets or resets passwords for users:</p>
			<div class="language-shell highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code>ldappasswd <span class="nt">-D</span> <span class="nv">cn</span><span class="o">=</span>admin,dc<span class="o">=</span>ibug <span class="nt">-W</span> <span class="nv">uid</span><span class="o">=</span>ibug,ou<span class="o">=</span>group,dc<span class="o">=</span>ibug
</code></pre>
				</div>
			</div>
			<p>If you don’t give the new password, <code class="language-plaintext highlighter-rouge">ldappasswd</code> will generate a random new one for you, which you can forward to the user themself.</p>
			<h3 id="import-passwords">Importing passwords from Linux</h3>
			<p>One great concern while migrating my lab’s authentication completely onto LDAP was whether users can keep their passwords. LDAP uses another hashing scheme SSHA by default, while any supported hashing scheme may be imported.</p>
			<p>By default, modern Linux stores hashed user password in <code class="language-plaintext highlighter-rouge">/etc/shadow</code>, which is only accessible by root. It contains lines like this:</p>
			<div class="language-text highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code>root:$y$j9T$egdUbc2x4FiVY42xxEH4z.$OJA25VwJ2fIEZizIqUDkS/yUtz8z5tuRiSS3XLum/F3:19064:0:99999:7:::
</code></pre>
				</div>
			</div>
			<p>The 2nd field, delimited by colons, is the hashed password in <a href="https://en.wikipedia.org/wiki/Bcrypt">Bcrypt</a> format. To import that into LDAP, prepend the hash with <code class="language-plaintext highlighter-rouge">{CRYPT}</code>, like this:</p>
			<div class="language-yaml highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="na">dn</span><span class="pi">:</span> <span class="s">uid=ibug,ou=group,dc=ibug</span>
<span class="na">changetype</span><span class="pi">:</span> <span class="s">modify</span>
<span class="na">replace</span><span class="pi">:</span> <span class="s">userPassword</span>
<span class="na">userPassword</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">CRYPT</span><span class="pi">}</span><span class="s">$y$j9T$egdUbc2x4FiVY42xxEH4z.$OJA25VwJ2fIEZizIqUDkS/yUtz8z5tuRiSS3XLum/F3</span>
</code></pre>
				</div>
			</div>
			<p>It will be replaced with LDAP’s default password hash type when the user changes their password for the next time.</p>
			<p>Now that we have our server set up and running, it’s time to configure client machines to use it.</p>
			<h2 id="client">Client setup</h2>
			<p>There are two options for clients: More commonly <code class="language-plaintext highlighter-rouge">libnss-ldapd</code> and <code class="language-plaintext highlighter-rouge">libpam-ldapd</code> are used together, or <code class="language-plaintext highlighter-rouge">sssd</code> if you’re familiar with it (which will not be described in this post). Note that are two obsolete packages <code class="language-plaintext highlighter-rouge">libnss-ldap</code> and <code class="language-plaintext highlighter-rouge">libpam-ldap</code> (both missing the final <code class="language-plaintext highlighter-rouge">d</code>) that might confuse you.</p>
			<p>Start with <code class="language-plaintext highlighter-rouge">apt install libnss-ldapd libpam-ldapd</code>. You’ll be asked for the LDAP server and the base DN, then “name services to configure”. Select <code class="language-plaintext highlighter-rouge">passwd group shadow</code> for now.</p>
			<p><img src="/image/linux/libnss-ldapd.png" alt="Configure libnss-ldapd" /></p>
			<p>These two packages should also pull in <code class="language-plaintext highlighter-rouge">nscd</code> (Name Service Cache Daemon) and <code class="language-plaintext highlighter-rouge">nslcd</code> (Name Service LDAP Client Daemon). The former provides a local cache for name service lookup results, while the latter provides the ability to lookup items from an LDAP server.</p>
			<p>After configuring the packages, your <code class="language-plaintext highlighter-rouge">/etc/nslcd.conf</code> should contain two lines that look similar to that of <code class="language-plaintext highlighter-rouge">/etc/ldap/ldap.conf</code>, except that the keys are in lowercase.</p>
			<div class="language-text highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code>uri ldap://ldap.example.com
base dc=ibug
</code></pre>
				</div>
			</div>
			<p>If the LDAP server is configured correctly (for <code class="language-plaintext highlighter-rouge">nslcd</code>), you should now be able to see LDAP users in the output of <code class="language-plaintext highlighter-rouge">getent passwd</code>, as well as <code class="language-plaintext highlighter-rouge">getent group</code>. LDAP users can also login via SSH or ttys.</p>
			<p>An LDAP user changes their password using the same <code class="language-plaintext highlighter-rouge">passwd</code> command, which will be stored in LDAP and immediately available to all machines connected to this LDAP server. In case it doesn’t, <code class="language-plaintext highlighter-rouge">nscd -i passwd</code> and <code class="language-plaintext highlighter-rouge">nscd -i group</code> will refresh the cache and allow nslcd to pull in the latest information.</p>
			<h2 id="advanced">Advanced topics</h2>
			<h3 id="tls">Securing LDAP server with TLS</h3>
			<p>Nothing is “baseline secure” over unencrypted traffic, so the next thing is to add TLS certificates for the LDAP server. Certificates aren’t hard to get. For example, if you have a public domain, <a href="https://letsencrypt.org/">Let’s Encrypt</a> is the easiest way to get a universally-trusted certificate. Otherwise, you can create a self-signed certificate that can include any domain name or IP address. <a href="https://hohnstaedt.de/xca/">XCA</a> is one of the best tools to manage a private Certificate Authority.</p>
			<p>Copy the certificate and private key files to the <code class="language-plaintext highlighter-rouge">/etc/ldap/</code> directory. Change the owner and group to <code class="language-plaintext highlighter-rouge">openldap</code> and file mode to <code class="language-plaintext highlighter-rouge">0644</code> (for the certificate) or <code class="language-plaintext highlighter-rouge">0400</code> (for the private key). This ensures only the OpenLDAP server can access them. Now you need to tell the server to <em>use</em> these files.</p>
			<div class="language-yaml highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="na">dn</span><span class="pi">:</span> <span class="s">cn=config</span>
<span class="na">changetype</span><span class="pi">:</span> <span class="s">modify</span>
<span class="na">add</span><span class="pi">:</span> <span class="s">olcTLSCertificateKeyFile</span>
<span class="na">olcTLSCertificateKeyFile</span><span class="pi">:</span> <span class="s">/etc/ldap/server.key</span>
<span class="pi">-</span>
<span class="na">add</span><span class="pi">:</span> <span class="s">olcTLSCertificateFile</span>
<span class="na">olcTLSCertificateFile</span><span class="pi">:</span> <span class="s">/etc/ldap/server.crt</span>
<span class="pi">-</span>
<span class="na">add</span><span class="pi">:</span> <span class="s">olcTLSCACertificateFile</span>
<span class="na">olcTLSCACertificateFile</span><span class="pi">:</span> <span class="s">/etc/ldap/server.crt</span>
</code></pre>
				</div>
			</div>
			<p>This time the LDAP “admin” user can’t import these changes. You need to log in to the server as <code class="language-plaintext highlighter-rouge">root</code>, then use the following command:</p>
			<div class="language-shell highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code>ldapmodify <span class="nt">-Y</span> EXTERNAL <span class="nt">-H</span> ldapi:/// <span class="nt">-f</span> ssl.ldif
</code></pre>
				</div>
			</div>
			<div class="notice--primary">
				<h4 id="external-authentication-method"><i class="fas fa-fw fa-lightbulb"></i> “External” authentication method</h4>
				<p>The “external” authentication method defers authentication to the transport layer. There are (at least) two kinds of supported methods: Unix domain socket option <code class="language-plaintext highlighter-rouge">SO_PEERCRED</code> (see <a href="https://man7.org/linux/man-pages/man7/unix.7.html">unix(7)</a>) and TLS client certificate. When connecting over UDS, the server can retrieve the client’s UID, GID and PID with that option.</p>
				<p>The <code class="language-plaintext highlighter-rouge">-H ldapi:///</code> tells the <code class="language-plaintext highlighter-rouge">ldap*</code> commands to connect over a local Unix domain socket, which is required for <code class="language-plaintext highlighter-rouge">-Y EXTERNAL</code> (we don’t have TLS client certificates yet).</p>
			</div>
			<div class="notice--danger">
				<h4 class="no_toc" id="order-is-important"><i class="fas fa-fw fa-exclamation-triangle"></i> Order is important</h4>
				<p>The OpenLDAP documentation did not cover the detail that the private key must be added <em>before</em> the certificate. Otherwise you’ll get this response:</p>
				<div class="language-text highlighter-rouge">
					<div class="highlight">
						<pre class="highlight"><code>ldap_modify: Other (e.g., implementation specific) error (80)
</code></pre>
					</div>
  </div>
				<p>References: <a href="https://askubuntu.com/a/1103245/612877">1</a>, <a href="https://gist.github.com/ndlrx/edef4474ec9f5edac594cc5e37644559">2</a>, <a href="https://serverfault.com/a/1007262/450575">3</a></p>
			</div>
			<p>After getting the certificates ready, we can now enable LDAP-over-TLS service. Somehow the Debian <code class="language-plaintext highlighter-rouge">slapd</code> package does not come with a native systemd service, but <code class="language-plaintext highlighter-rouge">/etc/init.d/slapd</code>, so “service settings” are configured at <code class="language-plaintext highlighter-rouge">/etc/default/slapd</code>. Locate that file and add <code class="language-plaintext highlighter-rouge">ldaps:///</code> for <code class="language-plaintext highlighter-rouge">SLAPD_SERVICES</code>. Optionally, though recommended, you can remove <code class="language-plaintext highlighter-rouge">ldap://</code> to disable the plaintext port. The line should now look like this:</p>
			<div class="language-shell highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="nv">SLAPD_SERVICES</span><span class="o">=</span><span class="s2">"ldaps:/// ldapi:///"</span>
</code></pre>
				</div>
			</div>
			<p>You can now use <code class="language-plaintext highlighter-rouge">systemctl restart slapd</code> to restart the server, and <code class="language-plaintext highlighter-rouge">netstat -tlpn</code> to verify that the server is listening on the correct port (TCP 636).</p>
			<h3 id="permissions">Managing permissions</h3>
			<p>By default,</p>
			<ul>
				<li>The “admin” user (using <code class="language-plaintext highlighter-rouge">-D cn=admin,dc=... -W</code>) can modify the “database”, where users, groups etc. are stored.</li>
				<li>The local root user can modify server settings. Namely, anything under the tree <code class="language-plaintext highlighter-rouge">cn=config</code>. Note that Distinguished Name (DN) resolves from right to left, like domain names.</li>
			</ul>
			<p>For me, I found it a hinderance that the root user cannot edit the database directly, so I added some permissions to make this happen.</p>
			<p>As you may have noticed, we used the same LDIF format to change TLS settings, except for the server port. In fact, the whole <code class="language-plaintext highlighter-rouge">cn=config</code> tree is another LDAP database, just like the <code class="language-plaintext highlighter-rouge">mysql</code> database in MySQL. And this “config” database also has its metadata under <code class="language-plaintext highlighter-rouge">cn=config</code>.</p>
			<p>First we identify where the metadata for the “config” database is:</p>
			<div class="language-shell highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code>ldapsearch <span class="nt">-Y</span> EXTERNAL <span class="nt">-b</span> <span class="nv">cn</span><span class="o">=</span>config
</code></pre>
				</div>
			</div>
			<p>You can pipe the above command to <code class="language-plaintext highlighter-rouge">less</code> or send to a file for easier inspection. Pay attention to lines beginning with <code class="language-plaintext highlighter-rouge">dn:</code>, which describes a directory “node”. One of them will look like:</p>
			<div class="language-yaml highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="na">dn</span><span class="pi">:</span> <span class="s">olcDatabase={1}mdb,cn=config</span>
</code></pre>
				</div>
			</div>
			<p>The <code class="language-plaintext highlighter-rouge">olc</code> prefix stands for <strong>O</strong>pen<strong>L</strong>DAP <strong>C</strong>onfiguration, and <code class="language-plaintext highlighter-rouge">{1}</code> indicates an entry from multiple of the same name. You’ll probably notice there’s <code class="language-plaintext highlighter-rouge">olcDatabase={0}config</code> as well, which we’ll cover soon.</p>
			<p>This item has a lot of attributes, among which there are:</p>
			<div class="language-yaml highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="na">dn</span><span class="pi">:</span> <span class="s">olcDatabase={1}mdb,cn=config</span>
<span class="na">objectClass</span><span class="pi">:</span> <span class="s">olcDatabaseConfig</span>
<span class="na">objectClass</span><span class="pi">:</span> <span class="s">olcMdbConfig</span>
<span class="na">olcDatabase</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">1</span><span class="pi">}</span><span class="s">mdb</span>
<span class="na">olcDbDirectory</span><span class="pi">:</span> <span class="s">/var/lib/ldap</span>
<span class="na">olcSuffix</span><span class="pi">:</span> <span class="s">dc=ibug</span>
<span class="na">olcAccess</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">0</span><span class="pi">}</span><span class="s">to attrs=userPassword by self write by anonymous auth by * none</span>
<span class="na">olcAccess</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">1</span><span class="pi">}</span><span class="s">to attrs=shadowLastChange by self write by * read</span>
<span class="na">olcAccess</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">2</span><span class="pi">}</span><span class="s">to * by * read</span>
<span class="na">olcRootDN</span><span class="pi">:</span> <span class="s">cn=admin,dc=ibug</span>
</code></pre>
				</div>
			</div>
			<p>The <code class="language-plaintext highlighter-rouge">olcAccess</code> key(s) describes its Access Control List (ACL), and apparently <code class="language-plaintext highlighter-rouge">{0}</code>, <code class="language-plaintext highlighter-rouge">{1}</code> and <code class="language-plaintext highlighter-rouge">{2}</code> have the same meaning as that of <code class="language-plaintext highlighter-rouge">olcDatabase={1}mdb</code>. The syntax is roughly as follows:</p>
			<div class="language-text highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code>olcAccess: {&lt;index&gt;}to &lt;what&gt; by &lt;who&gt; &lt;how&gt; [by &lt;who&gt; &lt;how&gt;]...
</code></pre>
				</div>
			</div>
			<p>Notice that there’s no explicit ACL to the “admin user”, because the admin user is registered as <code class="language-plaintext highlighter-rouge">olcRootDN</code> for this database. The next thing we need to do is to insert an all-access rule for the local root user. The next question is, how to “refer to” the root user?</p>
			<p>If you looked through <code class="language-plaintext highlighter-rouge">olcDatabase={0}config</code>, you should have the answer now:</p>
			<div class="language-yaml highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="na">dn</span><span class="pi">:</span> <span class="s">olcDatabase={0}config,cn=config</span>
<span class="nn">...</span>
<span class="na">olcAccess</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">0</span><span class="pi">}</span><span class="s">to * by dn.exact=gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth manage by * break</span>
<span class="nn">...</span>
</code></pre>
				</div>
			</div>
			<p>Unfortunately LDIF does not allow modifying or inserting an item into a repeated attribute directly, so the way to do this is to replace all of them:</p>
			<div class="language-yaml highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="na">dn</span><span class="pi">:</span> <span class="s">olcDatabase={1}mdb,cn=config</span>
<span class="na">changetype</span><span class="pi">:</span> <span class="s">modify</span>
<span class="na">replace</span><span class="pi">:</span> <span class="s">olcAccess</span>
<span class="na">olcAccess</span><span class="pi">:</span> <span class="s">to * by dn.exact=gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth manage by * break</span>
<span class="na">olcAccess</span><span class="pi">:</span> <span class="s">to attrs=userPassword by self write by anonymous auth by * none</span>
<span class="na">olcAccess</span><span class="pi">:</span> <span class="s">to attrs=shadowLastChange by self write by * read</span>
<span class="na">olcAccess</span><span class="pi">:</span> <span class="s">to * by * read</span>
</code></pre>
				</div>
			</div>
			<p>Seen how the <code class="language-plaintext highlighter-rouge">&lt;who&gt;</code> part is reminiscent of the “External authentication method” described above? Send this LDIF to the server and you’ll get the desired result. You can now try to modify the “user database” using root user and <code class="language-plaintext highlighter-rouge">-Y EXTERNAL</code>.</p>
			<p>For more detailed description, you can check out the <a href="https://www.openldap.org/doc/admin24/access-control.html">slapd.access</a> help page.</p>
			<h3 id="user-chsh">Allow users to change login shell</h3>
			<p>Changing the login shell is a basic privilege of a normal POSIX user. Unlike <code class="language-plaintext highlighter-rouge">passwd</code> that automatically handles LDAP users, <code class="language-plaintext highlighter-rouge">chsh</code> does not, and only complains about PAM authentication failed.</p>
			<p>It’s easy to discover that there’s a <code class="language-plaintext highlighter-rouge">chsh.ldap</code> command. It’s even easier to discover that it doesn’t work:</p>
			<div class="language-python highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="n">ibug</span><span class="o">@</span><span class="n">ldap</span><span class="p">:</span><span class="o">~</span><span class="err">$</span> <span class="n">chsh</span><span class="p">.</span><span class="n">ldap</span>
<span class="n">LDAP</span> <span class="n">password</span> <span class="k">for</span> <span class="n">ibug</span><span class="p">:</span>
<span class="n">Enter</span> <span class="n">the</span> <span class="n">new</span> <span class="n">value</span><span class="p">,</span> <span class="ow">or</span> <span class="n">press</span> <span class="n">ENTER</span> <span class="k">for</span> <span class="n">the</span> <span class="n">default</span>
<span class="n">Traceback</span> <span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">last</span><span class="p">):</span>
  <span class="n">File</span> <span class="s">"/usr/bin/chsh.ldap"</span><span class="p">,</span> <span class="n">line</span> <span class="mi">80</span><span class="p">,</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
    <span class="n">main</span><span class="p">()</span>
  <span class="n">File</span> <span class="s">"/usr/bin/chsh.ldap"</span><span class="p">,</span> <span class="n">line</span> <span class="mi">69</span><span class="p">,</span> <span class="ow">in</span> <span class="n">main</span>
    <span class="n">shell</span> <span class="o">=</span> <span class="n">ask_shell</span><span class="p">(</span><span class="n">user</span><span class="p">.</span><span class="n">shell</span><span class="p">)</span>
  <span class="n">File</span> <span class="s">"/usr/bin/chsh.ldap"</span><span class="p">,</span> <span class="n">line</span> <span class="mi">50</span><span class="p">,</span> <span class="ow">in</span> <span class="n">ask_shell</span>
    <span class="n">shell</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s">'  Login Shell [%s]: '</span> <span class="o">%</span> <span class="n">oldshell</span><span class="p">)</span>
<span class="nb">UnboundLocalError</span><span class="p">:</span> <span class="n">local</span> <span class="n">variable</span> <span class="s">'input'</span> <span class="n">referenced</span> <span class="n">before</span> <span class="n">assignment</span>
</code></pre>
				</div>
			</div>
			<p>If you look at <code class="language-plaintext highlighter-rouge">/usr/bin/chsh.ldap</code>, it contains this stupid assignment:</p>
			<div class="language-python highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="c1"># Provide Python 2 compatibility
</span><span class="k">try</span><span class="p">:</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="nb">raw_input</span>
<span class="k">except</span> <span class="nb">NameError</span><span class="p">:</span>
    <span class="k">pass</span>
</code></pre>
				</div>
			</div>
			<p>Removing this try-except block gets rid of the first error, but it’s still not working:</p>
			<div class="language-console highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="gp">ibug@ldap:~$</span><span class="w"> </span>chsh.ldap
<span class="go">LDAP password for ibug:
Enter the new value, or press ENTER for the default
  Login Shell [/bin/bash]:
/usr/bin/chsh.ldap: /bin/bash is an invalid shell
</span></code></pre>
				</div>
			</div>
			<p>The second one is trickier to fix because you don’t know where it’s doing wrong.</p>
			<p>It took me some effort to find bug report <a href="https://bugs.launchpad.net/ubuntu/+source/nss-pam-ldapd/+bug/1892482">LP#1892482</a>, which provides a link to <a href="https://github.com/arthurdejong/nss-pam-ldapd/commit/1025d5de336d8c9585b79df3154b5649da344281">this commit</a> that fixes the problem. You can safely apply that commit to your local installation of <code class="language-plaintext highlighter-rouge">/usr/share/nslcd-utils</code>.</p>
			<p>Now <code class="language-plaintext highlighter-rouge">chsh.ldap</code> seems to be working, <em>except</em> that it doesn’t save your selected shell.</p>
			<p>Remember how there’s an ACL to allow users to change their passwords?</p>
			<div class="language-yaml highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="na">olcAccess</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">0</span><span class="pi">}</span><span class="s">to attrs=userPassword by self write by anonymous auth by * none</span>
</code></pre>
				</div>
			</div>
			<p>That’s right, the only thing left to do is to add another ACL to allow users to change their login shells as well, replacing all <code class="language-plaintext highlighter-rouge">olcAccess</code> keys <em>again</em>:</p>
			<div class="language-yaml highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="na">dn</span><span class="pi">:</span> <span class="s">olcDatabase={1}mdb,cn=config</span>
<span class="na">changetype</span><span class="pi">:</span> <span class="s">modify</span>
<span class="na">replace</span><span class="pi">:</span> <span class="s">olcAccess</span>
<span class="na">olcAccess</span><span class="pi">:</span> <span class="s">to * by dn.exact=gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth manage by * break</span>
<span class="na">olcAccess</span><span class="pi">:</span> <span class="s">to attrs=userPassword by self write by anonymous auth by * none</span>
<span class="na">olcAccess</span><span class="pi">:</span> <span class="s">to attrs=loginShell by self write by * none</span>
<span class="na">olcAccess</span><span class="pi">:</span> <span class="s">to attrs=shadowLastChange by self write by * read</span>
<span class="na">olcAccess</span><span class="pi">:</span> <span class="s">to * by * read</span>
</code></pre>
				</div>
			</div>
			<p>This time there’s no need to include <code class="language-plaintext highlighter-rouge">by anonymous auth</code> because who checks the login shell for authentication?</p>
			<p>Now we can verify that <code class="language-plaintext highlighter-rouge">chsh.ldap</code> is working correctly:</p>
			<div class="language-console highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="gp">ibug@ldap:~$</span><span class="w"> </span>chsh.ldap
<span class="go">LDAP password for ibug:
Enter the new value, or press ENTER for the default
  Login Shell [/bin/bash]: /bin/zsh
</span><span class="gp">ibug@ldap:~$</span><span class="w"> </span>getent passwd | <span class="nb">grep </span>ibug
<span class="go">ibug:x:1000:1000:iBug:/home/ibug:/bin/zsh
</span><span class="gp">ibug@ldap:~$</span><span class="w">
</span></code></pre>
				</div>
			</div>
			<h2 id="afterword">Afterword</h2>
			<p>LDAP is a powerful tool to manage a wide range of things, including hosts (like <code class="language-plaintext highlighter-rouge">/etc/hosts</code>) and even Sudo rules, with increasing complexity to set up. There’s also Active Directory on Windows platform that shares the same concepts and is even inter-operable with LDAP.</p>
			<p>LDAP also supports plugins that enables automatic configuration of certain attributes, like “group membership”, where the plugin adds a corresponding <code class="language-plaintext highlighter-rouge">memberOf</code> for users when a <code class="language-plaintext highlighter-rouge">member</code> entry is created under a group. However, this plugin doesn’t work with the <code class="language-plaintext highlighter-rouge">posixGroup</code> object class and requires the conflicting <code class="language-plaintext highlighter-rouge">groupOfNames</code> object class. Fortunately, this does not affect the ability to lookup groups from users, since traditionally the user-group relationship is stored one-way only in <code class="language-plaintext highlighter-rouge">/etc/group</code>, and PAM by default tries to look it up this way.</p>
			<p>If you need access control, OpenSSH supports <a href="https://man7.org/linux/man-pages/man5/sshd_config.5.html">an <code class="language-plaintext highlighter-rouge">AllowGroup</code> directive</a> to restrict login to certain groups, which you can then remotely configure in LDAP.</p>
			<h2 id="references">References</h2>
			<ul>
				<li><a href="https://harrychen.xyz/2021/01/17/openldap-linux-auth/">使用 OpenLDAP 在 Linux 上进行中心化用户管理 - Harry Chen’s blog</a></li>
				<li><a href="https://access.redhat.com/documentation/en-us/red_hat_directory_server/11/html/administration_guide/managing_the_nss_database_used_by_directory_server">9.3. Managing the NSS Database Used by Directory Server</a> (Red Hat Documentation)</li>
				<li><a href="https://en.wikipedia.org/wiki/Bcrypt">Bcrypt - Wikipedia</a></li>
				<li><a href="https://hohnstaedt.de/xca/">XCA</a></li>
				<li>
					<p><a href="https://github.com/arthurdejong/nss-pam-ldapd/commit/1025d5de336d8c9585b79df3154b5649da344281">The commit</a> that fixes <code class="language-plaintext highlighter-rouge">chsh.ldap</code></p>
				</li>
			</ul>
			]]></content><author><name>iBug</name></author><category term="linux" /><category term="server" /><category term="ldap" /><summary type="html"><![CDATA[LDAP, the #1 way to get your graduation delayed (as has always been the meme around Tsinghua University), is every SysAdmin’s dream tool for their servers. As mighty as its rumors fly, LDAP takes the most serious dedication to set up and maintain, yet the slightest agitation to fail.]]></summary></entry><entry><title type="html">Install Proxmox VE on eMMC</title><link href="https://ibug.io/blog/2022/03/install-proxmox-ve-emmc/" rel="alternate" type="text/html" title="Install Proxmox VE on eMMC" /><published>2022-03-01T00:00:00+00:00</published><updated>2022-03-01T19:03:19+00:00</updated><id>https://ibug.io/blog/2022/03/install-proxmox-ve-emmc</id><content type="html" xml:base="https://ibug.io/blog/2022/03/install-proxmox-ve-emmc/"><![CDATA[<p>Recently I bought a mini PC looking forward to setting up a home router. It started quite well except the specs were higher than I anticipated. 8 GB RAM plus 128 GB eMMC - too much waste for “just a router”, so I figured I’d get some virtual machines to improve its utilization. Choosing the virtualization platform isn’t hard - I’m most familiar with Proxmox VE.</p>
		<p>The offcial ISO installer is pretty straightforward, until the last step:</p>
		<div class="language-text highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code>Unable to get device for partition 1 on device /dev/mmcblk0
</code></pre>
			</div>
		</div>
		<h2 id="solution">Solution</h2>
		<p>The Proxmox VE forum is <em>completely unhelpful</em> this time (<a href="https://forum.proxmox.com/threads/unable-to-get-device-for-partition-1-on-device-dev-mmcblk0.42348/">1</a>, <a href="https://forum.proxmox.com/threads/unable-to-get-device-for-partition-1.43234/">2</a>) with staff keeping on saying “it’s not supported”, so I had to look around for alternatives. Fortunately this article is right there:</p>
		<ul>
			<li><a href="https://lookas2001.com/%E8%A7%A3%E5%86%B3-proxmox-ve-%E6%97%A0%E6%B3%95%E5%AE%89%E8%A3%85%E5%88%B0-emmc-%E4%B8%8A%E7%9A%84%E9%97%AE%E9%A2%98/">解决 Proxmox VE 无法安装到 eMMC 上的问题 - lookas2001</a></li>
		</ul>
		<p>Turns out it’s hard-coded into Proxmox VE’s Perl installer script, so all you have to do is to patch it:</p>
		<ol>
			<li>Boot the installer ISO to the first menu, select the second option <code class="language-plaintext highlighter-rouge">Install Proxmox VE (Debug mode)</code></li>
			<li>The first time you’re present with a command-line prompt, type <code class="language-plaintext highlighter-rouge">exit</code> and Enter to skip it. This is a very early stage and you can’t do much here.</li>
			<li>The second time you have a shell, locate <code class="language-plaintext highlighter-rouge">/usr/bin/proxinstall</code> and open it. Text editors such as <code class="language-plaintext highlighter-rouge">vi</code> and <code class="language-plaintext highlighter-rouge">nano</code> are available.</li>
			<li>
				<p>Search for <code class="language-plaintext highlighter-rouge">unable to get device</code> and you should find some code like this:</p>
				<div class="language-perl highlighter-rouge">
					<div class="highlight">
						<pre class="highlight"><code> <span class="p">}</span> <span class="k">elsif</span> <span class="p">(</span><span class="nv">$dev</span> <span class="o">=~</span> <span class="sr">m|^/dev/[^/]+/hd[a-z]$|</span><span class="p">)</span> <span class="p">{</span>
     <span class="k">return</span> <span class="p">"</span><span class="si">${dev}$partnum</span><span class="p">";</span>
 <span class="p">}</span> <span class="k">elsif</span> <span class="p">(</span><span class="nv">$dev</span> <span class="o">=~</span> <span class="sr">m|^/dev/nvme\d+n\d+$|</span><span class="p">)</span> <span class="p">{</span>
     <span class="k">return</span> <span class="p">"</span><span class="si">${dev}</span><span class="s2">p</span><span class="si">$partnum</span><span class="p">";</span>
 <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
     <span class="nb">die</span> <span class="p">"</span><span class="s2">unable to get device for partition </span><span class="si">$partnum</span><span class="s2"> on device </span><span class="si">$dev</span><span class="se">\n</span><span class="p">";</span>
 <span class="p">}</span>
</code></pre>
					</div>
    </div>
				<p>The full code can be found <a href="https://github.com/proxmox/pve-installer/blob/b04864ece2654c6ecf794f9c3ad1cedede351532/proxinstall#L729">on GitHub</a> if you’d like.</p>
			</li>
			<li>
				<p>See how different kinds of storage devices are enumerated? Now add <code class="language-plaintext highlighter-rouge">/dev/mmcblk</code> to the list like this:</p>
				<div class="language-perl highlighter-rouge">
					<div class="highlight">
						<pre class="highlight"><code> <span class="p">}</span> <span class="k">elsif</span> <span class="p">(</span><span class="nv">$dev</span> <span class="o">=~</span> <span class="sr">m|^/dev/[^/]+/hd[a-z]$|</span><span class="p">)</span> <span class="p">{</span>
     <span class="k">return</span> <span class="p">"</span><span class="si">${dev}$partnum</span><span class="p">";</span>
 <span class="p">}</span> <span class="k">elsif</span> <span class="p">(</span><span class="nv">$dev</span> <span class="o">=~</span> <span class="sr">m|^/dev/nvme\d+n\d+$|</span><span class="p">)</span> <span class="p">{</span>
     <span class="k">return</span> <span class="p">"</span><span class="si">${dev}</span><span class="s2">p</span><span class="si">$partnum</span><span class="p">";</span>
 <span class="p">}</span> <span class="k">elsif</span> <span class="p">(</span><span class="nv">$dev</span> <span class="o">=~</span> <span class="sr">m|^/dev/mmcblk\d+$|</span><span class="p">)</span> <span class="p">{</span>
     <span class="k">return</span> <span class="p">"</span><span class="si">${dev}</span><span class="s2">p</span><span class="si">$partnum</span><span class="p">";</span>
 <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
     <span class="nb">die</span> <span class="p">"</span><span class="s2">unable to get device for partition </span><span class="si">$partnum</span><span class="s2"> on device </span><span class="si">$dev</span><span class="se">\n</span><span class="p">";</span>
 <span class="p">}</span>
</code></pre>
					</div>
    </div>
			</li>
			<li>Save your edits and type <code class="language-plaintext highlighter-rouge">exit</code>. Proceed with the installation as normal. Select <code class="language-plaintext highlighter-rouge">/dev/mmcblk0</code> (without the <code class="language-plaintext highlighter-rouge">bootX</code> suffix) as the install target. You may want to disable swap to avoid rapid wearing of the eMMC.</li>
			<li>The next time you have a shell, use <code class="language-plaintext highlighter-rouge">exit</code> to skip it. Nothing to do here.</li>
		</ol>
		<h2 id="rambling">Rambling</h2>
		<p>While it’s possible to install Proxmox VE on top of a matching version of Debian, it’s tedious to install Debian <em>just for PVE</em>. The last time I had to do it this way was on very old hardware that the PVE installer just crashed (X server died), and that the PVE installer didn’t have a CLI version. Plus a standard Debian installation typically comes with extra stuff that you don’t want on a PVE system (or want to get rid of ASAP).</p>
		<p>It’s also possible to modify the installer script beforehand, but you need to unpack <code class="language-plaintext highlighter-rouge">pve-installer.squashfs</code> and re-pack it into the ISO. You should think more seriously if you want to install PVE on a lot of eMMC devices.</p>
		]]></content><author><name>iBug</name></author><category term="linux" /><summary type="html"><![CDATA[Recently I bought a mini PC looking forward to setting up a home router. It started quite well except the specs were higher than I anticipated. 8 GB RAM plus 128 GB eMMC - too much waste for “just a router”, so I figured I’d get some virtual machines to improve its utilization. Choosing the virtualization platform isn’t hard - I’m most familiar with Proxmox VE.]]></summary></entry><entry><title type="html">New Pandora’s box: Install Linux and Windows onto the same NTFS partition</title><link href="https://ibug.io/blog/2021/11/linux-windows-amalgam-monster-ntfs/" rel="alternate" type="text/html" title="New Pandora’s box: Install Linux and Windows onto the same NTFS partition" /><published>2021-11-28T00:00:00+00:00</published><updated>2021-11-28T04:39:20+00:00</updated><id>https://ibug.io/blog/2021/11/linux-windows-amalgam-monster-ntfs</id><content type="html" xml:base="https://ibug.io/blog/2021/11/linux-windows-amalgam-monster-ntfs/"><![CDATA[<p>Linux 5.15 is shipped with a brand new driver for Microsoft’s classic NTFS filesystem, <a href="https://www.techrepublic.com/article/linux-kernel-5-15-is-now-available-and-it-has-something-special-for-ntfs-users/">NTFS3</a>. Unlike the decades-old open-source NTFS-3G project, which is based on FUSE and have always received criticism for breaking existing filesystems, NTFS3 is a new driver that is designed to be compatible with contemporary NTFS filesystems, while providing safer read/write operations. This makes it possible to install Linux onto NTFS (as is with most other filesystems), and opens up a whole new can of worms: run Linux alongside Windows, TOGETHER.</p>
	<div class="notice--danger">
		<h4 class="no_toc" id="warning"><i class="fas fa-exclamation-triangle"></i> WARNING</h4>
		<p>This is COMPLETELY EXPERIMENTAL. If you are not familiar with either Linux or Windows, <strong>do not try this</strong>.</p>
	</div>
	<p>Sounds WEIRD to me. I’m going to do this experiment on my Proxmox VE cluster.</p>
	<p><img src="/image/linux/monster/vm-create.png" alt="Create virtual machine" class="border" /></p>
	<h2 id="preparation">Preparation</h2>
	<h3 id="archiso">Archiso</h3>
	<p>At the time of writing this article, the latest Arch Linux ISO (2021.11.01) was shipped with Kernel <strong>5.14</strong>.15 - no new NTFS3 driver. I need to create one for myself or this won’t work.</p>
	<p><a href="https://wiki.archlinux.org/title/archiso">Archiso</a> is Arch’s official tool for creating custom ISO images. I’m not normally an Arch user, so I choose to install Arch first from an official ISO (20211101) before wiping it.</p>
	<p><img src="/image/linux/monster/install-arch-partition.png" alt="Partitioning in Arch ISO" /></p>
	<p>After this temporary system is set up, I just follow the Archiso guide and receive my own <code class="language-plaintext highlighter-rouge">archlinux-2021.11.22-x86_64.iso</code> with no trouble. It has Kernel <strong>5.15</strong>.4 packed.</p>
	<p>I copy the ISO onto the Proxmox VE host system, reboot the VM with this new ISO and wipe <code class="language-plaintext highlighter-rouge">/dev/sda2</code> to avoid (possible) further issues with the Windows installer. I also format <code class="language-plaintext highlighter-rouge">/dev/sda1</code> again to ensure I’m really starting over anew.</p>
	<h3 id="install-windows">Install Windows</h3>
	<p>Since NTFS is developed by Microsoft and for Windows, it seems reasonable to assume Windows is best suited for NTFS. So I’ll install Windows first lest it recognizes the filesystem created by <code class="language-plaintext highlighter-rouge">mkfs.ntfs</code> (from the old <code class="language-plaintext highlighter-rouge">ntfs-3g</code> package) as “foreign” and complains anyhow.</p>
	<p>The installation process of Windows 10 has always been as boring and mundane as it is, so I’m not going to be verbose here. Following the usual steps, except that the disk has already been partitioned, it’s easy to get Windows 10 up and ready.</p>
	<p><img src="/image/linux/monster/install-win10-oobe.png" alt="Windows 10 OOBE screen" /></p>
	<p>Proceeding through the out-of-box experience and I get to the desktop. There’s not many things of interest here, so I just shutdown the VM and take a snapshot.</p>
	<p>Now it’s time to get this compound monstrosity set up.</p>
	<h2 id="the-main-show">The Main Show</h2>
	<p>Swap the CD/DVD drive image for the newly created archiso and boot it up:</p>
	<p><img src="/image/linux/monster/install-archiso.png" alt="CD/DVD image selection" /></p>
	<p>With the proper Linux kernel equipped, I can now mount the NTFS partition create by Windows installer. It seems NTFS is sophisticated enough to even allow Unix filesystem attibutes, like file modes (permissions) and ownership, as well as “special file types” like symbolic links and named sockets (Unix domain sockets). This may hint that bootstrapping a Linux system should not be too problematic.</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>fdisk <span class="nt">-l</span> /dev/sda  <span class="c"># confirm partition layout</span>
mount <span class="nt">-t</span> ntfs3 /dev/sda2 /mnt
<span class="nb">mkdir</span> <span class="nt">-p</span> /mnt/boot/efi
mount /dev/sda1 /mnt/boot/efi
pacstrap /mnt base linux linux-firmware
</code></pre>
		</div>
	</div>
	<p>Indeed, <code class="language-plaintext highlighter-rouge">pacstrap</code> goes so smoothly that I almost forget it’s on a non-native filesystem. The only thing that makes me concerned is that <strong>there’s no <code class="language-plaintext highlighter-rouge">fsck</code> tool for NTFS</strong> (<em>file not found: <code class="language-plaintext highlighter-rouge">fsck.ntfs3</code></em> in console output).</p>
	<p><img src="/image/linux/monster/install-arch-pacstrap.png" alt="pacstrap output" /></p>
	<p>Now I can chroot into the system and set up the rest of the system.</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>genfstab <span class="nt">-U</span> /mnt <span class="o">&gt;&gt;</span> /mnt/etc/fstab
arch-chroot /mnt
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
vim /etc/locale.gen  <span class="c"># add en_US.UTF-8 UTF-8</span>
<span class="nb">echo </span>monster <span class="o">&gt;</span> /etc/hostname
passwd <span class="nt">-d</span> root
<span class="nb">exit</span>  <span class="c"># quit chroot environment, return to archiso</span>
</code></pre>
		</div>
	</div>
	<p>Fixing the bootloader is a bit different than usual, as Linux detects NTFS partitions as <code class="language-plaintext highlighter-rouge">ntfs</code>, not <code class="language-plaintext highlighter-rouge">ntfs3</code>. In case of auto mounting, Linux will try to mount with <code class="language-plaintext highlighter-rouge">-t ntfs</code>, which is not available (it’s provided by ntfs-3g). Fortunately, there’s a <code class="language-plaintext highlighter-rouge">rootfstype=</code> <a href="https://wiki.archlinux.org/title/kernel_parameters">kernel command-line parameter</a> to override the “filesystem type” parameter when mounting.</p>
	<p>Putting this into action:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>arch-chroot /mnt
<span class="c"># configure networking</span>
pacman <span class="nt">-Sy</span> grub efibootmgr
vim /etc/default/grub
<span class="c"># remove "quiet" from GRUB_CMDLINE_LINUX</span>
<span class="c"># set GRUB_CMDLINE_LINUX_DEFAULT="rootfstype=ntfs3"</span>
grub-install
grub-mkconfig <span class="nt">-o</span> /boot/grub/grub.cfg
</code></pre>
		</div>
	</div>
	<p><img src="/image/linux/monster/install-arch-grub.png" alt="Install GRUB for Arch Linux" /></p>
	<p>To make things a bit more interesting, I’m adding a desktop environment:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>pacman <span class="nt">-Sy</span> gnome
<span class="c"># select some items - not everything</span>
</code></pre>
		</div>
	</div>
	<p>And configure networking as well:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="nb">cd</span> /etc/systemd/network
vim ens18.network
<span class="nb">cd</span> ../system
<span class="nb">ln</span> <span class="nt">-s</span> /lib/systemd/system/systemd-networkd.service multi-user.target.wants/
</code></pre>
		</div>
	</div>
	<p>All set, let’s give it a try.</p>
	<h2 id="usage-experience">Usage experience</h2>
	<p>Arch Linux plays surprisingly well with the new NTFS3 filesystem driver.</p>
	<p><img src="/image/linux/monster/after-arch-neofetch.png" alt="System information in Arch Linux" /></p>
	<p>To keep things simple, I didn’t install too much software. During my testing, the only issue I encountered was that <code class="language-plaintext highlighter-rouge">ldconfig</code> never worked. It always aborts.</p>
	<p><img src="/image/linux/monster/arch-terminal-sigabrt.png" alt="ldconfig stops working" /></p>
	<p>A non-issue is that there’s no working <code class="language-plaintext highlighter-rouge">fsck</code> tool, and there’s a systemd service “Fsck at boot” that consequently fails. It’s not as useful so I just disabled it.</p>
	<p>The pioneer from r/archlinux said the system breaks after a few reboots, which didn’t happen to me. On the contrary, my Arch Linux was considerably resistant to Windows, and survived multiple Windows Updates, one Microsoft Update, and a few more. It even survived a CHKDSK despite a bunch of files being reported for “invalid filename” because <a href="https://stackoverflow.com/a/25477235/5958455">Windows dislikes colons in filenames</a> (not that NTFS doesn’t support).</p>
	<h2 id="thoughts">Thoughts</h2>
	<p>I must admit I’m amazed at how exquisitely NTFS is designed. It’s so mature that it hasn’t even been updated <a href="https://en.wikipedia.org/wiki/NTFS#Versions">since Windows XP</a>. One important part of NTFS is its Extended Attributes (EA) for files. Every NTFS filesystem contains a special file named <code class="language-plaintext highlighter-rouge">$MFT</code> located under its root directory. This is the metadata for all files, including file names, “normal attributes” and ACL, among which is the EA. Every file has an associated entry for EA, which can contain an arbitrary number of attributes (key-value pairs). In fact, the first generation of Windows Subsystem for Linux (WSL) stores Linux file modes and permissions <a href="https://docs.microsoft.com/en-us/windows/wsl/file-permissions">using custom EA keys</a>, which gets adapted by the new NTFS3 driver. Other EA keys are also used as needed, like <code class="language-plaintext highlighter-rouge">security.capability</code>, which is a 20-byte bitset. (Interestingly, EA was originally designed for compatibility with HPFS, which also has a similarly-extensible “Extended Attributes”.)</p>
	<p>The new NTFS3 driver is a delighting improvement to the Linux ecosystem. Complaints about the classic NTFS-3G driver <a href="https://superuser.com/q/613869/688600">have</a> <a href="https://www.reddit.com/r/linuxquestions/comments/73v5pi/why_is_ntfs_on_linux_so_slow/">always</a> <a href="https://askubuntu.com/q/187813/612877">been</a> <a href="https://unix.stackexchange.com/q/107978/211239">around</a>. Performance was one of the primary concerns because it not only is based on FUSE (Filesystem in USErspace), but also badly optimized. Use of FUSE means extra context switches when accessing files, which, paired with hard-coded 4 KiB read/write unit, delivers unusually slow access speeds.</p>
	<p>While the NTFS3 driver is a bit more optimized, concerns around compatibility are still encompassing. This is mainly because it’s still built on knowledge obtained from reverse engineering than technical documentation and standard. Fortunately, stability for NTFS-3G is already at a satisfactory level, and the new driver is thought to be more reliable than the old one.</p>
	<p>Besides, this is a perfect example of Linux’s inclusiveness. Years before the commencement of the new NTFS3 driver, <a href="https://github.com/CyanoHao/NTFS-as-rootfs">attempts were made</a> to run Linux on top of NTFS using NTFS-3G. This leads to an interesting question: Will Linux run on top of FAT32? Technical difficulties are more conspicuous and critical this time, like lack of support and extensibility for file modes and more. I’ll explore into this challenge and share my findings in a subsequent blog post. Stay tuned!</p>
	<h2 id="links--credits">Links &amp; Credits</h2>
	<ul>
		<li>Pioneer from r/archlinux: <a href="https://www.reddit.com/r/archlinux/comments/qwsftq/arch_linux_on_ntfs3/">Arch Linux on NTFS3!</a></li>
		<li>
			<p>Original idea by a GitHub user: <a href="https://gist.github.com/motorailgun/cc2c573f253d0893f429a165b5f851ee">Installing Windows and Linux into the same partition</a></p>
		</li>
	</ul>
	]]></content><author><name>iBug</name></author><category term="linux" /><category term="windows" /><summary type="html"><![CDATA[Linux 5.15 is shipped with a brand new driver for Microsoft’s classic NTFS filesystem, NTFS3. Unlike the decades-old open-source NTFS-3G project, which is based on FUSE and have always received criticism for breaking existing filesystems, NTFS3 is a new driver that is designed to be compatible with contemporary NTFS filesystems, while providing safer read/write operations. This makes it possible to install Linux onto NTFS (as is with most other filesystems), and opens up a whole new can of worms: run Linux alongside Windows, TOGETHER.]]></summary></entry><entry><title type="html">Reinstall Windows VPS into Linux with iPXE network boot</title><link href="https://ibug.io/blog/2021/11/convert-windows-vps-to-linux/" rel="alternate" type="text/html" title="Reinstall Windows VPS into Linux with iPXE network boot" /><published>2021-11-22T00:00:00+00:00</published><updated>2021-11-23T01:53:16+00:00</updated><id>https://ibug.io/blog/2021/11/convert-windows-vps-to-linux</id><content type="html" xml:base="https://ibug.io/blog/2021/11/convert-windows-vps-to-linux/"><![CDATA[<p>This November I found a discount from one of my favorite VPS providers, <a href="https://go.ibugone.com/vps-hk">NETfront</a>. They offered <strong>Linux VPS with 2 vCPUs and 2 GB RAM</strong> at HK$56/mo, and also <strong>Windows VPS with 4 vCPUs and 4 GB RAM</strong> at HK$49/mo. Looks strange, right? Why buy the crappy Linux VPS when you can have a better configuration with <em>less</em> money (if possible)?</p>
	<p class="notice--primary"><strong>Note</strong>: I knew this VPS provider ran <a href="https://www.proxmox.com/en/proxmox-ve">Proxmox VE</a> because I already had their VPSs. They’d give you a Proxmox VE noVNC console when you click “Console” to manage your VPS, from which you know they’re using QEMU/KVM as their virtualization platform. Direct access to QEMU screen is <em>awesome</em>!</p>
	<h2 id="get-vps">Get a VPS</h2>
	<p>First I head to the shopping cart to order a Windows VPS.</p>
	<p><img src="/image/linux/ipxe/vps-buy.png" alt="VPS SKU item" class="border" style="border-radius: 12px;" /></p>
	<p>Nice offer. It comes with unlimited traffic rate limited to 20 Mbps (BTW, it’s full duplex using Proxmox VE’s built-in “Rate Limit” feature for QEMU/KVM). I complete an order and get to create a VM for this service.</p>
	<p>Completely expected, only Windows images are available for choosing.</p>
	<p><img src="/image/linux/ipxe/vps-create.png" alt="VPS creation page" /></p>
	<p>That doesn’t matter, since I’m prepared to bypass the provided VM images and set it up on my own, so I picked <em>Disabled</em> for KVM OS Template. Hopefully it’ll speed up the VM creation process a bit, which, well, wouldn’t matter after all 😊.</p>
	<p>The next part involves a bit of patient waiting. The VM creation took quite a few minutes, perhaps to reserve that 128 GB of HDD? It would probably make sense to wipe the reserved area lest any previous data be left behind, which is a good practice in terms of security. Whatever, now the new VPS is ready, and I can see some basic information about it. I take down the IP address because later in iPXE environment I need to configure it as a static IP address.</p>
	<p><img src="/image/linux/ipxe/vps-status.png" alt="VPS ready" /></p>
	<p>Because I did not choose an OS template for the VPS, it must boot from network (which is true even if I <em>did</em> take a template).</p>
	<p><img src="/image/linux/ipxe/vps-boot-order.png" alt="Set boot order of VPS" style="border-radius: 6px;" /></p>
	<p>Now it’s time to start working!</p>
	<h2 id="network-booting-with-ipxe">Network booting with iPXE</h2>
	<p>iPXE is an open-source PXE (network boot) firmware, and is built into QEMU, ready for use.</p>
	<p>I open up the noVNC console and start the VPS. When I see “Press ESC for Boot Menu”, I go for it for the iPXE menu.</p>
	<p><img src="/image/linux/ipxe/ipxe-boot.png" alt="iPXE boot screen" /></p>
	<p>iPXE tries to configure network automatically using DHCP, but since the VPS environment does not have DHCP, I have to manually configure the network.</p>
	<p><img src="/image/linux/ipxe/ipxe-config.png" alt="iPXE configure IP address" /></p>
	<p>Now it’s time to load some boot source. <a href="https://netboot.xyz/docs/booting/ipxe">Netboot.xyz</a> is the first Google result for “publix pxe boot server”, so I’ll trust it for good.</p>
	<div class="notice--danger">
		<h4 class="no_toc" id="trap"><i class="fas fa-bug"></i> Trap</h4>
		<p>I previously got trapped following its <a href="https://netboot.xyz/docs/quick-start">quick start</a> guide. It didn’t boot for me and just dropped network connection mid-way. Turns out the <a href="https://netboot.xyz/docs/booting/ipxe"><em>Boot using iPXE</em></a> guide is the one I should follow.</p>
	</div>
	<p>According to <a href="https://netboot.xyz/docs/booting/ipxe">Netboot.xyz documentation</a>, the only command needed after network is up is <code class="language-plaintext highlighter-rouge">chain</code>. Noting that the iPXE firmware built into QEMU does not support HTTPS, I use plaintext HTTP instead. The final commands used in iPXE environment are here:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="nb">set </span>net0/ip 192.0.2.2           <span class="c"># Replace with your IP address</span>
<span class="nb">set </span>net0/netmask 255.255.255.0  <span class="c"># Replace as needed</span>
<span class="nb">set </span>net0/gateway 192.0.2.1      <span class="c"># Replace with your gateway address</span>
<span class="nb">set </span>dns 8.8.8.8
ifopen net0
chain <span class="nt">--autofree</span> http://boot.netboot.xyz
</code></pre>
		</div>
	</div>
	<p>Within a few seconds, I see the OS selection screen.</p>
	<p><img src="/image/linux/ipxe/ipxe-netboot.xyz.png" alt="Loaded Netboot.xyz from iPXE" /></p>
	<p>Debian has always been my #1 choice for servers, no reason to miss it. Select Linux Network Installs and look for Debian Bullseye.</p>
	<p><img src="/image/linux/ipxe/ipxe-install-debian.png" alt="Debian network installer" /></p>
	<p>Now I’m halfway to success as Debian installer shows up. There’s still a small note: the Debian installer doesn’t “inherit” network settings from the iPXE firmware, so it must be configured again for Debian. The auto configuration attempt will fail and Debian will prompt for manual configuration. Not any difficult.</p>
	<p><img src="/image/linux/ipxe/ipxe-install-debian-network.png" alt="Configure network for Debian installer" /></p>
	<p>Now it’s time to wipe Windows (where’s Windows?) and install Linux!</p>
	<p><img src="/image/linux/ipxe/ipxe-install-debian-disk.png" alt="Configure disk partitions for Debian" /></p>
	<p>Select <code class="language-plaintext highlighter-rouge">deb.debian.org</code> as package source since this is a Hong Kong VPS and not a mainland China one, and proceed through the rest of the process. After a reboot, I can see the login screen of the newly installed OS. Hooray!</p>
	<p><img src="/image/linux/ipxe/debian-ok.png" alt="Debian ready" /></p>
	<p>If I replace <code class="language-plaintext highlighter-rouge">linux-image-amd64</code> with <code class="language-plaintext highlighter-rouge">linux-image-cloud-amd64</code>, I can free up some 100 MB disk space than the default setup:</p>
	<p><img src="/image/linux/ipxe/debian-df.png" alt="Debian DF" /></p>
	<p>That’s it. With just some small efforts, this is now an afforable, high-spec Linux VPS.</p>
	<p>While the VPS control panel would never offer Linux templates should anything go wrong, it’s always possible to boot from iPXE again for a “rescue environment”.</p>
	<h2 id="easter-egg">Easter Egg</h2>
	<p>During Debian installation, the installer automatically added the <code class="language-plaintext highlighter-rouge">hyperv-daemon</code> package after examining hardware. After booting into Debian, <code class="language-plaintext highlighter-rouge">systemd-detect-virt</code> reports “microsoft” (i.e. Windows Hyper-V). This VPS hosting provider may have some black magic with their Windows VPS cluster so that QEMU/KVM behaves so. This issue doesn’t seem to exist in their “native” Linux VPS, but it’s worth noting.</p>
	]]></content><author><name>iBug</name></author><category term="linux" /><category term="networking" /><summary type="html"><![CDATA[This November I found a discount from one of my favorite VPS providers, NETfront. They offered Linux VPS with 2 vCPUs and 2 GB RAM at HK$56/mo, and also Windows VPS with 4 vCPUs and 4 GB RAM at HK$49/mo. Looks strange, right? Why buy the crappy Linux VPS when you can have a better configuration with less money (if possible)?]]></summary></entry><entry><title type="html">Secure site-to-site connection with Linux IPsec VPN</title><link href="https://ibug.io/blog/2021/10/linux-ipsec-with-ip-xfrm/" rel="alternate" type="text/html" title="Secure site-to-site connection with Linux IPsec VPN" /><published>2021-10-23T00:00:00+00:00</published><updated>2021-10-24T00:43:55+00:00</updated><id>https://ibug.io/blog/2021/10/linux-ipsec-with-ip-xfrm</id><content type="html" xml:base="https://ibug.io/blog/2021/10/linux-ipsec-with-ip-xfrm/"><![CDATA[<p>Linux has a built-in framework for Internet Protocol Security (IPsec), which is often combined with other tunneling technologies (e.g. <a href="https://en.wikipedia.org/wiki/Layer_2_Tunneling_Protocol">L2TP</a> and <a href="https://en.wikipedia.org/wiki/Generic_Routing_Encapsulation">GRE</a>) to create secure cross-site network connections. As an innovative attempt to a lab in this semester’s Network Security course, which was designed to work over multiple Windows Server 2003 virtual machines (VM), I decided to go on my own and proceed with Linux VMs.</p>
	<p>As covered in <a href="/blog/2021/01/linux-container-explained/#namespaces">my previous blog</a>, one of the fundamentals of a Linux container is namespaces, among which the network namespace is of great interest here. Since a network namespace creates a copy of the entire network stack, it’s suitable as a substitute for a full VM for this lab. This enables me to work on this lab with lightweight containers on my Proxmox VE cluster.</p>
	<h2 id="setting-up-network">Setting up network</h2>
	<p>The lab is designed to work on VirtualBox platform, and the network structure is laid out as follows:</p>
	<p><img src="/image/linux/ipsec/network-structure-vbox.png" alt="VirtualBox network structure" /></p>
	<p>As <a href="https://pve.proxmox.com/wiki/Network_Configuration#_naming_conventions">Proxmox VE requires</a> bridges to be named as <code class="language-plaintext highlighter-rouge">vmbr#</code> where <code class="language-plaintext highlighter-rouge">#</code> is a number, I renamed the networks as follows:</p>
	<p><img src="/image/linux/ipsec/network-structure-pve.png" alt="Proxmox VE network structure" /></p>
	<p>To create the networks, I edit <code class="language-plaintext highlighter-rouge">/etc/network/interfaces</code> to append these lines:</p>
	<div class="language-plaintext highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>auto vmbr91
iface vmbr91 inet manual
    bridge_ports none
    bridge_stp off
    bridge_fd 0

auto vmbr92
iface vmbr92 inet manual
    bridge_ports none
    bridge_stp off
    bridge_fd 0

auto vmbr95
iface vmbr95 inet manual
    bridge_ports none
    bridge_stp off
    bridge_fd 0

auto vmbr96
iface vmbr96 inet manual
    bridge_ports none
    bridge_stp off
    bridge_fd 0
</code></pre>
		</div>
	</div>
	<p>The <code class="language-plaintext highlighter-rouge">bridge_stp</code> and <code class="language-plaintext highlighter-rouge">bridge_fd</code> options turns off <a href="https://en.wikipedia.org/wiki/Spanning_Tree_Protocol">STP</a>, which is <a href="https://wiki.debian.org/BridgeNetworkConnections#Configuring_bridging_in_.2Fetc.2Fnetwork.2Finterfaces">usually a better choice</a> in a virtualized environment.</p>
	<p>I then bring up the new bridges so VMs can later be attached to:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>ifup vmbr91 vmbr92 vmbr95 vmbr96
</code></pre>
		</div>
	</div>
	<p>Now it’s time to set up the VMs.</p>
	<h2 id="setting-up-containers">Setting up containers</h2>
	<p>As explained above, container is an excellent replacement for full-fledged virtual machines for this lab, so I create containers using the Proxmox VE web interface.</p>
	<p><img src="/image/linux/ipsec/create-ct.png" alt="Create CT" /></p>
	<p>It’s also helpful to make a plan for the container IDs first, since I will heavily utilize <code class="language-plaintext highlighter-rouge">pct enter</code> to get into the container. The web console won’t work with some shortcut keys, notably <kbd>Ctrl</kbd>+<kbd>W</kbd> and <kbd>Ctrl</kbd>+<kbd>T</kbd>.</p>
	<table>
		<thead>
			<tr>
				<th>Container (Name)</th>
				<th>ID</th>
				<th>Network</th>
				<th>IP Address</th>
			</tr>
		</thead>
		<tbody>
			<tr>
				<td>Router</td>
				<td>980</td>
				<td>vmbr95<br />
					vmbr96</td>
				<td>10.55.55.55/24<br />
					10.66.66.66/24</td>
			</tr>
			<tr>
				<td>Server A</td>
				<td>981</td>
				<td>vmbr91<br />
					vmbr95</td>
				<td>192.168.1.1/24<br />
					10.55.55.1/24<br />
					Gateway 10.55.55.55</td>
			</tr>
			<tr>
				<td>Server B</td>
				<td>982</td>
				<td>vmbr92<br />
					vmbr96</td>
				<td>192.168.2.1/24<br />
					10.66.66.1/24<br />
					Gateway 10.66.66.66</td>
			</tr>
			<tr>
				<td>Client A</td>
				<td>983</td>
				<td>vmbr91</td>
				<td>192.168.1.2<br />
					Gateway 192.168.1.1</td>
			</tr>
			<tr>
				<td>Client B</td>
				<td>984</td>
				<td>vmbr92</td>
				<td>192.168.2.2<br />
					Gateway 192.168.2.1</td>
			</tr>
		</tbody>
	</table>
	<p>Also I’m more comfortable with newer software, so I go with the Debian 11 template provided by Proxmox.</p>
	<p><img src="/image/linux/ipsec/create-ct-template.png" alt="Select template" /></p>
	<p>The rest of the settings aren’t of much interest, and the default settings should suffice. On a side note, 2 GB is more than abundant for Root Disk because I need virtually no extra software to work on this lab.</p>
	<p><img src="/image/linux/ipsec/create-ct-confirm.png" alt="CT configuration" /></p>
	<p>Don’t start the container right now, because there’s another network interface to be added. I head to the page to add <code class="language-plaintext highlighter-rouge">eth6</code> for the router, connecting to <code class="language-plaintext highlighter-rouge">vmbr96</code> as illustrated in the graph.</p>
	<p><img src="/image/linux/ipsec/router-add-network.png" alt="Add network interface to Router" /></p>
	<p>To save some time, I created the remaining containers using <code class="language-plaintext highlighter-rouge">pct</code> command. The command for creating CT 981 is as follows and the others are similar (omitted for brevity).</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>pct create 981 nfs-template:vztmpl/debian-11-standard_11.0-1_amd64.tar.gz <span class="se">\</span>
  <span class="nt">--rootfs</span> local-lvm:2 <span class="se">\</span>
  <span class="nt">--hostname</span> ibug-ServerA <span class="se">\</span>
  <span class="nt">--net0</span> <span class="nv">name</span><span class="o">=</span>eth1,bridge<span class="o">=</span>vmbr91,firewall<span class="o">=</span>0,ip<span class="o">=</span>192.168.1.1/24 <span class="se">\</span>
  <span class="nt">--net1</span> <span class="nv">name</span><span class="o">=</span>eth5,bridge<span class="o">=</span>vmbr95,firewall<span class="o">=</span>0,ip<span class="o">=</span>10.55.55.1/24,gw<span class="o">=</span>10.55.55.55 <span class="se">\</span>
  <span class="nt">--unprivileged</span> 1
</code></pre>
		</div>
	</div>
	<p>Now that the containers have been created, it’s time to get some extra software ready for the lab.</p>
	<p><img src="/image/linux/ipsec/cts.png" alt="Containers ready" /></p>
	<h3 id="configure-containers">Configure containers</h3>
	<p>The lab originally requires capturing traffic with Wireshark on Windows Server, but on Linux it’s more typical to do this with <code class="language-plaintext highlighter-rouge">tcpdump</code>, which needs to be installed on the Router. Additionally to make working and debugging easier, <code class="language-plaintext highlighter-rouge">tcpdump</code> and a text editor of your choice should also go on <strong>the Router and the two Servers</strong>. So I install Vim and <code class="language-plaintext highlighter-rouge">tcpdump</code> on all three containers mentioned. No extra software is needed for the two Clients.</p>
	<p>You may find it easier to temporarily change the network setting to allow the container to connect to the APT repository, install the software and then change it back.</p>
	<p>But for me I’d rather “just do it”, so I connect the Router container to the external network and run <code class="language-plaintext highlighter-rouge">apt install</code> as needed.</p>
	<p><img src="/image/linux/ipsec/install-software.png" alt="Install software on Router" /></p>
	<p>And then I configure the router to perform NAT for other containers to reach the outer world, so that I can do <code class="language-plaintext highlighter-rouge">apt install</code> directly (<code class="language-plaintext highlighter-rouge">iptables</code> lines). It’s also helpful to configure the routing table so the Clients can reach each other easily (<code class="language-plaintext highlighter-rouge">ip route</code> lines).</p>
	<p><img src="/image/linux/ipsec/setup-nat.png" alt="Configure firewall and routing" /></p>
	<p>I also need to enable IP forwarding on the Router and both Servers.</p>
	<p><img src="/image/linux/ipsec/enable-ip-forward.png" alt="Enable IP forwarding" /></p>
	<p>I can now see that Client A can reach Client B correctly. If I do packet capturing on the Router or either Server, I can see plaintext traffic going through.</p>
	<p><img src="/image/linux/ipsec/tcpdump-plain.png" alt="tcpdump plain traffic" /></p>
	<p>If you can reach here, it means your lab environment is now ready as I do.</p>
	<h2 id="ipsec-rules">IPsec rules</h2>
	<p>Linux provides native support for IPsec via the XFRM framework, and the (primitive) tool to manage it is the <code class="language-plaintext highlighter-rouge">ip xfrm</code> command. The XFRM framework matches packets with <strong>policies</strong> (as <strong>Security Policies, SP</strong>) and transforms (hence the name) packets with <strong>states</strong> (as <strong>Security Associations, SA</strong>). SP and SA are managed through two subcommands, <code class="language-plaintext highlighter-rouge">ip xfrm policy</code> and <code class="language-plaintext highlighter-rouge">ip xfrm state</code>, and there’s one last subcommand <code class="language-plaintext highlighter-rouge">ip xfrm monitor</code> that may come in handy from time to time.</p>
	<h3 id="ip-xfrm-command">ip-xfrm command</h3>
	<p>The syntax for <code class="language-plaintext highlighter-rouge">ip xfrm policy</code> is as follows. Only <code class="language-plaintext highlighter-rouge">add</code> and <code class="language-plaintext highlighter-rouge">delete</code> are given because we’re not interested in others. The full syntax can always be seen via <code class="language-plaintext highlighter-rouge">ip xfrm policy help </code> and <a href="https://man7.org/linux/man-pages/man8/ip-xfrm.8.html">the man page</a>.</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>ip xfrm policy add SELECTOR <span class="nb">dir </span>DIR tmpl TMPL <span class="o">[</span> tmpl TMPL <span class="o">]</span>...
ip xfrm policy delete SELECTOR <span class="nb">dir </span>DIR
ip xfrm policy flush  <span class="c"># deletes everything</span>

SELECTOR :<span class="o">=</span> <span class="o">[</span> src IP/CIDR <span class="o">]</span> <span class="o">[</span> dst IP/CIDR <span class="o">]</span> <span class="o">[</span> dev DEV <span class="o">]</span> <span class="o">[</span> UPSPEC <span class="o">]</span>
DIR :<span class="o">=</span> <span class="k">in</span> | out | fwd
TMPL :<span class="o">=</span> <span class="o">[</span> src IP <span class="o">]</span> <span class="o">[</span> dst IP <span class="o">]</span> <span class="o">[</span> proto PROTO <span class="o">]</span>
        <span class="o">[</span> spi SPI <span class="o">]</span> <span class="o">[</span> mode MODE <span class="o">]</span> <span class="o">[</span> reqid REQID <span class="o">]</span>
MODE :<span class="o">=</span> transport | tunnel
</code></pre>
		</div>
	</div>
	<p>The syntax for <code class="language-plaintext highlighter-rouge">ip xfrm state</code> is as follows. Similarly, <code class="language-plaintext highlighter-rouge">ip xfrm state help</code> gives the full syntax.</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>ip xfrm state add TMPL ALGO <span class="o">[</span> ALGO <span class="o">]</span>...
ip xfrm state delete TMPL
ip xfrm state flush  <span class="c"># deletes everything</span>

ALGO :<span class="o">=</span> <span class="o">{</span> enc | auth <span class="o">}</span> ALGO-NAME ALGO-KEY |
        aead ALGO-NAME ALGO-KEY ALGO-ICV-LEN
</code></pre>
		</div>
	</div>
	<h4 id="one-important-note">One important note</h4>
	<p>Among all the elements there’s one I’d like to specifically note: the direction <code class="language-plaintext highlighter-rouge">dir</code> isn’t quite the same as <code class="language-plaintext highlighter-rouge">INPUT</code> / <code class="language-plaintext highlighter-rouge">OUTPUT</code> / <code class="language-plaintext highlighter-rouge">FORWARD</code> as in the iptables firewall. Instead it carries the following meaning (<a href="https://serverfault.com/a/1048382/450575">source</a>):</p>
	<table>
		<thead>
			<tr>
				<th>Security Policy</th>
				<th>Meaning</th>
			</tr>
		</thead>
		<tbody>
			<tr>
				<td>Output policy (dir out)</td>
				<td>SP works as a selector on <strong>outgoing packets</strong> to select which are to be encrypted+encapsulated (analogous to firewall <code class="language-plaintext highlighter-rouge">POSTROUTING</code> chain)</td>
			</tr>
			<tr>
				<td>Input policy (dir in)</td>
				<td>SP works as a selector on <strong>incoming packets which already have been decrypted+decapsulated</strong> and have a destination IP local to the system (analogous to firewall <code class="language-plaintext highlighter-rouge">INPUT</code> chain)</td>
			</tr>
			<tr>
				<td>Forward policy (dir fwd)</td>
				<td>SP works as a selector on <strong>incoming packets which already have been decrypted+decapsulated</strong> and have a destination IP not local to the system (analogous to firewall <code class="language-plaintext highlighter-rouge">FORWARD</code> chain)</td>
			</tr>
		</tbody>
	</table>
	<p>So the direction works like this:</p>
	<ul>
		<li>The <code class="language-plaintext highlighter-rouge">dir out</code> is for encryption policies</li>
		<li>The <code class="language-plaintext highlighter-rouge">dir in</code> and <code class="language-plaintext highlighter-rouge">dir fwd</code> is to select and filter encrypted packets</li>
	</ul>
	<p>The curious may now ask: Where are the decryption policies?</p>
	<p>The answer is: The Security Associations! (Surprise!)</p>
	<p>Incoming IPsec packets (ESP, AH etc.) that match a SA will <em>always</em> be decrypted, regardless of configured SPs (so SA is analogous to the firewall <code class="language-plaintext highlighter-rouge">PREROUTING</code> chain). <strong>However</strong>, if the decrypted packet (or plain traffic) does not match a valid SP, it’s silently dropped and no further processing in the Linux network stack is done.</p>
	<p>I got trapped in this part for an hour in my initial experiments because it’s just too intuitive to misunderstand how <code class="language-plaintext highlighter-rouge">dir</code> works. And that’s why I’m taking a special note on this.</p>
	<h3 id="configure-ipsec-rules">Configure IPsec rules</h3>
	<p>Because I want to enable the Clients to connect to each other via the Servers, I configure <strong>an output policy and a forwarding policy</strong> on both Servers (with the opposite directions, of course).</p>
	<p>I add the Security Associations on Server A with the following commands. Note that it’s often better to generate the keys randomly than using a easily guessable value.</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="nv">SPI</span><span class="o">=</span>0x69427567
<span class="nv">AUTHKEY</span><span class="o">=</span>0x0123456789ABCDEF0123456789ABCDEF
<span class="nv">ENCKEY</span><span class="o">=</span>0xFEDCBA9876543210FEDCBA9876543210

ip xfrm state add <span class="se">\</span>
  src 10.55.55.1 dst 10.66.66.1 proto esp spi <span class="nv">$SPI</span> mode tunnel <span class="se">\</span>
  auth sha256 <span class="nv">$AUTHKEY</span> enc aes <span class="nv">$ENCKEY</span>
ip xfrm state add <span class="se">\</span>
  src 10.66.66.1 dst 10.55.55.1 proto esp spi <span class="nv">$SPI</span> mode tunnel <span class="se">\</span>
  auth sha256 <span class="nv">$AUTHKEY</span> enc aes <span class="nv">$ENCKEY</span>
</code></pre>
		</div>
	</div>
	<p>As the encrypted packets will be transported through the virtual “public Internet”, the source and destination addresses must be those of the public interfaces on the Servers.</p>
	<p>You can of course use different Security Parameter Indices and keys for both directions, but I choose the same parameters for simplicity.</p>
	<p>I then add the Security Policies on Server A with the following commands:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>ip xfrm policy add <span class="se">\</span>
  src 192.168.1.0/24 dst 192.168.2.0/24 <span class="nb">dir </span>out <span class="se">\</span>
  tmpl src 10.55.55.1 dst 10.66.66.1 proto esp spi <span class="nv">$SPI</span> mode tunnel
ip xfrm policy add <span class="se">\</span>
  src 192.168.2.0/24 dst 192.168.1.0/24 <span class="nb">dir </span>fwd <span class="se">\</span>
  tmpl src 10.66.66.1 dst 10.55.55.1 proto esp spi <span class="nv">$SPI</span> mode tunnel
</code></pre>
		</div>
	</div>
	<p>I also add the Security Associations on Server B with the same Security Parameter Index, Authentication Key and Encryption Key. The commands are identical to those run on Server A.</p>
	<p>The Security Policies require minimal changes: <code class="language-plaintext highlighter-rouge">dir out</code> and <code class="language-plaintext highlighter-rouge">dir fwd</code> should be swapped on Server B. The <code class="language-plaintext highlighter-rouge">ip xfrm policy add</code> commands are otherwise identical.</p>
	<p>Now I enter Client A to see if Client B is still reachable:</p>
	<p><img src="/image/linux/ipsec/ping-with-ipsec.png" alt="Client A still reaches Client B" /></p>
	<p>However, <code class="language-plaintext highlighter-rouge">tcpdump</code> on the Router shows Encrypted Security Payload instead of any plain traffic:</p>
	<p><img src="/image/linux/ipsec/tcpdump-esp.png" alt="tcpdump showing ESP packets" /></p>
	<p>The packet capturing shows that traffic between Server A and Server B is correctly encrypted with IPsec, so that communication between the two “sites” are now secured (except the key is weak).</p>
	<h2 id="inspecting-traffic-with-wireshark">Inspecting traffic with Wireshark</h2>
	<p>In fact, <code class="language-plaintext highlighter-rouge">tcpdump</code> supports dumping captured packets to file in Pcap format, which is a universal format also supported by the popular GUI software Wireshark.</p>
	<p>To start over again with a “clean” IPsec tunnel, I reset the Security Policies and Security Associations with</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>ip xfrm policy flush
ip xfrm state flush
</code></pre>
		</div>
	</div>
	<p>And then I reapply all Policies and Associations with the commands shown in the previous section.</p>
	<p>I start capturing packets to file with <code class="language-plaintext highlighter-rouge">tcpdump</code>:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>tcpdump <span class="nt">-ni</span> eth5 <span class="nt">-w</span> a.pcap ip and not arp
</code></pre>
		</div>
	</div>
	<p>I add filter expression to reduce noise (get rid of ARP and IPv6 NDP stuff), and again I send some traffic from Client A to Client B. I capture 10 packets here, which is enough for illustration purposes.</p>
	<p>I take the Pcap file from the container to my (Windows) computer, and open it with Wireshark:</p>
	<p><img src="/image/linux/ipsec/wireshark-no-decryption.png" alt="Pcap file in Wireshark" /></p>
	<p>The captured packets are correct - they’re encrypted in ESP format.</p>
	<p>I then head to <strong>Edit → Preferences</strong>, locate <strong>Protocol » ESP</strong> on the left, and add the Security Associations used in this experiment. I also tick the “<em>Attempt to detect/decode ecnrypted ESP payloads</em>” checkbox.</p>
	<p><img src="/image/linux/ipsec/wireshark-import-esp-sa.png" alt="Add ESP SA in Wireshark" /></p>
	<p>Now I go back to the main screen, and I can see that Wireshark decrypts the ESP payload using the SAs I just supplied. The inner packet data is revealed to be ICMP packets because I use Ping to perform the reachability test all the way.</p>
	<p><img src="/image/linux/ipsec/wireshard-decrypted.png" alt="Wireshark showing decrypted ESP data" /></p>
	<p>Wireshark also highlights all packets because they are identified to belong to the same “connection” (ICMP session).</p>
	<p>If you’re wondering, the decrypted payload content (shown in the “Decrypted Data” tab at the bottom) is a complete IPv4 packet, plus ESP metadata like authentication information and a “Next Header” value. The Next Header is the same as the “Protocol” field in an ordinary IPv4 packet. For an IPv4 packet encapsulated, the Next Header value is 4, which is the same value as “IP-in-IP tunnel”. For carried IPv6 traffic, the Next Header value is 41, the value for “IP6-in-IP tunnel” (or Simple Internet Transition, SIT).</p>
	<h3 id="easter-egg">Easter egg</h3>
	<p>Before loading SAs into Wireshark, I noticed it showing an interesting note for every other packet:</p>
	<p><img src="/image/linux/ipsec/wireshark-expected-sn.png" alt="Wireshark suggesting alternative sequence number" /></p>
	<p>This is because Wireshark is identifying streams by SPI, which is normally different for every IPsec stream, including both directions between the same pair of tunnel endpoints. When I’m using the same SPI for both directions, Wireshark gets confused and mistakes them for one stream, and suggests incrementing sequence numbers for “repeated” packets.</p>
	<h2 id="bonus-ipsec-tunnel-mode-vs-ip-in-ip-tunneling-inside-ipsec-transport-mode">Bonus: IPsec tunnel mode vs. IP-in-IP tunneling inside IPsec transport mode</h2>
	<p class="notice--primary">Big shoutout to my friend <a href="https://github.com/RTXUX">@RTXUX</a> who originally came up with this idea!</p>
	<p>Notice how Wireshark shows the “decrypted data” as a complete IP packet, and that the “Next Header” field in the outer ESP packet is 4 (<a href="https://en.wikipedia.org/wiki/IP_in_IP">IP-in-IP tunneling protocol</a>):</p>
	<p><img src="/image/linux/ipsec/bonus-wireshark-decrypted-data.png" alt="Wireshark decrypted payload" /></p>
	<p>Recalling the differences between IPsec transport mode and tunnel mode as taught in class or covered by <a href="https://docs.oracle.com/cd/E36784_01/html/E36838/ipsecov-13.html">Oracle’s documentation</a>:</p>
	<blockquote>
		<ul>
			<li>In transport mode, the IP addresses in the outer header are used to determine the IPsec policy that will be applied to the packet.</li>
			<li>In tunnel mode, two IP headers are sent. The inner IP packet determines the IPsec policy that protects its contents.</li>
		</ul>
	</blockquote>
	<p>It’s reasonable to wonder if the tunnel mode is equivalent to the transport mode with an identical IP-in-IP tunnel inside. This wouldn’t sound too silly because with an IP-based tunneling protocol like IP-in-IP or GRE, we’re literally wrapping up the inner payload and using the tunneling protocol as a means of transport (at Transport Layer), and the Transport Layer is exactly what’s carried in an IPsec transport mode packet. The only way to find this out is with practice.</p>
	<p>To test if they’re compatible, continuing from the end state of the course lab, I reset all Security Policies and Security Associations on Server A while leaving Server B intact.</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="c"># on Server A</span>
ip xfrm policy flush
ip xfrm state flush
</code></pre>
		</div>
	</div>
	<p>The test setup would be an IP-in-IP tunnel as it has the same protocol number (4) as the ESP payload, so I create one on Server A first.</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>ip tunnel add ipip0 mode ipip <span class="nb">local </span>10.55.55.1 remote 10.66.66.1 ttl 64
ip <span class="nb">link set </span>ipip0 up
</code></pre>
		</div>
	</div>
	<p>I also need to setup routing, since I don’t have IPsec policies to wrap it up for me. (Note: You can add a network address to this tunnel interface, but it’s not necessary.)</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>ip route add 192.168.2.0/24 dev ipip0
</code></pre>
		</div>
	</div>
	<p>Then I wrap it up with the same IPsec policies, except that the mode has been switched to “transport” and there’s no longer a “forward” direction, since the transported packets are IP-in-IP packets with the two servers being the source and the destination:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>ip xfrm policy add <span class="se">\</span>
  src 10.55.55.1 dst 10.66.66.1 <span class="nb">dir </span>out <span class="se">\</span>
  tmpl src 10.55.55.1 dst 10.66.66.1 proto esp spi <span class="nv">$SPI</span> mode transport
ip xfrm policy add <span class="se">\</span>
  src 10.66.66.1 dst 10.55.55.1 <span class="nb">dir </span><span class="k">in</span> <span class="se">\</span>
  tmpl src 10.66.66.1 dst 10.55.55.1 proto esp spi <span class="nv">$SPI</span> mode transport
</code></pre>
		</div>
	</div>
	<p>The Security Associations need no change as the encrypted packets will have the same source, destination and SPI.</p>
	<p>With Server B retaining its original setup, I can confirm that Client A can still reach Client B:</p>
	<p><img src="/image/linux/ipsec/bonus-ping-with-ipsec.png" alt="Client A still reaches Client B" /></p>
	<p>This phenomenon at least proves that IPsec tunnel mode is compatible with IP-in-IP tunnel inside IPsec transport mode.</p>
	<p>Same as above, I perform packet capturing on the Router and compare the results in Wireshark:</p>
	<p><img src="/image/linux/ipsec/bonus-wireshark-compare.png" alt="Comparing packet streams in Wireshark" /></p>
	<p>Seeing how they have identical structures, I can now draw the conclusion that the two modes are fully equivalent, <em>if properly set up</em>.</p>
	<h3 id="caveats">Caveats</h3>
	<p>I emphasized <em>properly set up</em> at the end of the last line above. This is because Linux implements IPsec as a <em>policy-based</em> VPN (and so does Windows), as opposed to <em>route-based</em> VPNs (with OpenVPN being a common example). There’s a difference worth noting.</p>
	<ul>
		<li>
			<p><strong>Policy-based VPN</strong> matches and works on <em>outgoing packets</em>, which may have already gone through multiple levels of routing decisions, and are recaptured before they leave the network processing stack.</p>
			<p>Wikipedia has an excellent graph showing the packet flow in Linux network stack, and you can see that “xfrm lookup” happens right before the packet processing ends.</p>
			<p><img src="https://upload.wikimedia.org/wikipedia/commons/3/37/Netfilter-packet-flow.svg" alt="Packet flow in Linux network stack" /></p>
			<p>Policy-based VPN has the advantage of minimizing the setup job, as it works as a tunnel and handles transport policies on its own, but is sometimes less convenient for being a separate facility from the already-complicated routing policies and NAT rules that a common network gateway may already have. Also, you may want to avoid multiple levels of encryption for both performance reasons and <a href="https://security.stackexchange.com/a/18104/168307">security concerns</a>, which further adds to the complexity of your Security Policies and management efforts.</p>
		</li>
		<li>
			<p><strong>Route-based VPN</strong> creates a virtual network interface (usually either TUN or TAP) and applies cryptographic transformations to traffic sent to or received from this interface. It has the advantage of integrating perfectly with existing routing policies, NAT rules, firewall (if the firewall is configured on the tunnel endpoint) and even packet capturing. As route-based VPNs use the same routing policy database (RPDB) as the main network stack, you can even run dynamic routing protocols inside, like OSPF or BGP. In fact, it is a very common modus operandi in <a href="https://en.wikipedia.org/wiki/Decentralized_network_42">DN42</a> to connect with <a href="https://en.wikipedia.org/wiki/WireGuard">WireGuard</a> and run BGP inside.</p>
			<p>Depending on the software used, it may be even easier to setup a route-based VPN (like OpenVPN), but traffic filtering needs to be done from inside. This is virtually the only disadvantage of route-based VPN.</p>
		</li>
	</ul>
	<p>It’s often a matter of choice between these options. There are more route-based VPN implementations (OpenVPN, WireGuard etc.) but enterprise support for policy-based VPN is more mature, so a decision is to be made when it comes to deployment. I personally never used policy-based VPN outside this lab because I often need complex routing policies and NAT rules that policy VPNs are bad at, but YMMV.</p>
	<h2 id="troubleshooting">Troubleshooting</h2>
	<p>Finally, if you are going to use my article as a hands-on tutorial for setting up a similar lab, some troubleshooting experiences and tips would certainly turn useful.</p>
	<ul>
		<li>Creating <code class="language-plaintext highlighter-rouge">ip xfrm state</code> results in <em>Protocol not supported</em>: Check on the Proxmox VE host if <code class="language-plaintext highlighter-rouge">modprobe xfrm4_tunnel</code> works correctly. It may fail with <em>Unknown symbol in module</em> or <em>Invalid argument</em>. In either case, update the Linux kernel package to the latest and reboot the host.</li>
		<li>Decrypted packets not found except in <code class="language-plaintext highlighter-rouge">tcpdump</code>: Check <code class="language-plaintext highlighter-rouge">/proc/net/xfrm_stat</code> and see which number is going up. This kernel interface provides statistics for packets dropped by the XFRM framework. Refer to <a href="https://www.kernel.org/doc/Documentation/networking/xfrm_proc.txt">the kernel documentation</a> to see what each number means.</li>
		<li><strong>Bonus section:</strong>
			<ul>
				<li><code class="language-plaintext highlighter-rouge">ip tunnel add</code> showing <code class="language-plaintext highlighter-rouge">add tunnel "tunl0": failed: No such device</code>: The <code class="language-plaintext highlighter-rouge">ipip</code> and <code class="language-plaintext highlighter-rouge">tunnel4</code> modules need to be loaded on the host. A simple <code class="language-plaintext highlighter-rouge">modprobe</code> command should do it</li>
			</ul>
		</li>
	</ul>
	]]></content><author><name>iBug</name></author><category term="linux" /><category term="networking" /><summary type="html"><![CDATA[Linux has a built-in framework for Internet Protocol Security (IPsec), which is often combined with other tunneling technologies (e.g. L2TP and GRE) to create secure cross-site network connections. As an innovative attempt to a lab in this semester’s Network Security course, which was designed to work over multiple Windows Server 2003 virtual machines (VM), I decided to go on my own and proceed with Linux VMs.]]></summary></entry><entry><title type="html">Disassembling a hardware RAID 1 array in Proxmox VE</title><link href="https://ibug.io/blog/2021/08/proxmox-disassemble-hardware-raid1/" rel="alternate" type="text/html" title="Disassembling a hardware RAID 1 array in Proxmox VE" /><published>2021-08-15T00:00:00+00:00</published><updated>2021-08-16T01:05:26+00:00</updated><id>https://ibug.io/blog/2021/08/proxmox-disassemble-hardware-raid1</id><content type="html" xml:base="https://ibug.io/blog/2021/08/proxmox-disassemble-hardware-raid1/"><![CDATA[<p>Yesterday in a server maintenance period, we decided to tune the storage layout of our Proxmox VE server, which included disassembling a RAID 1 array and adjusting the size of the root filesystem.</p>
	<h2 id="backup-data">Backup data</h2>
	<p class="notice--danger">As is always, potentially destructive disk operations should be preceded with a backup of anything necessary for recovery.</p>
	<p>Proxmox VE uses a kind of “standard” partition layout, with the first 512 MB of the primary disk allocated for the EFI System Partition (ESP), and the rest forming an LVM physical volume (PV), which then becomes a volume group (VG) named <code class="language-plaintext highlighter-rouge">pve</code>. In the <code class="language-plaintext highlighter-rouge">pve</code> VG, a fifth of total available space is allocated to the root filesystem for the Proxmox VE system, and the rest goes to a thin pool named <code class="language-plaintext highlighter-rouge">data</code>.</p>
	<p>The initial disk layout on our server is like this:</p>
	<p><img src="/image/proxmox-raid1/initial-fdisk.png" alt="Initial disk layout" /></p>
	<p>The system is booted with UEFI, so the first partition can be safely ignored. The second partition is the ESP and contains no critical data, as it can be rebuilt when needed. The only thing left for backup is the rootfs since we haven’t made use of the <code class="language-plaintext highlighter-rouge">data</code> volume. A good news is that the rootfs only has less then 3.5 GB of content (we have separate storages for the system and our virtual machines), so backing up is as easy as allocating a 4 GB volume on our data storage and copying the whole rootfs over with <a href="https://www.samba.org/rsync/">Rsync</a>:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>rsync <span class="nt">-aHAXx</span> / /mnt/backup/
</code></pre>
		</div>
	</div>
	<p>In addition, it’s been said in <a href="https://superuser.com/a/137310/688600">this Super User answer</a> that</p>
	<blockquote>
		<p>Of course, it may be a complete jerk for you and wipe the drives for no good reason, but this is very unlikely.</p>
	</blockquote>
	<p>So we might not even need that backup (in fact we didn’t). After all, it’s better safe than sorry, isn’t it?</p>
	<h2 id="disassemble-array">Disassembling the RAID array</h2>
	<p>The standard procedure for this is to reboot into BIOS setup and change the settings there.</p>
	<p>I reboot the server, hitting F9 on its POST screen.</p>
	<p><img src="/image/proxmox-raid1/hpe-enter-bios.png" alt="HPE POST Screen" /></p>
	<p>Next, I locate the built-in RAID controller. It’s called “HPE Smart Array”. I navigate into the options, locate the RAID-1 array, and select “Delete Array”. It completes just in a flash.</p>
	<p><img src="/image/proxmox-raid1/hpe-bios-array-setting.png" alt="HPE Array Setting" /></p>
	<p>To ensure the changes take effect, I reboot the server again.</p>
	<h2 id="restore-partitions">Restore the partition table</h2>
	<p>Because the disks may previously contain some RAID information at their start, their content may not be recognized now, so I insert a virtual CD-ROM drive using the “Virtual Media” feature provided by the Baseboard Management Controller (BMC, also known as IPMI). It’s good we have a file server providing these handy resources. As the host system has been updated to <a href="https://pve.proxmox.com/wiki/Roadmap#Proxmox_VE_7.0">Proxmox VE 7</a>, I picked the new Debian Bullseye Live CD instead of Buster. This ensures I can start the server for disk recovery jobs.</p>
	<p><img src="/image/proxmox-raid1/set-virtual-media.png" alt="Insert ISO from IPMI" /></p>
	<p>This time I enter “One-Time Boot Menu” to boot from the CD-ROM. I select “iLO Virtual CD-ROM” and it starts up.</p>
	<p><img src="/image/proxmox-raid1/hpe-bios-boot-from-iso.png" alt="Select boot item" /></p>
	<p>In a few seconds, the Debian boot screen shows up.</p>
	<p><img src="/image/linux/debian-11-livecd.png" alt="Debian Bullseye GRUB screen" /></p>
	<p>Now I can run <code class="language-plaintext highlighter-rouge">fdisk</code> to check the disk status. As expected, no partitions are found.</p>
	<p>Given that the “Delete Array” operation completes so quickly, I’m sure it did nothing to data stored on the disk, so I can try recovering the partition table. <a href="https://linux.die.net/man/1/testdisk"><code class="language-plaintext highlighter-rouge">testdisk</code></a> is one of the utilities that do this job.</p>
	<p><img src="/image/proxmox-raid1/after-disassembly-fdisk.png" alt="Disk layout after disassembly" /></p>
	<p>The terminal interface of testdisk is straightforward. Select the only disk given (<code class="language-plaintext highlighter-rouge">/dev/sda</code>, the one you gave it as CLI argument), select the previous partition table type (testdisk tells you if it can find out, which matches that in the first image of this article), and select “Analyze”.</p>
	<p><img src="/image/proxmox-raid1/testdisk-disk-type.png" alt="Testdisk select disk type" /></p>
	<p>If testdisk found a partition table in the previous screen, the analyze step doesn’t need a second - it will just show the discovered partition. If it didn’t find anything, you can still run “Quick Search” and get your partition table back.</p>
	<p><img src="/image/proxmox-raid1/testdisk-analysis.png" alt="Testdisk partition analysis" /></p>
	<p>In my case, I just select “Backup” and proceed to next step. Testdisk is smart enough to discard the first nonsense partition (it’s completely redundant on a UEFI system), and I’m left with two.</p>
	<p><img src="/image/proxmox-raid1/testdisk-overview.png" alt="Testdisk found partitions" /></p>
	<p>There’s no change I need to make at this stage, so I just proceed to the final screen and let testdisk write the partition table.</p>
	<p><img src="/image/proxmox-raid1/testdisk-confirm.png" alt="Testdisk confirm partitions" /></p>
	<p>Although testdisk tells me “<em>You will have to reboot for the change to take effect</em>”, calling <code class="language-plaintext highlighter-rouge">partprobe</code> is all that’s necessary. Now I can confirm with <code class="language-plaintext highlighter-rouge">fdisk</code> that the partition table has been restored.</p>
	<p><img src="/image/proxmox-raid1/restored-fdisk.png" alt="Restored disk layout" /></p>
	<p class="notice--info"><code class="language-plaintext highlighter-rouge">partprobe</code> doesn’t come with Debian Bullseye live CD (it did with Debian Buster). To get the command I installed <code class="language-plaintext highlighter-rouge">parted</code> package.</p>
	<h2 id="shrink-rootfs">Shrinking the root filesystem</h2>
	<p>It’s a complete waste to give the rootfs a whopping 96 GB when we only use some 3.5 GB, so I go to shrink it down to 16 GB.</p>
	<p>Before shrinking the volume, it’s necessary to shrink the <em>filesystem</em> first. Yes, a “partition” and a “filesystem” are two different concepts.</p>
	<p>The rootfs of Proxmox VE resides in LVM, so the first thing is to get LVM tools up and running. I tried <code class="language-plaintext highlighter-rouge">apt install lvm2</code>, and was (a bit) surprised to found that it came with Debian Bullseye Live CD.</p>
	<p>I get back the VG <code class="language-plaintext highlighter-rouge">pve</code> by <code class="language-plaintext highlighter-rouge">vgscan</code>, and make all LVs available for operation by <code class="language-plaintext highlighter-rouge">vgchange -ay pve</code>. I can then mount <code class="language-plaintext highlighter-rouge">/dev/pve/root</code> somewhere and check the volume usage with <code class="language-plaintext highlighter-rouge">df -h</code>. Just around 4 gigs, we’re good.</p>
	<p>Many years ago I read <a href="https://matt.berther.io/2015/02/03/how-to-resize-aws-ec2-ebs-volumes/">this blog by Matt Berther</a> about shrinking EBS volumes on AWS EC2. The same solution is still applicable here (though years of Linux experience relieved me of the need for the blog as a reference).</p>
	<p>I unmount the rootfs and run <code class="language-plaintext highlighter-rouge">e2fsck -f /dev/pve/root</code> to ensure a clean state of the filesystem, followed by <code class="language-plaintext highlighter-rouge">resize2fs -M -p /dev/pve/root</code> to perform the shrinking.</p>
	<p><img src="/image/proxmox-raid1/shrink-rootfs.png" alt="Shrinking rootfs" /></p>
	<p>After the filesystem is shrunk, I shrink the logical volume with <code class="language-plaintext highlighter-rouge">lvresize -L 16G pve/root</code>. Then I grow the filesystem back to the full size of the volume with <code class="language-plaintext highlighter-rouge">resize2fs -p /dev/pve/root</code> (without the <code class="language-plaintext highlighter-rouge">-M</code> option).</p>
	<p><img src="/image/proxmox-raid1/grow-rootfs.png" alt="Restore rootfs" /></p>
	<h2 id="convert-rootfs-to-mirrored">Restoring rootfs to “RAID” state</h2>
	<p>The main reason we set up RAID 1 for these disks is to provide resilience against disk failures, so we can still have the system running if either disk dies. Completely breaking up the RAID array defeats this purpose, so it’s helpful to at least add the rootfs back to the mirrored state.</p>
	<p>Luckily, <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/logical_volume_manager_administration/mirror_create">LVM provides the ability</a> to create mirrored volumes. Converting an existing one is even easier:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>lvconvert <span class="nt">-m1</span> pve/root
</code></pre>
		</div>
	</div>
	<p>The command failed for an obvious reason: There’s only one disk in the VG.</p>
	<p>Recalling that a RAID 1 array has just been broken up, there’s <code class="language-plaintext highlighter-rouge">/dev/sdb</code> with an identical partition structure available. I repeat the same steps to recover the partition table on <code class="language-plaintext highlighter-rouge">/dev/sdb</code>, and wiped <code class="language-plaintext highlighter-rouge">/dev/sdb2</code> to avoid conflict. I can then add it to the VG as a second PV:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="nb">dd </span><span class="k">if</span><span class="o">=</span>/dev/zero <span class="nv">of</span><span class="o">=</span>/dev/sdb2 <span class="nv">bs</span><span class="o">=</span>1M <span class="nv">count</span><span class="o">=</span>1
pvcreate /dev/sdb2
vgextend pve /dev/sdb2
</code></pre>
		</div>
	</div>
	<p>Now I can convert the rootfs to “mirrored” volume.</p>
	<p><img src="/image/proxmox-raid1/extend-vg.png" alt="Extend volume group" /></p>
	<p>The “data” volume can also be extended to take all remaining space as well:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>lvextend <span class="nt">-l</span> +100%FREE pve/data
</code></pre>
		</div>
	</div>
	<h2 id="fix-grub">Fixing up GRUB</h2>
	<p>To ensure the system can boot up normally, GRUB should be updated. This needs to be done in chroot inside the original system environment. A bunch of mounts must be setup for GRUB reinstallation to work.</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>mount /dev/pve/root /srv

<span class="c"># systemd-udev requires these two directories to be available</span>
mount <span class="nt">-o</span> rbind /run /srv/run
mount <span class="nt">-o</span> rbind /tmp /srv/tmp

<span class="nb">chroot</span> /srv
mount <span class="nt">-t</span> devtmpfs _ /dev
mount /dev/sda1 /boot/efi
mount <span class="nt">-t</span> proc _ /proc
mount <span class="nt">-t</span> sysfs _ /sys
</code></pre>
		</div>
	</div>
	<p>Now I can replace <code class="language-plaintext highlighter-rouge">grub-pc</code> with <code class="language-plaintext highlighter-rouge">grub-efi</code> with <code class="language-plaintext highlighter-rouge">apt install grub-efi</code>, and then run <code class="language-plaintext highlighter-rouge">grub-install</code> on both <code class="language-plaintext highlighter-rouge">/dev/sda1</code> and <code class="language-plaintext highlighter-rouge">/dev/sdb1</code> so that both disks are bootable.</p>
	<h2 id="fix-initrd">Fixing up ramdisk</h2>
	<div class="notice--info">
		<h4 class="no_toc" id="save-yourself-some-hassle"><i class="fas fa-lightbulb"></i> Save yourself some hassle</h4>
		<p>This paragraph tells a trap I encountered. If you’re following this article as a step-by-step guide, you can skip this paragraph and do this instead:</p>
		<ol>
			<li>Either install <code class="language-plaintext highlighter-rouge">mdadm</code>, or</li>
			<li>Edit <code class="language-plaintext highlighter-rouge">/etc/initramfs-tools/modules</code> and append two lines <code class="language-plaintext highlighter-rouge">dm_raid</code> and <code class="language-plaintext highlighter-rouge">raid1</code>.</li>
		</ol>
		<p>After picking an action above, run <code class="language-plaintext highlighter-rouge">update-initramfs -u -k all</code> and you can proceed to rebooting from the live CD.</p>
	</div>
	<p>Looking at the checklist, everything should have been taken care of, so I reboot the server. The Proxmox GRUB screen passed as normal. To my surprise, the server is stuck at <em>Loading initial ramdisk</em>.</p>
	<p>To display more information for troubleshooting, I reboot the server again, pressing <code class="language-plaintext highlighter-rouge">e</code> on the GRUB screen so I can edit the boot item. I remove <code class="language-plaintext highlighter-rouge">quiet</code> and added <code class="language-plaintext highlighter-rouge">nomodeset</code> to the kernel command line (see <a href="https://askubuntu.com/q/716957/612877">Ask Ubuntu</a>), and hit Ctrl-X to boot. This does turn up something useful:</p>
	<p><img src="/image/proxmox-raid1/loading-initial-ramdisk-nomodeset.png" alt="Debug output for Loading initial ramdisk" /></p>
	<p>Google search for “raid: failed to run raid array” brings me to <a href="https://askubuntu.com/q/292092/612877">this Ask Ubuntu question</a>. Checking the answers and the comments, I reboot again into Debian Live CD, mount the rootfs, install <code class="language-plaintext highlighter-rouge">mdadm</code>, and <code class="language-plaintext highlighter-rouge">update-initramfs</code> again. The next reboot proved correct, and the Proxmox VE server is back up now.</p>
	<h2 id="other-stuff">Other stuff</h2>
	<p>At this point, this server maintenance job has been concluded. If you’re stumbling upon this article and find a mistake or have other questions, feel free to leave a comment below.</p>
	]]></content><author><name>iBug</name></author><category term="linux" /><summary type="html"><![CDATA[Yesterday in a server maintenance period, we decided to tune the storage layout of our Proxmox VE server, which included disassembling a RAID 1 array and adjusting the size of the root filesystem.]]></summary></entry><entry><title type="html">I switched from Google Chrome to Microsoft Edge</title><link href="https://ibug.io/blog/2021/06/switch-from-google-chrome-to-microsoft-edge/" rel="alternate" type="text/html" title="I switched from Google Chrome to Microsoft Edge" /><published>2021-06-12T00:00:00+00:00</published><updated>2021-06-12T03:08:23+00:00</updated><id>https://ibug.io/blog/2021/06/switch-from-google-chrome-to-microsoft-edge</id><content type="html" xml:base="https://ibug.io/blog/2021/06/switch-from-google-chrome-to-microsoft-edge/"><![CDATA[<p>Last year (maybe September? I don’t remember now) I switched my primary browser from Google Chrome to the new Microsoft Edge. It turned out to be a wise move and I’ve been with Edge for more than half a year now. In this article I’ll share my ideas with this move.</p>
	<h3 id="same-chromium-kernel">Same Chromium kernel</h3>
	<p>The moment Microsoft Edge went attractive was when I learned that <a href="https://www.browserstack.com/blog/chromium-based-edge/"><strong>it started to be based on Chromium</strong></a>, so that web pages will behave identially as if they were on Google Chrome or the Chromium browser. This is particularly important as I often engineer for Chrome when developing front-end applications.</p>
	<p>Beside that, the seamless availability of existing Chrome extensions is also a great plus. I rely heavily on several extensions to enhance my surfing experience, some of which are:</p>
	<ul>
		<li><a href="https://microsoftedge.microsoft.com/addons/detail/tampermonkey/iikmkjmpaadaobahmlepeloendndfphd">Tampermonkey</a></li>
		<li><a href="https://microsoftedge.microsoft.com/addons/detail/ublock-origin/odfafepnkmbhccpbejgmiehpchacaeak">uBlock Origin</a></li>
		<li>Proxy SwitchyOmega</li>
		<li><a href="https://microsoftedge.microsoft.com/addons/detail/https-everywhere/fchjpkplmbeeeaaogdbhjbgbknjobohb">HTTPS Everywhere</a></li>
	</ul>
	<p>Needless to say, the old EdgeHTML Edge browser was just disappointing, lacking many common browser features and a buggy rendering engine. I surely take it as a sensible move to replace the old kernel.</p>
	<h3 id="windows-integration">Integration with Windows</h3>
	<p>As for everything else designed for or ships with Windows, Microsoft Edge integrates excellently into Windows and other Microsoft online products.</p>
	<p>You can log in to Microsoft Edge with your Microsoft account with just one click, if you have the account set up with your Windows user. Then the syncing launches automatically, and your saved bookmarks, histories, forms etc. are readily available.</p>
	<p>A logged-in Microsoft Edge browser also eases the login process of most Microsoft products, like Office Online, OneDrive, or whatever web application using Microsoft OAuth login. As long as the browser is authenticated, the <code class="language-plaintext highlighter-rouge">login.microsoftonline.com</code> page proceeds automatically. This comes in handy when you want to maximize your operation on the web.</p>
	<p>For sensitive access like <code class="language-plaintext highlighter-rouge">account.microsoft.com</code>, Microsoft Edge will prompt you for your PIN (if you have it set up on the computer) or password via the native Windows authentication system, bringing the same level of security of your Windows login to browser Microsoft account access.</p>
	<h3 id="data-syncing">Data syncing</h3>
	<p>Since I’m already using OneDrive for my document storage and syncing, I feel my data safer with Microsoft, and so does my browser information. Just like Google Chrome, the new Microsoft Edge syncs everything across computers and mobile devices. For the best connected experience, I also fetched Microsoft Edge (Android) from Google Play Store and signed in there. This enabled me to continue where I left off from my computer right on my phone.</p>
	<p>One extra bonus point for mainland China users: Browser data sync for Microsoft Edge doesn’t require “over-the-wall” internet access. But for power users of Google Chrome (and Google search), I believe this isn’t an issue already.</p>
	<h3 id="better-pdf-reader">Better PDF reader</h3>
	<p>As with the old EdgeHTML version, the built-in PDF reader of Microsoft Edge outperforms that of all other browsers. Given its good performance and lower power consumption, it’s my PDF reader of choice on a business laptop that focuses on battery-run duration, so that I don’t need Adobe Acrobat for all its fancy features and battery hogging. Microsoft Edge provides all the basic functionalities I need on-the-go, like bookmarks nagivation and pen drawing.</p>
	<h3 id="better-performance">Better performance</h3>
	<p>Microsoft Edge, as promised, eats around 20% to 30% less memory than Google Chrome under the same load. This may not be a problem for beefy workstations with a lot of memory, but it surely plays a role in common househeld desktops and laptops. At a minimum, even if you don’t need to keep more tabs at the same time, the extra memory allows you to run other applications, or simply gives the computer a breath.</p>
	<h2 id="disadvantages">Disadvantages</h2>
	<p>Being relatively new as a consumer product, the new Microsoft Edge is still distant from perfection. There are quite a number of bugs or incomplete functionalities to spot.</p>
	<h3 id="missing-favicons">Missing favicons</h3>
	<p>The first thing it should fix is loading favicons for Favorites website. <strong>It doesn’t, at all.</strong> With a newly imported Favorites library from another browser, <strong>all favicons are missing</strong>. On contrary, Google Chrome tries to load as many as possible after importing bookmarks, which is usually done in a few minutes. This makes the initial setup particularly bothersome, as you now have to read every bookmark title to determine its target, when you <em>could have</em> done so just by skimming through the icons.</p>
	<p><img src="/image/microsoft-edge/missing-favicons.png" alt="image" /></p>
	<p>I really appreciate these blank icons. Thank you for reminding me of the 90’s nostagia of the web’s simplicity, Microsoft.</p>
	<h3 id="new-tab-page-search-locked-to-bing">“New Tab” page search locked to Bing</h3>
	<p>This one is obvious: Whatever you enter into the most noticeable input form will be searches <strong>via Bing</strong>. While in the settings Edge does allow you to choose a search provider for the <em>address bar</em>, it doesn’t, however, for the New Tab page. Google Chrome, however, does this with more sanity: The search provider for the address bar is also used for the New Tab page, giving you a consistent experience for searching.</p>
	<p>To be honest, I would’ve stood with it had Chrome also locked the New Tab page search to Google, which is what I’m using extensively. But Bing just never gives the same level of precision with its search results, so locking a search form to Bing gives me the impression that Microsoft is <em>condescending</em>.</p>
	<h2 id="summary">Summary</h2>
	<p>So far so good. I’ve stayed with Microsoft Edge since and overall it’s quite satisfactory. There are many other differences that makes my experiences with Edge subtly better than with Chrome, like larger UI buttons and menus. So unless you’re a 100% Google power user, I’d recommend the new Microsoft Edge to you, too.</p>
	]]></content><author><name>iBug</name></author><category term="software" /><category term="web" /><summary type="html"><![CDATA[Last year (maybe September? I don’t remember now) I switched my primary browser from Google Chrome to the new Microsoft Edge. It turned out to be a wise move and I’ve been with Edge for more than half a year now. In this article I’ll share my ideas with this move.]]></summary></entry><entry><title type="html">Tunight talk</title><link href="https://ibug.io/blog/2021/04/tunight-talk/" rel="alternate" type="text/html" title="Tunight talk" /><published>2021-04-17T00:00:00+00:00</published><updated>2021-04-17T21:55:43+00:00</updated><id>https://ibug.io/blog/2021/04/tunight-talk</id><content type="html" xml:base="https://ibug.io/blog/2021/04/tunight-talk/"><![CDATA[<p>class: center, middle</p>
	<h1 id="tech-talk">Tech Talk</h1>
	<p><a href="//ibug.io">iBug</a>
		<br />
		<a href="https://lug.ustc.edu.cn">LUG @ USTC</a>
		<br />
		April 17, 2021</p>
	<hr />
	<h2 id="overview">Overview</h2>
	<ul>
		<li>Intranet of USTCLUG</li>
		<li>Auto SSL certificate</li>
		<li>Vlab</li>
		<li>Miscellaneous</li>
	</ul>
	<hr />
	<h2 id="intranet-of-ustclug">Intranet of USTCLUG</h2>
	<ul>
		<li>Multiple cloud and on-premises servers in different datacenters</li>
		<li>Public and internal services
			<ul>
				<li>Public: Mirrors, Auth DNS, Homepage</li>
				<li>Internal: LDAP, Mail gateway, InfluxDB</li>
			</ul>
		</li>
	</ul>
	<p>–</p>
	<!-- -->
	<ul>
		<li>Layer 2 overlay network
			<ul>
				<li><a href="//www.tinc-vpn.org">Tinc VPN</a></li>
			</ul>
		</li>
	</ul>
	<hr />
	<h2 id="tinc-vpn">Tinc VPN</h2>
	<ul>
		<li>Configured in switch mode</li>
		<li>Mesh layout</li>
		<li><strong>Bridged within one datacenter (cluster)</strong></li>
		<li>Secured over the Internet</li>
	</ul>
	<hr />
	<iframe src="https://www.draw.io/?lightbox=1&amp;highlight=0000ff&amp;edit=_blank&amp;layers=1&amp;nav=1&amp;title=LUG%20Network.html#Uhttps%3A%2F%2Fdrive.google.com%2Fa%2F0x01.me%2Fuc%3Fid%3D1WAROAPB8ThTkIjMyFnGvtGgbH-TV4FWh%26export%3Ddownload" frameborder="0" style="width: 100%; height: 100%;"></iframe>
	<hr />
	<p>layout: true</p>
	<h2 id="automatic-ssl-certificate-issue--renewal">Automatic SSL certificate issue &amp; renewal</h2>
	<hr />
	<hr />
	<p>Compliance:</p>
	<ul>
		<li>Our friend sponsored us a Japan VPS so we resolve most of <code class="language-plaintext highlighter-rouge">ustclug.org</code> (from outside USTCnet) to it
			<ul>
				<li>We resolve <code class="language-plaintext highlighter-rouge">ustclug.org</code> to USTCnet when source is also in USTCnet</li>
			</ul>
		</li>
	</ul>
	<!-- -->
	<ul>
		<li>USTC Mirrors has 4 ISP connections (CERNET, Telecom, Mobile, Unicom) and we want to route users by source</li>
	</ul>
	<p>–</p>
	<!-- -->
	<ul>
		<li>Solution: Self-hosted Bind9 server
			<ul>
				<li>Return different answers based on source IP (views)</li>
			</ul>
		</li>
	</ul>
	<hr />
	<ul>
		<li>Solution: Self-hosted Bind9 server
			<ul>
				<li>Return different answers based on source IP (views)</li>
			</ul>
		</li>
		<li>Custom authoritative DNS servers</li>
	</ul>
	<p>–</p>
	<ul>
		<li>Git-based DNS management</li>
		<li>Integration into existing applications?
			<ul>
				<li>We have no easy-to-use API</li>
			</ul>
		</li>
	</ul>
	<hr />
	<p>layout: true</p>
	<h2 id="automatic-ssl-certificate-issue--renewal-1">Automatic SSL certificate issue &amp; renewal</h2>
	<p>Use an existing API!</p>
	<hr />
	<hr />
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="c"># apt list ~npython3-certbot-dns</span>
python3-certbot-dns-cloudflare    - Doesn<span class="s1">'t support sub-zones
python3-certbot-dns-digitalocean  - [OK]
python3-certbot-dns-dnsimple      - Paid
python3-certbot-dns-gandi         - Doesn'</span>t support sub-zones
python3-certbot-dns-gehirn        - <span class="o">[</span>Couldn<span class="s1">'t determine]
python3-certbot-dns-google        - Doesn'</span>t support sub-zones
python3-certbot-dns-linode        - No account, couldn<span class="s1">'t determine
python3-certbot-dns-ovh           - Could not register account
python3-certbot-dns-rfc2136       - Performance?
python3-certbot-dns-route53       - Paid
python3-certbot-dns-sakuracloud   - Could not register account
</span></code></pre>
		</div>
	</div>
	<p><code class="language-plaintext highlighter-rouge">acme.sh</code>?</p>
	<hr />
	<pre><code class="language-dns">_acme-challenge.lug.ustc.edu.cn.     600 IN CNAME  lug.ssl-digitalocean.ustclug.org.
_acme-challenge.ustclug.org.         600 IN CNAME  lug.ssl-digitalocean.ustclug.org.
_acme-challenge.proxy.ustclug.org.   600 IN CNAME  lug.ssl-digitalocean.ustclug.org.
_acme-challenge.mirrors.ustc.edu.cn. 600 IN CNAME  mirrors.ssl-digitalocean.ustclug.org.
</code></pre>
	<pre><code class="language-dns">ssl-digitalocean.ustclug.org.  86400 IN NS  ns1.digitalocean.com.
                               86400 IN NS  ns2.digitalocean.com.
                               86400 IN NS  ns3.digitalocean.com.
</code></pre>
	<hr />
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>acme.sh <span class="nt">--issue</span> <span class="se">\</span>
  <span class="nt">--dns</span> dns_dgon <span class="se">\</span>
  <span class="nt">--domain-alias</span> lug.ssl-digitalocean.ustclug.org <span class="se">\</span>
  <span class="nt">-d</span> lug.ustc.edu.cn <span class="se">\</span>
  <span class="nt">-d</span> <span class="se">\*</span>.lug.ustc.edu.cn <span class="se">\</span>
  <span class="nt">-d</span> ustclug.org <span class="se">\</span>
  <span class="nt">-d</span> <span class="se">\*</span>.ustclug.org <span class="se">\</span>
  <span class="nt">-d</span> <span class="se">\*</span>.proxy.ustclug.org <span class="se">\</span>
  <span class="nt">--cert-file</span> cert/lug/cert.pem <span class="se">\</span>
  <span class="nt">--key-file</span> cert/lug/privkey.pem <span class="se">\</span>
  <span class="nt">--fullchain-file</span> cert/lug/fullchain.pem
</code></pre>
		</div>
	</div>
	<hr />
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>acme.sh <span class="nt">--issue</span> <span class="se">\</span>
  <span class="nt">--dns</span> dns_dgon <span class="se">\</span>
  <span class="nt">--domain-alias</span> mirrors.ssl-digitalocean.ustclug.org <span class="se">\</span>
  <span class="nt">-d</span> mirrors.ustc.edu.cn <span class="se">\</span>
  <span class="nt">-d</span> <span class="se">\*</span>.mirrors.ustc.edu.cn <span class="se">\</span>
  <span class="nt">--cert-file</span> cert/mirrors/cert.pem <span class="se">\</span>
  <span class="nt">--key-file</span> cert/mirrors/privkey.pem <span class="se">\</span>
  <span class="nt">--fullchain-file</span> cert/mirrors/fullchain.pem
</code></pre>
		</div>
	</div>
	<hr />
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>git <span class="nt">-C</span> cert add <span class="nt">--all</span>
git <span class="nt">-C</span> cert <span class="nt">-c</span> user.name<span class="o">=</span>GitHub <span class="nt">-c</span> user.email<span class="o">=</span>noreply@github.com commit <span class="se">\</span>
    <span class="nt">-m</span> <span class="s2">"Update certificates on </span><span class="si">$(</span><span class="nb">date</span> +%Y-%m-%d<span class="si">)</span><span class="s2">"</span> <span class="se">\</span>
    <span class="nt">-m</span> <span class="s2">"</span><span class="si">$(</span>git log <span class="nt">-1</span> <span class="nt">--pretty</span><span class="o">=</span><span class="s1">'tformat:[%h] %an: %s'</span> HEAD<span class="si">)</span><span class="s2">"</span>
git <span class="nt">-C</span> cert push
</code></pre>
		</div>
	</div>
	<hr />
	<p>layout: true</p>
	<h2 id="vlab">Vlab</h2>
	<hr />
	<p><img src="https://vlab.ustc.edu.cn/docs/images/home.png" alt="" /></p>
	<hr />
	<p>layout: false
		class: center, middle</p>
	<div><img src="https://vlab.ustc.edu.cn/docs/images/vlab-in-browser.jpg" /></div>
	<hr />
	<p>layout: true</p>
	<h2 id="vlab-1">Vlab</h2>
	<hr />
	<ul>
		<li>Xilinx Vivado
			<ul>
				<li>Multiple GBs of <em>slow</em> downloading</li>
				<li>Hard to setup and maintain</li>
			</ul>
		</li>
		<li>Other software (MATLAB, Wolfram Mathematica etc.)
			<ul>
				<li>Same size &amp; complexity issues</li>
			</ul>
		</li>
	</ul>
	<p>–</p>
	<!-- -->
	<ul>
		<li>
			<s>Another VPS provider</s>
		</li>
		<li>LXC containers
			<ul>
				<li>Lightweight</li>
				<li>Host-manageable</li>
				<li>System container (<s>application container</s>)</li>
			</ul>
		</li>
	</ul>
	<hr />
	<ul>
		<li>Sharing &amp; Isolation</li>
	</ul>
	<p>–</p>
	<!-- -->
	<ul>
		<li>Storage allocation: LVM
			<ul>
				<li>iSCSI isn’t multi-mount-aware</li>
				<li>ZFS doesn’t support</li>
				<li>NFS = SPOF</li>
			</ul>
		</li>
	</ul>
	<p>–</p>
	<ul>
		<li>But why does LVM work?</li>
	</ul>
	<p>–</p>
	<ul>
		<li><strong>“Activated volume”</strong>
			<ul>
				<li>PVE native support: Only activate volumes in use by VMs/CTs</li>
			</ul>
		</li>
	</ul>
	<p>–</p>
	<!-- -->
	<ul>
		<li>Network isolation: VXLAN
			<ul>
				<li><span style="color: salmon;">❤</span> -50</li>
				<li>Solution: Increase host <span style="color: salmon;">❤</span> to 1550</li>
			</ul>
		</li>
	</ul>
	<hr />
	<p>User access:</p>
	<ul>
		<li>VNC unified login
			<ul>
				<li>10,000 lines of C++ (by <a href="//github.com/pdlan">pdlan</a>)
					<ul>
						<li>Identify users via VNC login username
							<ul>
								<li>Multi VM selection: <code class="language-plaintext highlighter-rouge">username:id</code></li>
							</ul>
						</li>
						<li>Queries Django for VM information</li>
					</ul>
				</li>
			</ul>
		</li>
		<li>Browser login: noVNC</li>
	</ul>
	<p>–</p>
	<ul>
		<li>SSH unified login
			<ul>
				<li>Modified from <a href="//github.com/tg123/sshpiper">tg123/sshpiper</a></li>
				<li>Pubkey-based user identificaion
					<ul>
						<li>Certificate-based VM access</li>
					</ul>
				</li>
			</ul>
		</li>
		<li>Browser login: Wetty (alpha)</li>
	</ul>
	<hr />
	<p>layout: false</p>
	<iframe src="https://vlab.ustc.edu.cn/grafana/d-solo/2/vlab-usage-statistics?orgId=1&amp;from=1587065070291&amp;to=1618601070291&amp;theme=light&amp;panelId=2" frameborder="0" style="width: 100%; height: 100%;"></iframe>
	<hr />
	<p>layout: true</p>
	<h2 id="miscellaneous">Miscellaneous</h2>
	<hr />
	<ul>
		<li>Protect ports of VM from host (iptables)
			<ul>
				<li>SSH-based “authentication” ✔</li>
			</ul>
		</li>
	</ul>
	<hr />
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>:INPUT DROP <span class="o">[</span>0:0]
<span class="c"># ...</span>
:iBug - <span class="o">[</span>0:0]
<span class="nt">-A</span> INPUT <span class="nt">-m</span> conntrack <span class="nt">--ctstate</span> RELATED,ESTABLISHED <span class="nt">-j</span> ACCEPT
<span class="nt">-A</span> INPUT <span class="nt">-i</span> lo <span class="nt">-j</span> ACCEPT
<span class="nt">-A</span> INPUT <span class="nt">-j</span> iBug
<span class="nt">-A</span> INPUT <span class="nt">-g</span> BLOCK

<span class="c"># ...</span>
<span class="nt">-A</span> iBug <span class="nt">-p</span> icmp <span class="nt">-j</span> ACCEPT
<span class="nt">-A</span> iBug <span class="nt">-p</span> tcp <span class="nt">-m</span> multiport <span class="nt">--dports</span> 22,80,443,8888,25565 <span class="nt">-j</span> ACCEPT
<span class="nt">-A</span> iBug <span class="nt">-m</span> <span class="nb">set</span> <span class="o">!</span> <span class="nt">--match-set</span> home src <span class="nt">-p</span> tcp <span class="nt">--dport</span> 3389 <span class="nt">-j</span> BLOCK
</code></pre>
		</div>
	</div>
	<p><code class="language-plaintext highlighter-rouge">/etc/iptables/ipsets</code>:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>create home <span class="nb">hash</span>:ip family inet <span class="nb">timeout </span>600
</code></pre>
		</div>
	</div>
	<hr />
	<p><code class="language-plaintext highlighter-rouge">~/.ssh/rc</code>:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="k">if</span> <span class="o">[</span> <span class="nt">-z</span> <span class="s2">"</span><span class="nv">$BASH</span><span class="s2">"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then
  </span><span class="nb">exec</span> /bin/bash <span class="nt">--</span> <span class="s2">"</span><span class="nv">$0</span><span class="s2">"</span> <span class="s2">"</span><span class="nv">$@</span><span class="s2">"</span>
  <span class="nb">exit </span>1
<span class="k">fi

</span><span class="nv">_ssh_client</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">SSH_CONNECTION</span><span class="p">%% *</span><span class="k">}</span><span class="s2">"</span>
<span class="nv">_ppid</span><span class="o">=</span><span class="s2">"</span><span class="si">$(</span>ps <span class="nt">-o</span> <span class="nv">ppid</span><span class="o">=</span> <span class="si">$(</span>ps <span class="nt">-o</span> <span class="nv">ppid</span><span class="o">=</span> <span class="nv">$PPID</span><span class="si">))</span><span class="s2">"</span>

<span class="nb">nohup</span> /home/ubuntu/.local/bin/_ssh_refresh_client <span class="s2">"</span><span class="nv">$_ssh_client</span><span class="s2">"</span> <span class="s2">"</span><span class="nv">$_ppid</span><span class="s2">"</span> &amp;&gt;/dev/null &amp; <span class="nb">exit </span>0
</code></pre>
		</div>
	</div>
	<hr />
	<p><code class="language-plaintext highlighter-rouge">_ssh_refresh_client</code>:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="k">if</span> <span class="o">[</span> <span class="nt">-z</span> <span class="s2">"</span><span class="nv">$BASH</span><span class="s2">"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then
  </span><span class="nb">exec</span> /bin/bash <span class="nt">--</span> <span class="s2">"</span><span class="nv">$0</span><span class="s2">"</span> <span class="s2">"</span><span class="nv">$@</span><span class="s2">"</span>
<span class="k">fi

</span><span class="nv">_ssh_client</span><span class="o">=</span><span class="s2">"</span><span class="nv">$1</span><span class="s2">"</span>
<span class="nv">_ppid</span><span class="o">=</span><span class="s2">"</span><span class="nv">$2</span><span class="s2">"</span>

<span class="k">while </span><span class="nb">kill</span> <span class="nt">-0</span> <span class="s2">"</span><span class="nv">$_ppid</span><span class="s2">"</span> 2&gt;/dev/null<span class="p">;</span> <span class="k">do
  </span><span class="nb">sudo </span>ipset <span class="nt">-exist</span> add home <span class="s2">"</span><span class="nv">$_ssh_client</span><span class="s2">"</span> <span class="nb">timeout </span>300
  <span class="nb">sleep </span>60
<span class="k">done
</span><span class="nb">exit </span>0
</code></pre>
		</div>
	</div>
	<hr />
	<p>layout: false</p>
	<h2 id="your-notification-center"><em>Your</em> notification center</h2>
	<p><a href="https://github.com/iBug/rss-to-telegram">iBug/rss-to-telegram</a></p>
	<p><img src="/image/rss-to-telegram.png" alt="" /></p>
	<hr />
	<h2 id="cloudflare-worker-makes-free-file-sharing-site">Cloudflare Worker makes free file sharing site</h2>
	<p><a href="https://github.com/iBug/cf-github-releases">iBug/cf-github-releases</a></p>
	<p><a href="https://download.ibugone.com">My demo site</a> (<a href="https://github.com/iBug/Archive/releases">Repository</a>)</p>
	<p><img src="/image/cloudflare/cf-github-releases.png" alt="" /></p>
	<hr />
	<p>class: center, middle
		layout: false</p>
	<h1 id="thank-you">Thank you!</h1>
	]]></content><author><name>iBug</name></author><summary type="html"><![CDATA[Slides for my talk at Tunight]]></summary></entry><entry><title type="html">Setting up a GitHub webhook on AWS Lambda</title><link href="https://ibug.io/blog/2021/02/github-webhook-on-aws-lambda/" rel="alternate" type="text/html" title="Setting up a GitHub webhook on AWS Lambda" /><published>2021-02-19T00:00:00+00:00</published><updated>2021-02-27T03:04:22+00:00</updated><id>https://ibug.io/blog/2021/02/github-webhook-on-aws-lambda</id><content type="html" xml:base="https://ibug.io/blog/2021/02/github-webhook-on-aws-lambda/"><![CDATA[<p>Last month I set up my own Telegram bot for GitHub event notification. To receive GitHub events via webhook, a receiver is needed. True, it isn’t hard to write a <a href="https://palletsprojects.com/p/flask/">Flask</a> or <a href="http://sinatrarb.com/">Sinatra</a> server and throw the whole thing onto a VPS, but thinking about the complexity and maintenance efforts, serverless platforms like AWS Lambda smells like a better fit. So I decided to take this opportunity to begin my exploration to “the serverless industry”.</p>
	<p><small><a href="/p/41-cn">There’s a Chinese version of this article / 本文还有中文版</a></small></p>
	<h2 id="aws-lambda">Setting up AWS Lambda</h2>
	<p>I have had an AWS account for years, so I’ll skip the sign-up process in this article and head straight to <a href="https://console.aws.amazon.com/">AWS Management Console</a>.</p>
	<p>Locate the <a href="https://console.aws.amazon.com/lambda/home"><strong>Lambda</strong></a> entry in the list of AWS services. It’s in the first group so should be easy to spot.</p>
	<p><img src="/image/aws/console-home-1.png" alt="AWS Management Console Home" /></p>
	<p>And then we create a new Lambda function, selecting Python 3.8 as the runtime environment</p>
	<p><img src="/image/aws/lambda-create-function-1.png" alt="Create new Lambda function" class="border" /></p>
	<p>After clicking “Create”, you’ll be brought to the edit page of that function, with the following code filled in as a starting point.</p>
	<div class="language-python highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="kn">import</span> <span class="nn">json</span>

<span class="k">def</span> <span class="nf">lambda_handler</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="c1"># TODO implement
</span>    <span class="k">return</span> <span class="p">{</span>
        <span class="s">'statusCode'</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
        <span class="s">'body'</span><span class="p">:</span> <span class="n">json</span><span class="p">.</span><span class="n">dumps</span><span class="p">(</span><span class="s">'Hello from Lambda!'</span><span class="p">)</span>
    <span class="p">}</span>
</code></pre>
		</div>
	</div>
	<p>We don’t know what this code can do for now, so let’s put it aside and turn to the API Gateway part, since eventually we’ll use it as the webhook receiver endpoint.</p>
	<h2 id="api-gateway">Setting up AWS API Gateway</h2>
	<p>Open the <a href="https://console.aws.amazon.com/apigateway/main">AWS API Gateway console</a> and click <strong>Create API</strong> on the top right.</p>
	<p><img src="/image/aws/api-gateway-new-1.png" alt="Create API" class="border" /></p>
	<p>On the next screen, we add our Lambda function created earlier as an integration here.</p>
	<p><img src="/image/aws/api-gateway-new-2.png" alt="Configure integrations" class="border" /></p>
	<p>Then it turns to Routes. Routes describe how HTTP endpoints are mapped to integrations (receivers). An example (default) route is pre-filled in the dialog.</p>
	<p><img src="/image/aws/api-gateway-routes-1.png" alt="Configure routes (1)" class="border" /></p>
	<p>Since we have our Lambda function as the only integration here, we want to process actual routes by ourselves. Delete that path <code class="language-plaintext highlighter-rouge">/myGitHubWebhook</code> and enter <code class="language-plaintext highlighter-rouge">$default</code> into that box. <code class="language-plaintext highlighter-rouge">$default</code> is a special value that once entered, the “method” dropdown greys out.</p>
	<p><img src="/image/aws/api-gateway-routes-2.png" alt="Configure routes (2)" class="border" /></p>
	<p>We can now visit our API to see if it works.</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">ubuntu@iBug-Server:~ $</span><span class="w"> </span>curl https://nad73szpz7.execute-api.us-east-1.amazonaws.com/
<span class="go">"Hello from Lambda!"
</span><span class="gp">ubuntu@iBug-Server:~ $</span><span class="w">
</span></code></pre>
		</div>
	</div>
	<h2 id="lambda-code">Coding for Lambda</h2>
	<p>With the infrastructure set up, we should now write our code for the GitHub webhook receiver.</p>
	<p>We need to first know how the client request is passed to our Lambda function. This is not hard to figure out with some simple code that just spits out what it receives. To save some time, I’ve done this so you don’t have to. Here’s what you’d receive via the <code class="language-plaintext highlighter-rouge">event</code> object passed to the Lambda function entry. Keep in mind that it’s a dictionary in Python.</p>
	<details>
		<summary>
			<p>Example content of <code class="language-plaintext highlighter-rouge">event</code> object</p>
		</summary>
		<div class="language-json highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"version"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2.0"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"routeKey"</span><span class="p">:</span><span class="w"> </span><span class="s2">"$default"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"rawPath"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/api-test"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"rawQueryString"</span><span class="p">:</span><span class="w"> </span><span class="s2">"taoky=strong"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"headers"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"accept"</span><span class="p">:</span><span class="w"> </span><span class="s2">"*/*"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"accept-encoding"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gzip"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"cdn-loop"</span><span class="p">:</span><span class="w"> </span><span class="s2">"cloudflare"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"cf-connecting-ip"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2001:db8::1"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"cf-ipcountry"</span><span class="p">:</span><span class="w"> </span><span class="s2">"XX"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"cf-pseudo-ipv4"</span><span class="p">:</span><span class="w"> </span><span class="s2">"255.255.255.255"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"cf-ray"</span><span class="p">:</span><span class="w"> </span><span class="s2">"8b8cca72b23e09a5-NRT"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"cf-request-id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"d2160d7f1100000738c5e62000000001"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"cf-visitor"</span><span class="p">:</span><span class="w"> </span><span class="s2">"{</span><span class="se">\"</span><span class="s2">scheme</span><span class="se">\"</span><span class="s2">:</span><span class="se">\"</span><span class="s2">https</span><span class="se">\"</span><span class="s2">}"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"content-length"</span><span class="p">:</span><span class="w"> </span><span class="s2">"0"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"host"</span><span class="p">:</span><span class="w"> </span><span class="s2">"api.example.com"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"user-agent"</span><span class="p">:</span><span class="w"> </span><span class="s2">"curl/7.68.0"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"x-amzn-trace-id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Root=1-8dab11ae-d63d4eec890259ddab5a7709"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"x-forwarded-for"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2001:db8::1, 162.158.118.243"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"x-forwarded-port"</span><span class="p">:</span><span class="w"> </span><span class="s2">"443"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"x-forwarded-proto"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"x-custom-header"</span><span class="p">:</span><span class="w"> </span><span class="s2">"hello"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"queryStringParameters"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"taoky"</span><span class="p">:</span><span class="w"> </span><span class="s2">"strong"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"requestContext"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"accountId"</span><span class="p">:</span><span class="w"> </span><span class="s2">"166333366666"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"apiId"</span><span class="p">:</span><span class="w"> </span><span class="s2">"nad73szpz7"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"domainName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"api.example.com"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"domainPrefix"</span><span class="p">:</span><span class="w"> </span><span class="s2">"api"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"http"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"method"</span><span class="p">:</span><span class="w"> </span><span class="s2">"POST"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"path"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/api-test"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"protocol"</span><span class="p">:</span><span class="w"> </span><span class="s2">"HTTP/1.1"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"sourceIp"</span><span class="p">:</span><span class="w"> </span><span class="s2">" 162.158.118.243"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"userAgent"</span><span class="p">:</span><span class="w"> </span><span class="s2">"curl/7.68.0"</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="nl">"requestId"</span><span class="p">:</span><span class="w"> </span><span class="s2">"ZcOQCw-WICLEQdg="</span><span class="p">,</span><span class="w">
    </span><span class="nl">"routeKey"</span><span class="p">:</span><span class="w"> </span><span class="s2">"$default"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"stage"</span><span class="p">:</span><span class="w"> </span><span class="s2">"$default"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"time"</span><span class="p">:</span><span class="w"> </span><span class="s2">"20/Jan/2021:16:40:00 +0000"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"timeEpoch"</span><span class="p">:</span><span class="w"> </span><span class="mi">1611160800000</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"body"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Cg=="</span><span class="p">,</span><span class="w">
  </span><span class="nl">"isBase64Encoded"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
			</div>
  </div>
	</details>
	<p>A few notes about the content:</p>
	<ul>
		<li><code class="language-plaintext highlighter-rouge">isBase64Encoded</code> refers to the <code class="language-plaintext highlighter-rouge">body</code> item. In the above example, the actual POST content is a single newline.-</li>
		<li><code class="language-plaintext highlighter-rouge">body</code> may be absent for requests that doesn’t send data, like a GET request.</li>
		<li><code class="language-plaintext highlighter-rouge">headers</code> are all in lowercase which is in line with HTTP/2 specifications. <strong>It could be due to me placing my custom domain behind Cloudflare.</strong></li>
	</ul>
	<p>With that in mind, we can expand the boilerplate Lambda function:</p>
	<div class="language-python highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">def</span> <span class="nf">lambda_handler</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="n">route</span> <span class="o">=</span> <span class="n">event</span><span class="p">[</span><span class="s">"rawPath"</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">route</span> <span class="o">==</span> <span class="s">"/api-test"</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s">'statusCode'</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
            <span class="s">'headers'</span><span class="p">:</span> <span class="p">{</span><span class="s">'Content-Type'</span><span class="p">:</span> <span class="s">'application/json'</span><span class="p">},</span>
            <span class="s">'body'</span><span class="p">:</span> <span class="n">json</span><span class="p">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">event</span><span class="p">),</span>
        <span class="p">}</span>
    <span class="k">elif</span> <span class="n">route</span> <span class="o">==</span> <span class="s">"/github-webhook"</span><span class="p">:</span>
        <span class="c1"># TODO Write webhook receiver code
</span>        <span class="k">pass</span>
</code></pre>
		</div>
	</div>
	<p>The actual webhook processing code shouldn’t be too difficult to write. For example, here’s an example of verifying GitHub via the HMAC signature:</p>
	<div class="language-python highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="kn">import</span> <span class="nn">base64</span>
<span class="kn">import</span> <span class="nn">hashlib</span>
<span class="kn">import</span> <span class="nn">hmac</span>
<span class="kn">import</span> <span class="nn">os</span>
</code></pre>
		</div>
	</div>
	<div class="language-python highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="n">secret</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'MY_ENV_VAR'</span><span class="p">]</span>
<span class="n">signature</span> <span class="o">=</span> <span class="n">event</span><span class="p">[</span><span class="s">'headers'</span><span class="p">][</span><span class="s">'x-hub-signature'</span><span class="p">].</span><span class="n">split</span><span class="p">(</span><span class="s">"="</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">body</span> <span class="o">=</span> <span class="n">event</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'body'</span><span class="p">,</span> <span class="s">""</span><span class="p">)</span>
<span class="k">if</span> <span class="n">event</span><span class="p">[</span><span class="s">'isBase64Encoded'</span><span class="p">]:</span>
    <span class="n">body</span> <span class="o">=</span> <span class="n">base64</span><span class="p">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">body</span><span class="p">)</span>

<span class="n">hashsum</span> <span class="o">=</span> <span class="n">hmac</span><span class="p">.</span><span class="n">new</span><span class="p">(</span><span class="n">signature</span><span class="p">,</span> <span class="n">secret</span><span class="p">,</span> <span class="n">hashlib</span><span class="p">.</span><span class="n">sha1</span><span class="p">).</span><span class="n">hexdigest</span><span class="p">()</span>
<span class="k">if</span> <span class="n">hashsum</span> <span class="o">!=</span> <span class="n">signature</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s">'statusCode'</span><span class="p">:</span> <span class="mi">401</span><span class="p">,</span>
        <span class="s">'body'</span><span class="p">:</span> <span class="s">"Bad signature"</span><span class="p">,</span>
    <span class="p">}</span>

<span class="c1"># Do whatever you want
</span>
<span class="k">return</span> <span class="p">{</span>
  <span class="s">'statusCode'</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
  <span class="s">'body'</span><span class="p">:</span> <span class="s">"OK"</span><span class="p">,</span>
<span class="p">}</span>
</code></pre>
		</div>
	</div>
	<h3 id="lambda-environment-variables">Adding environment variables</h3>
	<p>As shown in the example above, I put the webhook secret in an environment variable. We need to add it to our Lambda function before it could be used.</p>
	<p>Doing so is straightforward. Head to Lambda console and select the function, then scroll down to <em>Environment variables</em> section, where you can manage variables for this Lambda function.</p>
	<p><img src="/image/aws/lambda-environment-variables-1.png" alt="Lambda - Environment variables" class="border" /></p>
	<h2 id="customization">Customizing the webhook</h2>
	<p>Now we’ve got all the foundation established, we can do whatever we want with it. Here are some ideas that could try with:</p>
	<ul>
		<li>Connect to Slack and send a notification for every push or CI run result (<a href="https://docs.github.com/en/developers/webhooks-and-events/webhook-events-and-payloads#check_run">the event is <code class="language-plaintext highlighter-rouge">check_run</code></a>)</li>
		<li>Connect to a Telegram bot and send a message to you for your subscribed events</li>
		<li>Start a Netlify or Vercel build or deployment</li>
		<li>Start GitHub Actions on another repository</li>
		<li>and many more possibilities…</li>
	</ul>
	<h2 id="custom-domain">Bonus: Adding a custom domain</h2>
	<p>Before calling this an article, there’s one more thing I’d like to cover. A custom domain is handy so that you’re in full control of your API, and fortunately AWS API Gateway <em>does</em> support this.</p>
	<p>You may have already noticed the <em>Custom Domain Names</em> on the left pane of API Gateway console, so it’s time to pay that a visit.</p>
	<p>The box on the left with a title <em>Domain names</em> is where we need to start from. Click the big <strong>Create</strong> button and enter your custom domain dedicated for AWS API Gateway, like <code class="language-plaintext highlighter-rouge">api.example.com</code>, and click the bridge red button on the bottom right to save the settings. You don’t have to change any other things there as the defaults just work.</p>
	<p>Now you should see this screen:</p>
	<p><img src="/image/aws/api-gateway-custom-domain-1.png" alt="API Gateway - Custom domain" class="border" /></p>
	<p>Head to your DNS provider and add a CNAME record for <code class="language-plaintext highlighter-rouge">api.example.com</code> pointing to the <code class="language-plaintext highlighter-rouge">execute-api</code> domain shown there. If you’re using Cloudflare, you can safely turn on the CDN setting (the orange cloud icon) to enjoy Cloudflare’s faster global network.</p>
	<p>Next we’ll add “API mapping” for our custom domain. Select the <em>API mapping</em> tab in the center of the above image and click <strong>Configure API mappings</strong> on the right. Add a new mapping, select your API and the <code class="language-plaintext highlighter-rouge">$default</code> stage, and give it a subpath if you want, like shown below:</p>
	<p><img src="/image/aws/api-gateway-custom-domain-2.png" alt="API Gateway - Custom domain - API mapping" class="border" /></p>
	<div class="notice--primary">
		<h4 class="no_toc" id="dont-worry-about-your-subpath"><i class="fas fa-fw fa-sun"></i> Don’t worry about your subpath</h4>
		<p>API Gateway will automatically strip the path before passing it to the Lambda function. This means if you set the path to <code class="language-plaintext highlighter-rouge">/hello</code> and visit <code class="language-plaintext highlighter-rouge">https://api.example.com/hello/world</code>, your Lambda function will still see the <code class="language-plaintext highlighter-rouge">rawPath</code> key being <code class="language-plaintext highlighter-rouge">/world</code>. You don’t have to change your code to adapt this part. Very convenient, isn’t it?</p>
	</div>
	<p>Now our GitHub webhook receiver will start with <code class="language-plaintext highlighter-rouge">https://api.example.com/github</code>, and our “API test” endpoint will be <code class="language-plaintext highlighter-rouge">https://api.example.com/github/api-test</code>.</p>
	<p>You may need to configure AWS Certificate Manager to obtain a valid SSL certificate for use on AWS, so that your API is accessible through HTTPS, depending on your domain settings. With Cloudflare this is unnecessary and you can safely ignore it.</p>
	<h2 id="others">Other notes</h2>
	<p>AWS Lambda provides 400,000 GB-seconds of execution for free each month, and this Free Tier does not expire. However, AWS API Gateway doesn’t have a perpetual Free Tier offer, and their standard pricing is US$1 per 1M API calls. The cost on this part is generally low unless you’re making a public service (that becomes popular).</p>
	<p>Besides, AWS provides 1 GB of free outbound traffic each month, and bills you at US$0.09 per GB thereafter. This means you’ll need to be careful when generating a lot of traffic, like frequently uploading large images.</p>
	<p>All pricing examples are based on US East 1 (N. Virginia) region. Other regions are generally more expensive than this, so watch your bills if you make something big.</p>
	]]></content><author><name>iBug</name></author><category term="github" /><category term="aws" /><summary type="html"><![CDATA[Last month I set up my own Telegram bot for GitHub event notification. To receive GitHub events via webhook, a receiver is needed. True, it isn’t hard to write a Flask or Sinatra server and throw the whole thing onto a VPS, but thinking about the complexity and maintenance efforts, serverless platforms like AWS Lambda smells like a better fit. So I decided to take this opportunity to begin my exploration to “the serverless industry”.]]></summary></entry><entry><title type="html">Fix traceroute not showing intermediate results in a virtual machine on Windows</title><link href="https://ibug.io/blog/2021/02/traceroute-from-vmware/" rel="alternate" type="text/html" title="Fix traceroute not showing intermediate results in a virtual machine on Windows" /><published>2021-02-04T00:00:00+00:00</published><updated>2021-02-10T19:09:18+00:00</updated><id>https://ibug.io/blog/2021/02/traceroute-from-vmware</id><content type="html" xml:base="https://ibug.io/blog/2021/02/traceroute-from-vmware/"><![CDATA[<p>Today when I was running some networking diagnostics from an Ubuntu inside VMware Workstation, I noticed this strange result from <a href="https://en.wikipedia.org/wiki/MTR_(software)"><code class="language-plaintext highlighter-rouge">mtr</code> (My Traceroute)</a>:</p>
	<p><img src="/image/linux/traceroute-failure.png" alt="MTR with all intermediate hops blank" /></p>
	<p>This doesn’t look right. Googling around brought me to this page: <a href="https://communities.vmware.com/t5/VMware-Workstation-Player/traceroute-from-Ubuntu-just-shows-first-and-last-hops-on/m-p/1677263">traceroute from Ubuntu just shows first and last hops on VMPlayer 3.1.4 - VMware Technology Network VMTN</a></p>
	<p>The answers in that thread mentioned two points:</p>
	<ul>
		<li><em>On the other hand once I switched to bridge, everything works.</em></li>
		<li><em>What about the intermediary requests, well the answers come back but somehow they are blocked by the Windows firewall.</em></li>
	</ul>
	<p>I immediately realized that it’s because <strong>Windows Firewall blocked responses from the intermediate hops</strong>.</p>
	<h2 id="the-answer">The answer</h2>
	<div class="notice--primary">
		<h4 class="no_toc" id="the-short-answer"><i class="fas fa-shield-check"></i> The short answer</h4>
		<p>The responses from the intermediate routers aren’t “expected” and are blocked off by Windows Firewall.</p>
	</div>
	<h4 class="no_toc" id="the-long-answer">The long answer</h4>
	<p>Windows Firewall has a built-in connection tracking mechanism, similar to that of Linux (conntrack). Since <code class="language-plaintext highlighter-rouge">mtr</code> sends <a href="https://en.wikipedia.org/wiki/Ping_(networking_utility)#Echo_request">pings (ICMP Echo Requests)</a> to the target host, Windows Firewall is expecting ICMP Echo Replies from the target host as the correct response. However, traceroute works by sending packets with TTL starting from 1 until it reaches the target host, and receiving “timed out” notices from the intermediate routers when the packet “dies from time”. This creates two discrepancies:</p>
	<ul>
		<li>The responses are ICMP Time Exceeded packets, not Echo Replies.</li>
		<li>The responses come from the intermediate routers, not the target host.</li>
	</ul>
	<p>This unfortunately somehow “broke” the connection tracking mechanism in Windows Firewall, and leads to the responses being blocked off by Windows Firewall by default.</p>
	<h2 id="the-solution">The solution</h2>
	<div class="notice--warning">
		<h4 class="no_toc" id="the-short-solution"><i class="fas fa-shield-check"></i> The short solution</h4>
		<p>Just turn off Windows Firewall entirely. <strong>You probably don’t want to or shouldn’t do this.</strong> Read on for the complete and real solution.</p>
	</div>
	<p>The correct solution to this problem is to let the intermediary responses through Windows Firewall. To actually do this, we’ll <strong>create a new firewall rule that allows ICMP Time Exceeded packets to come in</strong>. You can stop here now if you know how to configure Windows Firewall.</p>
	<p>Step-by-step solution:</p>
	<ol>
		<li>Open <strong>Windows Defender Firewall with Advanced Security</strong> (at least it’s called as such on my Windows 10). This can be done in two ways:
			<ul>
				<li>Go to <strong>Start</strong> → <strong>Windows Administrative Tools</strong> → <strong>Windows Defender Firewall with Advanced Security</strong></li>
				<li>Or hit <strong><kbd><i class="fab fa-fw fa-windows"></i>Win</kbd>+<kbd>R</kbd></strong>, enter <code class="language-plaintext highlighter-rouge">WF.msc</code> and hit Enter.</li>
			</ul>
		</li>
		<li>
			<p>Select <strong>Inbound Rules</strong> on the left and then <strong>New Rule…</strong> on the right.</p>
			<p><img src="https://i.stack.imgur.com/m1suMs.png" alt="Screenshot" /></p>
		</li>
		<li>
			<p>Follow the prompt to create a new rule. Select the following options for each step. Note that the desired options are selected by default in some steps so you can simply click <strong>Next</strong>.</p>
			<ul>
				<li>Rule Type: <strong>Custom</strong></li>
				<li>Program: <strong>All programs</strong> (just click Next)</li>
				<li>Protocol and Ports:
					<ul>
						<li>Protocol type: <strong>ICMPv4</strong></li>
						<li><em>(Optional)</em> Internet Control Message Protocol (ICMP) settings: Click <strong>Customize</strong> → Select <strong>Specific ICMP types</strong> and tick <strong>Time Exceeded</strong></li>
					</ul>
				</li>
				<li>Scope: <strong>Any IP address</strong> for both (just click Next)</li>
				<li>Action: <strong>Allow</strong> (just click Next)</li>
				<li>Profile: Select all (just click Next)</li>
				<li>Name: <strong>Core Networking - Time Exceeded (ICMPv4-In)</strong> (apparently just any name you prefer)</li>
			</ul>
			<p>Click <strong>Finish</strong> and you should immediately see intermediate hops if you’re using <code class="language-plaintext highlighter-rouge">mtr</code>. For example:</p>
			<p><img src="/image/linux/traceroute-ok.png" alt="MTR correctly functioning" /></p>
		</li>
		<li>
			<p><em>(Optional)</em> Repeat the above steps but select <strong>ICMPv6</strong> for <em>Protocol type</em> if you want to enable IPv6 traceroute. Don’t forget to give it a different name (e.g. <em>(ICMPv6-In)</em> at the end).</p>
			<ul>
				<li>In my case there’s already a built-in rule named <strong>Core Networking - Time Exceeded (ICMPv6-In)</strong> which is even enabled by default. If you find it there, you can simply enable it.</li>
			</ul>
		</li>
	</ol>
	<h3 id="bonus">Bonus</h3>
	<p>If you want to make your rule <em>more solid</em> and <em>look</em> “canonical”, you can add it to the built-in system group <strong>Core Networking</strong> with the help of PowerShell.</p>
	<div class="language-powershell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="nv">$rule</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Get-NetFirewallRule</span><span class="w"> </span><span class="nt">-DisplayName</span><span class="w"> </span><span class="s2">"Core Networking - Time Exceeded (ICMPv4-In)"</span><span class="w">
</span><span class="nv">$rule</span><span class="o">.</span><span class="nf">Group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Core Networking"</span><span class="w">
</span><span class="nv">$rule</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Set-NetFirewallRule</span><span class="w">
</span></code></pre>
		</div>
	</div>
	<p>Your new rule will look like this after running the above commands. You may need to restart the Windows Firewall window to see changes.</p>
	<p><img src="/image/windows/core-networking-time-exceeded-icmpv4-in.png" alt="New Rule" /></p>
	<hr />
	<p>This article was originally written as <a href="https://superuser.com/a/1623001/688600">an answer on Super User</a>.</p>
	]]></content><author><name>iBug</name></author><category term="networking" /><category term="windows" /><summary type="html"><![CDATA[Today when I was running some networking diagnostics from an Ubuntu inside VMware Workstation, I noticed this strange result from mtr (My Traceroute):]]></summary></entry></feed>